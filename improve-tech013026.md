Hi please improve the design by keeping all original features and adding new features 1.Please save default case and review guidance in the program that user can choose to load default dataset/document or upload new dataset/document. Also user can modify cases and review guidance in markdown and download the modifed data (json, csv for case; text, markdown for guidance). 2. If the user uploaded case dataset (cases) is not standardized dataset, system will transform it into standardized dataset before user can modify if. Please let user to modify and download the modified datasets (case in csv or JSON). 3. Please add a new button to refresh application compeletness. Also adding information about what items are not finished. import os

import json

import base64

import random

import re

from datetime import datetime

from io import BytesIO

from typing import Dict, Any, List, Tuple, Optional



import streamlit as st

import yaml

import pandas as pd

import altair as alt

from pypdf import PdfReader



try:

    from docx import Document  # python-docx

except ImportError:

    Document = None



try:

    from reportlab.pdfgen import canvas

    from reportlab.lib.pagesizes import letter

except ImportError:

    canvas = None

    letter = None



try:

    import pytesseract

    from pdf2image import convert_from_bytes

    from PIL import Image

except ImportError:

    pytesseract = None

    convert_from_bytes = None

    Image = None



from openai import OpenAI

import google.generativeai as genai

from anthropic import Anthropic

import httpx





# ============================================================

# 0) Streamlit page config

# ============================================================

st.set_page_config(

    page_title="Antigravity AI Workspace",

    layout="wide",

    initial_sidebar_state="expanded",

)



# ============================================================

# 1) Models & Providers

# ============================================================

ALL_MODELS = [

    # OpenAI

    "gpt-4o-mini",

    "gpt-4.1-mini",

    # Gemini

    "gemini-2.5-flash",

    "gemini-3-flash-preview",

    "gemini-2.5-flash-lite",

    "gemini-3-pro-preview",

    # Anthropic (examples; can extend freely)

    "claude-3-5-sonnet-20241022",

    "claude-3-5-haiku-20241022",

    "claude-3-opus-20240229",

    # xAI Grok

    "grok-4-fast-reasoning",

    "grok-4-1-fast-non-reasoning",

]



OPENAI_MODELS = {"gpt-4o-mini", "gpt-4.1-mini"}

GEMINI_MODELS = {

    "gemini-2.5-flash",

    "gemini-3-flash-preview",

    "gemini-2.5-flash-lite",

    "gemini-3-pro-preview",

}

ANTHROPIC_MODELS = {

    "claude-3-5-sonnet-20241022",

    "claude-3-5-haiku-20241022",

    "claude-3-opus-20240229",

}

GROK_MODELS = {"grok-4-fast-reasoning", "grok-4-1-fast-non-reasoning"}





def get_provider(model: str) -> str:

    if model in OPENAI_MODELS:

        return "openai"

    if model in GEMINI_MODELS:

        return "gemini"

    if model in ANTHROPIC_MODELS:

        return "anthropic"

    if model in GROK_MODELS:

        return "grok"

    raise ValueError(f"Unknown/unsupported model: {model}")





# ============================================================

# 2) i18n (English / zh-TW)

# ============================================================

I18N: Dict[str, Dict[str, str]] = {

    "en": {

        "app_title": "Antigravity AI Workspace",

        "top_tagline": "A WOW workspace for agents, dashboards, notes, and art styles",

        "theme": "Theme",

        "light": "Light",

        "dark": "Dark",

        "language": "Language",

        "english": "English",

        "zh_tw": "Traditional Chinese (ç¹é«”ä¸­æ–‡)",

        "style_engine": "Style Engine",

        "painter_style": "Painter Style",

        "jackpot": "Jackpot",

        "global_settings": "Global Settings",

        "default_model": "Default Model",

        "default_max_tokens": "Default max_tokens",

        "temperature": "Temperature",

        "api_keys": "API Keys",

        "active_env": "Active (Env)",

        "missing": "Missing",

        "provided_session": "Provided (Session)",

        "agents_catalog": "Agents Catalog (agents.yaml)",

        "upload_agents_yaml": "Upload custom agents.yaml",

        "dashboard": "Dashboard",

        "tw_premarket": "TW Premarket Application",

        "fda_510k": "510(k) Intelligence",

        "pdf_md": "PDF â†’ Markdown",

        "pipeline": "510(k) Review Pipeline",

        "note_keeper": "Note Keeper & Magics",

        "agents_config": "Agents Config Studio",

        "workflow_studio": "Agent Workflow Studio",

        "status_wall": "WOW Status Wall",

        "run_agent": "Run Agent",

        "prompt": "Prompt",

        "model": "Model",

        "input_text": "Input Text / Markdown",

        "output": "Output",

        "view_mode": "View mode",

        "markdown": "Markdown",

        "plain_text": "Plain text",

        "api_pulse": "API Connection Pulse",

        "token_meter": "Token Usage Meter",

        "agent_status": "Agent Status",

        "idle": "Idle",

        "thinking": "Thinking",

        "done": "Done",

        "error": "Error",

        "clear_history": "Clear history",

        "export_history": "Export history (CSV)",

        "note_upload": "Upload note file (.pdf/.txt/.md)",

        "note_paste": "Paste your notes (text/markdown)",

        "note_transform": "Transform to organized Markdown + coral keywords",

        "note_color": "Keyword color",

        "ai_magics": "AI Magics",

        "magic_keywords": "AI Keywords",

        "magic_summarize": "Summarize",

        "magic_polish": "Polisher",

        "magic_critique": "Critique",

        "magic_poet": "Poet Mode",

        "magic_translate": "Translate",

        "apply": "Apply",

        "run": "Run",

        "reset": "Reset",

        "step": "Step",

        "run_step": "Run step",

        "run_next": "Run next",

        "workflow_input": "Workflow Input",

        "workflow_output": "Workflow Output",

        "add_step": "Add step",

        "remove_step": "Remove last step",

        "load_defaults": "Load recommended workflow",

        "download_md": "Download Markdown",

    },

    "zh-tw": {

        "app_title": "Antigravity AI å·¥ä½œç©ºé–“",

        "top_tagline": "WOW ç´šï¼šä»£ç†å·¥ä½œæµã€äº’å‹•å„€è¡¨æ¿ã€ç­†è¨˜é­”æ³•ã€è—è¡“ä¸»é¡Œ",

        "theme": "ä¸»é¡Œ",

        "light": "æ·ºè‰²",

        "dark": "æ·±è‰²",

        "language": "èªžè¨€",

        "english": "è‹±æ–‡",

        "zh_tw": "ç¹é«”ä¸­æ–‡",

        "style_engine": "é¢¨æ ¼å¼•æ“Ž",

        "painter_style": "ç•«å®¶é¢¨æ ¼",

        "jackpot": "æ‹‰éœ¸",

        "global_settings": "å…¨åŸŸè¨­å®š",

        "default_model": "é è¨­æ¨¡åž‹",

        "default_max_tokens": "é è¨­ max_tokens",

        "temperature": "æº«åº¦(å‰µé€ åŠ›)",

        "api_keys": "API é‡‘é‘°",

        "active_env": "å·²å•Ÿç”¨ï¼ˆç’°å¢ƒè®Šæ•¸ï¼‰",

        "missing": "ç¼ºå°‘",

        "provided_session": "å·²æä¾›ï¼ˆæœ¬æ¬¡æœƒè©±ï¼‰",

        "agents_catalog": "ä»£ç†ç›®éŒ„ï¼ˆagents.yamlï¼‰",

        "upload_agents_yaml": "ä¸Šå‚³è‡ªè¨‚ agents.yaml",

        "dashboard": "å„€è¡¨æ¿",

        "tw_premarket": "ç¬¬äºŒã€ä¸‰ç­‰ç´šé†«ç™‚å™¨ææŸ¥é©—ç™»è¨˜",

        "fda_510k": "510(k) æ™ºèƒ½åˆ†æž",

        "pdf_md": "PDF â†’ Markdown",

        "pipeline": "510(k) å¯©æŸ¥å…¨æµç¨‹",

        "note_keeper": "ç­†è¨˜åŠ©æ‰‹èˆ‡é­”æ³•",

        "agents_config": "ä»£ç†è¨­å®šå·¥ä½œå®¤",

        "workflow_studio": "ä»£ç†å·¥ä½œæµå·¥ä½œå®¤",

        "status_wall": "WOW ç‹€æ…‹ç‰†",

        "run_agent": "åŸ·è¡Œä»£ç†",

        "prompt": "æç¤ºè©ž",

        "model": "æ¨¡åž‹",

        "input_text": "è¼¸å…¥ï¼ˆæ–‡å­—/Markdownï¼‰",

        "output": "è¼¸å‡º",

        "view_mode": "æª¢è¦–æ¨¡å¼",

        "markdown": "Markdown",

        "plain_text": "ç´”æ–‡å­—",

        "api_pulse": "API é€£ç·šè„ˆå‹•",

        "token_meter": "Token ç”¨é‡å„€è¡¨",

        "agent_status": "ä»£ç†ç‹€æ…‹",

        "idle": "å¾…å‘½",

        "thinking": "æ€è€ƒä¸­",

        "done": "å®Œæˆ",

        "error": "éŒ¯èª¤",

        "clear_history": "æ¸…é™¤ç´€éŒ„",

        "export_history": "åŒ¯å‡ºç´€éŒ„ï¼ˆCSVï¼‰",

        "note_upload": "ä¸Šå‚³ç­†è¨˜æª”ï¼ˆ.pdf/.txt/.mdï¼‰",

        "note_paste": "è²¼ä¸Šç­†è¨˜ï¼ˆæ–‡å­—/Markdownï¼‰",

        "note_transform": "æ•´ç†æˆçµæ§‹åŒ– Markdown + çŠç‘šè‰²é—œéµå­—",

        "note_color": "é—œéµå­—é¡è‰²",

        "ai_magics": "AI é­”æ³•",

        "magic_keywords": "AI é—œéµå­—",

        "magic_summarize": "æ‘˜è¦",

        "magic_polish": "æ½¤ç¨¿",

        "magic_critique": "è©•è«–",

        "magic_poet": "è©©äººæ¨¡å¼",

        "magic_translate": "ç¿»è­¯",

        "apply": "å¥—ç”¨",

        "run": "åŸ·è¡Œ",

        "reset": "é‡ç½®",

        "step": "æ­¥é©Ÿ",

        "run_step": "åŸ·è¡Œæœ¬æ­¥é©Ÿ",

        "run_next": "åŸ·è¡Œä¸‹ä¸€æ­¥",

        "workflow_input": "å·¥ä½œæµè¼¸å…¥",

        "workflow_output": "å·¥ä½œæµè¼¸å‡º",

        "add_step": "æ–°å¢žæ­¥é©Ÿ",

        "remove_step": "åˆªé™¤æœ€å¾Œä¸€æ­¥",

        "load_defaults": "è¼‰å…¥å»ºè­°å·¥ä½œæµ",

        "download_md": "ä¸‹è¼‰ Markdown",

    },

}





def lang_code() -> str:

    return st.session_state.settings.get("language", "zh-tw")





def t(key: str) -> str:

    return I18N.get(lang_code(), I18N["en"]).get(key, key)





# ============================================================

# 3) Style Engine: 20 painter styles + Jackpot

# ============================================================

PAINTER_STYLES_20 = [

    "Van Gogh",

    "Picasso",

    "Monet",

    "Da Vinci",

    "Dali",

    "Mondrian",

    "Warhol",

    "Rembrandt",

    "Klimt",

    "Hokusai",

    "Munch",

    "O'Keeffe",

    "Basquiat",

    "Matisse",

    "Pollock",

    "Kahlo",

    "Hopper",

    "Magritte",

    "Cyberpunk",

    "Bauhaus",

]



# Theme tokens (CSS variables) per painter style

STYLE_TOKENS: Dict[str, Dict[str, str]] = {

    "Van Gogh": {

        "--bg1": "#0b1020",

        "--bg2": "#1f3b73",

        "--accent": "#f7c948",

        "--accent2": "#60a5fa",

        "--card": "rgba(255,255,255,0.10)",

        "--border": "rgba(255,255,255,0.22)",

    },

    "Picasso": {

        "--bg1": "#2b2b2b",

        "--bg2": "#7c2d12",

        "--accent": "#f59e0b",

        "--accent2": "#a3e635",

        "--card": "rgba(255,255,255,0.10)",

        "--border": "rgba(255,255,255,0.22)",

    },

    "Monet": {

        "--bg1": "#a1c4fd",

        "--bg2": "#c2e9fb",

        "--accent": "#2563eb",

        "--accent2": "#0ea5e9",

        "--card": "rgba(255,255,255,0.35)",

        "--border": "rgba(255,255,255,0.45)",

    },

    "Da Vinci": {

        "--bg1": "#f6f0d9",

        "--bg2": "#cbb38b",

        "--accent": "#7c2d12",

        "--accent2": "#1f2937",

        "--card": "rgba(255,255,255,0.35)",

        "--border": "rgba(17,24,39,0.18)",

    },

    "Dali": {

        "--bg1": "#0f172a",

        "--bg2": "#b91c1c",

        "--accent": "#fbbf24",

        "--accent2": "#38bdf8",

        "--card": "rgba(255,255,255,0.12)",

        "--border": "rgba(255,255,255,0.22)",

    },

    "Mondrian": {

        "--bg1": "#f8fafc",

        "--bg2": "#e2e8f0",

        "--accent": "#ef4444",

        "--accent2": "#2563eb",

        "--card": "rgba(255,255,255,0.60)",

        "--border": "rgba(0,0,0,0.18)",

    },

    "Warhol": {

        "--bg1": "#0b1020",

        "--bg2": "#6d28d9",

        "--accent": "#22c55e",

        "--accent2": "#f472b6",

        "--card": "rgba(255,255,255,0.10)",

        "--border": "rgba(255,255,255,0.22)",

    },

    "Rembrandt": {

        "--bg1": "#07050a",

        "--bg2": "#2c1810",

        "--accent": "#f59e0b",

        "--accent2": "#fbbf24",

        "--card": "rgba(255,255,255,0.08)",

        "--border": "rgba(245,158,11,0.20)",

    },

    "Klimt": {

        "--bg1": "#0b1020",

        "--bg2": "#3b2f0b",

        "--accent": "#fbbf24",

        "--accent2": "#fde68a",

        "--card": "rgba(255,255,255,0.10)",

        "--border": "rgba(251,191,36,0.25)",

    },

    "Hokusai": {

        "--bg1": "#061a2b",

        "--bg2": "#1e3a8a",

        "--accent": "#60a5fa",

        "--accent2": "#93c5fd",

        "--card": "rgba(255,255,255,0.10)",

        "--border": "rgba(147,197,253,0.25)",

    },

    "Munch": {

        "--bg1": "#1f2937",

        "--bg2": "#7f1d1d",

        "--accent": "#fb7185",

        "--accent2": "#fde047",

        "--card": "rgba(255,255,255,0.10)",

        "--border": "rgba(255,255,255,0.22)",

    },

    "O'Keeffe": {

        "--bg1": "#fff7ed",

        "--bg2": "#fecdd3",

        "--accent": "#db2777",

        "--accent2": "#f97316",

        "--card": "rgba(255,255,255,0.55)",

        "--border": "rgba(219,39,119,0.18)",

    },

    "Basquiat": {

        "--bg1": "#111827",

        "--bg2": "#f59e0b",

        "--accent": "#22c55e",

        "--accent2": "#60a5fa",

        "--card": "rgba(255,255,255,0.12)",

        "--border": "rgba(255,255,255,0.22)",

    },

    "Matisse": {

        "--bg1": "#ffedd5",

        "--bg2": "#fde68a",

        "--accent": "#ea580c",

        "--accent2": "#2563eb",

        "--card": "rgba(255,255,255,0.60)",

        "--border": "rgba(234,88,12,0.20)",

    },

    "Pollock": {

        "--bg1": "#0b1020",

        "--bg2": "#111827",

        "--accent": "#f97316",

        "--accent2": "#22c55e",

        "--card": "rgba(255,255,255,0.10)",

        "--border": "rgba(255,255,255,0.20)",

    },

    "Kahlo": {

        "--bg1": "#064e3b",

        "--bg2": "#7f1d1d",

        "--accent": "#fbbf24",

        "--accent2": "#22c55e",

        "--card": "rgba(255,255,255,0.10)",

        "--border": "rgba(255,255,255,0.22)",

    },

    "Hopper": {

        "--bg1": "#0b1020",

        "--bg2": "#0f766e",

        "--accent": "#60a5fa",

        "--accent2": "#fbbf24",

        "--card": "rgba(255,255,255,0.10)",

        "--border": "rgba(255,255,255,0.22)",

    },

    "Magritte": {

        "--bg1": "#0b1020",

        "--bg2": "#1d4ed8",

        "--accent": "#e2e8f0",

        "--accent2": "#fbbf24",

        "--card": "rgba(255,255,255,0.10)",

        "--border": "rgba(255,255,255,0.22)",

    },

    "Cyberpunk": {

        "--bg1": "#050816",

        "--bg2": "#1b0033",

        "--accent": "#22d3ee",

        "--accent2": "#a78bfa",

        "--card": "rgba(255,255,255,0.08)",

        "--border": "rgba(34,211,238,0.25)",

    },

    "Bauhaus": {

        "--bg1": "#f8fafc",

        "--bg2": "#e2e8f0",

        "--accent": "#111827",

        "--accent2": "#ef4444",

        "--card": "rgba(255,255,255,0.70)",

        "--border": "rgba(17,24,39,0.15)",

    },

}





def apply_style_engine(theme_mode: str, painter_style: str):

    """

    WOW UI: glassmorphism + style tokens + subtle animated background + neon/ink accents.

    """

    tokens = STYLE_TOKENS.get(painter_style, STYLE_TOKENS["Van Gogh"])

    is_dark = theme_mode.lower() == "dark"



    # Base variables

    text_color = "#e5e7eb" if is_dark else "#0f172a"

    subtext = "#cbd5e1" if is_dark else "#334155"

    card_text = "#f8fafc" if is_dark else "#0f172a"

    shadow = "0 18px 50px rgba(0,0,0,0.38)" if is_dark else "0 18px 50px rgba(2,6,23,0.18)"

    glass = "rgba(17,24,39,0.38)" if is_dark else "rgba(255,255,255,0.55)"



    # Pollock splatter overlay (lightweight CSS only)

    splatter = ""

    if painter_style == "Pollock":

        splatter = """

        body:before{

            content:"";

            position:fixed; inset:0;

            background:

              radial-gradient(circle at 10% 20%, rgba(249,115,22,0.18) 0 10%, transparent 12%),

              radial-gradient(circle at 70% 35%, rgba(34,197,94,0.18) 0 9%, transparent 11%),

              radial-gradient(circle at 40% 80%, rgba(96,165,250,0.18) 0 12%, transparent 14%),

              radial-gradient(circle at 85% 75%, rgba(244,114,182,0.16) 0 8%, transparent 10%);

            pointer-events:none;

            filter: blur(0.2px);

            mix-blend-mode: screen;

            opacity:0.85;

        }

        """



    css = f"""

    <style>

    :root {{

        {"".join([f"{k}:{v};" for k,v in tokens.items()])}

        --text: {text_color};

        --subtext: {subtext};

        --glass: {glass};

        --shadow: {shadow};

        --radius: 18px;

        --radius2: 26px;

        --coral: #FF7F50;

    }}



    /* Background */

    body {{

        color: var(--text);

        background: radial-gradient(1200px circle at 12% 8%, var(--bg2) 0%, transparent 55%),

                    radial-gradient(900px circle at 88% 18%, var(--accent2) 0%, transparent 50%),

                    linear-gradient(135deg, var(--bg1), var(--bg2));

        background-attachment: fixed;

    }}

    {splatter}



    /* Streamlit base tweaks */

    .block-container {{

        padding-top: 1.0rem;

        padding-bottom: 3.5rem;

    }}



    /* WOW Top Hero */

    .wow-hero {{

        border-radius: var(--radius2);

        padding: 18px 18px;

        margin: 0 0 14px 0;

        background: linear-gradient(135deg, rgba(255,255,255,0.10), rgba(255,255,255,0.02));

        border: 1px solid var(--border);

        box-shadow: var(--shadow);

        backdrop-filter: blur(12px);

    }}

    .wow-title {{

        font-size: 1.35rem;

        font-weight: 800;

        letter-spacing: 0.02em;

        margin: 0;

        color: var(--text);

    }}

    .wow-subtitle {{

        margin: 6px 0 0 0;

        color: var(--subtext);

        font-size: 0.95rem;

    }}

    .wow-chips {{

        margin-top: 10px;

        display:flex;

        flex-wrap: wrap;

        gap: 8px;

    }}

    .wow-chip {{

        display:inline-flex;

        align-items:center;

        gap: 8px;

        padding: 6px 10px;

        border-radius: 999px;

        font-size: 0.82rem;

        background: rgba(255,255,255,0.10);

        border: 1px solid var(--border);

        backdrop-filter: blur(10px);

        color: var(--text);

    }}



    /* Cards / glass containers */

    .wow-card {{

        border-radius: var(--radius);

        padding: 14px 16px;

        background: var(--glass);

        border: 1px solid var(--border);

        box-shadow: var(--shadow);

        backdrop-filter: blur(12px);

    }}

    .wow-card h3, .wow-card h4 {{

        margin: 0 0 8px 0;

    }}

    .wow-kpi {{

        font-size: 1.55rem;

        font-weight: 800;

        margin-top: 4px;

    }}

    .wow-muted {{

        color: var(--subtext);

        font-size: 0.92rem;

    }}



    /* Buttons */

    .stButton > button {{

        border-radius: 999px !important;

        border: 1px solid var(--border) !important;

        background: linear-gradient(135deg, var(--accent), var(--accent2)) !important;

        color: {"#0b1020" if not is_dark else "#0b1020"} !important;

        font-weight: 800 !important;

        letter-spacing: 0.02em !important;

        box-shadow: 0 14px 35px rgba(0,0,0,0.25) !important;

    }}

    .stButton > button:hover {{

        filter: brightness(1.04);

        transform: translateY(-1px);

        transition: 120ms ease;

    }}



    /* Inputs */

    .stTextInput input, .stTextArea textarea, .stSelectbox div[data-baseweb="select"] > div {{

        border-radius: 14px !important;

        border: 1px solid var(--border) !important;

        background: rgba(255,255,255,{0.06 if is_dark else 0.55}) !important;

        color: var(--text) !important;

    }}



    /* Tabs */

    button[role="tab"] {{

        border-radius: 999px !important;

    }}



    /* Status dot */

    .dot {{

        width: 10px;

        height: 10px;

        border-radius: 50%;

        display: inline-block;

        margin-right: 8px;

        box-shadow: 0 0 0 3px rgba(255,255,255,0.06);

    }}

    .dot-green {{ background: #22c55e; box-shadow: 0 0 18px rgba(34,197,94,0.55); }}

    .dot-red {{ background: #ef4444; box-shadow: 0 0 18px rgba(239,68,68,0.55); }}

    .dot-amber {{ background: #f59e0b; box-shadow: 0 0 18px rgba(245,158,11,0.55); }}



    /* Small badges */

    .wow-badge {{

        display:inline-flex;

        align-items:center;

        padding: 3px 10px;

        border-radius: 999px;

        font-size: 0.78rem;

        font-weight: 700;

        border: 1px solid var(--border);

        background: rgba(255,255,255,0.10);

        color: var(--text);

    }}



    /* Coral highlight helper */

    .coral {{

        color: var(--coral);

        font-weight: 800;

    }}

    </style>

    """

    st.markdown(css, unsafe_allow_html=True)





# ============================================================

# 4) State init

# ============================================================

if "settings" not in st.session_state:

    st.session_state["settings"] = {

        "theme": "Dark",

        "language": "zh-tw",  # "en" or "zh-tw"

        "painter_style": "Van Gogh",

        "model": "gpt-4o-mini",

        "max_tokens": 12000,

        "temperature": 0.2,

        "token_budget_est": 250_000,  # session visual budget

    }



if "history" not in st.session_state:

    st.session_state["history"] = []



if "api_keys" not in st.session_state:

    st.session_state["api_keys"] = {"openai": "", "gemini": "", "anthropic": "", "grok": ""}



if "workflow" not in st.session_state:

    st.session_state["workflow"] = {

        "steps": [],  # list of dicts: {agent_id, model, max_tokens, prompt, system_override?}

        "cursor": 0,

        "input": "",

        "outputs": [],  # per-step output (editable)

        "statuses": [],  # per-step status

    }





# ============================================================

# 5) API key logic (env first; hide if env exists)

# ============================================================

def env_key_present(env_var: str) -> bool:

    v = os.getenv(env_var, "")

    return bool(v and v.strip())





def get_api_key(provider: str, api_keys: Dict[str, str]) -> str:

    mapping = {

        "openai": "OPENAI_API_KEY",

        "gemini": "GEMINI_API_KEY",

        "anthropic": "ANTHROPIC_API_KEY",

        "grok": "GROK_API_KEY",

    }

    env_var = mapping.get(provider, "")

    return api_keys.get(provider) or os.getenv(env_var) or ""





def api_status(provider: str) -> Tuple[str, str]:

    """

    returns: (status: 'env'|'session'|'missing', label)

    """

    mapping = {

        "openai": "OPENAI_API_KEY",

        "gemini": "GEMINI_API_KEY",

        "anthropic": "ANTHROPIC_API_KEY",

        "grok": "GROK_API_KEY",

    }

    env_var = mapping[provider]

    if env_key_present(env_var):

        return "env", t("active_env")

    if st.session_state["api_keys"].get(provider, "").strip():

        return "session", t("provided_session")

    return "missing", t("missing")





# ============================================================

# 6) LLM call router

# ============================================================

def call_llm(

    model: str,

    system_prompt: str,

    user_prompt: str,

    max_tokens: int = 12000,

    temperature: float = 0.2,

    api_keys: Optional[dict] = None,

) -> str:

    provider = get_provider(model)

    api_keys = api_keys or {}



    key = get_api_key(provider, api_keys)

    if not key:

        raise RuntimeError(f"Missing API key for provider: {provider}")



    if provider == "openai":

        client = OpenAI(api_key=key)

        resp = client.chat.completions.create(

            model=model,

            messages=[

                {"role": "system", "content": system_prompt or ""},

                {"role": "user", "content": user_prompt or ""},

            ],

            max_tokens=max_tokens,

            temperature=temperature,

        )

        return resp.choices[0].message.content



    if provider == "gemini":

        genai.configure(api_key=key)

        llm = genai.GenerativeModel(model)

        resp = llm.generate_content(

            (system_prompt or "").strip() + "\n\n" + (user_prompt or "").strip(),

            generation_config={

                "max_output_tokens": max_tokens,

                "temperature": temperature,

            },

        )

        return resp.text



    if provider == "anthropic":

        client = Anthropic(api_key=key)

        resp = client.messages.create(

            model=model,

            system=system_prompt or "",

            max_tokens=max_tokens,

            temperature=temperature,

            messages=[{"role": "user", "content": user_prompt or ""}],

        )

        return resp.content[0].text



    if provider == "grok":

        with httpx.Client(base_url="https://api.x.ai/v1", timeout=90) as client:

            resp = client.post(

                "/chat/completions",

                headers={"Authorization": f"Bearer {key}"},

                json={

                    "model": model,

                    "messages": [

                        {"role": "system", "content": system_prompt or ""},

                        {"role": "user", "content": user_prompt or ""},

                    ],

                    "max_tokens": max_tokens,

                    "temperature": temperature,

                },

            )

            resp.raise_for_status()

            data = resp.json()

        return data["choices"][0]["message"]["content"]



    raise RuntimeError(f"Unsupported provider for model {model}")





# ============================================================

# 7) Generic helpers (pdf/text, logging, status UI)

# ============================================================

def log_event(tab: str, agent: str, model: str, tokens_est: int, meta: Optional[dict] = None):

    st.session_state["history"].append(

        {

            "tab": tab,

            "agent": agent,

            "model": model,

            "tokens_est": int(tokens_est),

            "ts": datetime.utcnow().isoformat(),

            "meta": meta or {},

        }

    )





    return max(1, int(len(text) / 4))





def extract_pdf_pages_to_text(file, start_page: int, end_page: int, use_ocr: bool = False) -> str:

    """

    Extract text from PDF pages, optionally using OCR for scanned docs.

    """

    # 1. Standard pypdf extraction

    pdf_text = ""

    try:

        reader = PdfReader(file)

        n = len(reader.pages)

        start = max(0, start_page - 1)

        end = min(n, end_page)

        

        raw_texts = []

        for i in range(start, end):

            try:

                page_text = reader.pages[i].extract_text() or ""

                raw_texts.append(page_text)

            except Exception:

                raw_texts.append("")

        pdf_text = "\n\n".join(raw_texts).strip()

    except Exception as e:

        print(f"pypdf extraction error: {e}")



    # 2. If OCR requested (or fallback if empty and OCR available)

    if use_ocr:

        if pytesseract is None or convert_from_bytes is None:

            return pdf_text + "\n\n[System: OCR requested but libraries (pytesseract/pdf2image) are missing.]"

        

        ocr_text = []

        # Reset file pointer for pdf2image

        file.seek(0)

        try:

            # We convert only the requested pages. convert_from_bytes uses 1-based first_page/last_page

            images = convert_from_bytes(file.read(), first_page=start_page, last_page=end_page)

            for img in images:

                text = pytesseract.image_to_string(img, lang='eng+chi_tra') # Try English + Traditional Chinese

                ocr_text.append(text)

            

            return "\n\n".join(ocr_text).strip()

        except Exception as e:

            return pdf_text + f"\n\n[System: OCR failed: {e}]"



    return pdf_text





def create_pdf_from_text(text: str) -> bytes:

    if canvas is None or letter is None:

        raise RuntimeError("Missing 'reportlab'. Add 'reportlab' to requirements.txt to export PDF.")

    buf = BytesIO()

    c = canvas.Canvas(buf, pagesize=letter)

    width, height = letter

    margin = 72

    line_height = 14

    y = height - margin

    for line in (text or "").splitlines():

        if y < margin:

            c.showPage()

            y = height - margin

        c.drawString(margin, y, line[:2000])

        y -= line_height

    c.save()

    buf.seek(0)

    return buf.getvalue()





def show_pdf(pdf_bytes: bytes, height: int = 600):

    if not pdf_bytes:

        return

    b64 = base64.b64encode(pdf_bytes).decode("utf-8")

    st.markdown(

        f"""<iframe src="data:application/pdf;base64,{b64}" width="100%" height="{height}"></iframe>""",

        unsafe_allow_html=True,

    )





def status_row(label: str, status: str):

    color_class = {

        "pending": "dot-amber",

        "running": "dot-amber",

        "done": "dot-green",

        "error": "dot-red",

        "idle": "dot-amber",

        "thinking": "dot-amber",

    }.get(status, "dot-amber")



    st.markdown(

        f"""

        <div style="display:flex; align-items:center; gap:10px; margin:2px 0;">

          <span class="dot {color_class}"></span>

          <div style="font-weight:800;">{label}</div>

          <span class="wow-badge">{status}</span>

        </div>

        """,

        unsafe_allow_html=True,

    )





# ============================================================

# 8) Load agents.yaml (fallback included)

# ============================================================

def load_agents_cfg() -> Dict[str, Any]:

    try:

        with open("agents.yaml", "r", encoding="utf-8") as f:

            cfg = yaml.safe_load(f) or {}

        if "agents" not in cfg:

            cfg["agents"] = {}

        return cfg

    except Exception:

        return {"agents": {}}





def ensure_fallback_agents(cfg: Dict[str, Any]) -> Dict[str, Any]:

    agents = cfg.setdefault("agents", {})



    def put(aid: str, obj: Dict[str, Any]):

        if aid not in agents:

            agents[aid] = obj



    # Keep original default agents (existing app behavior)

    put(

        "fda_510k_intel_agent",

        {

            "name": "510(k) Intelligence Agent",

            "model": "gpt-4o-mini",

            "system_prompt": "You are an FDA 510(k) analyst.",

            "max_tokens": 12000,

            "category": "FDA 510(k)",

            "description_tw": "ç”¢å‡º 510(k) æƒ…è³‡/æ‘˜è¦èˆ‡è¡¨æ ¼ã€‚",

        },

    )

    put(

        "pdf_to_markdown_agent",

        {

            "name": "PDF â†’ Markdown Agent",

            "model": "gemini-2.5-flash",

            "system_prompt": "You convert PDF-extracted text into clean markdown.",

            "max_tokens": 12000,

            "category": "Document",

            "description_tw": "å°‡ PDF æ–‡å­—è½‰æˆä¹¾æ·¨ Markdownã€‚",

        },

    )

    put(

        "tw_screen_review_agent",

        {

            "name": "TFDA é å¯©å½¢å¼å¯©æŸ¥ä»£ç†",

            "model": "gemini-2.5-flash",

            "system_prompt": "You are a TFDA premarket screen reviewer.",

            "max_tokens": 12000,

            "category": "TFDA Premarket",

            "description_tw": "ä¾ç”³è«‹æ›¸èˆ‡æŒ‡å¼•åšå½¢å¼å¯©æŸ¥/ç¼ºæ¼åˆ†æžã€‚",

        },

    )

    put(

        "tw_app_doc_helper",

        {

            "name": "TFDA ç”³è«‹æ›¸æ’°å¯«åŠ©æ‰‹",

            "model": "gpt-4o-mini",

            "system_prompt": "You help improve TFDA application documents.",

            "max_tokens": 12000,

            "category": "TFDA Premarket",

            "description_tw": "å„ªåŒ–ç”³è«‹æ›¸ Markdown çµæ§‹èˆ‡èªžå¥ã€‚",

        },

    )



    # New: Note Keeper magics agents

    put(

        "note_organizer",

        {

            "name": "Note Organizer",

            "model": "gpt-4o-mini",

            "system_prompt": "You turn messy notes into structured markdown without adding facts.",

            "max_tokens": 12000,

            "category": "Note Keeper",

            "description_tw": "æŠŠé›œäº‚ç­†è¨˜æ•´ç†æˆæœ‰æ¨™é¡Œ/æ¢åˆ—çš„ Markdownã€‚",

        },

    )

    put(

        "keyword_extractor",

        {

            "name": "Keyword Extractor",

            "model": "gemini-2.5-flash",

            "system_prompt": "You extract high-signal keywords/entities from technical notes.",

            "max_tokens": 4000,

            "category": "Note Keeper",

            "description_tw": "å¾žç­†è¨˜æŠ½å–é«˜è¨Šè™Ÿé—œéµå­—/å¯¦é«”ã€‚",

        },

    )

    put(

        "polisher",

        {

            "name": "Polisher",

            "model": "gpt-4.1-mini",

            "system_prompt": "You rewrite text for clarity and professional tone without changing meaning.",

            "max_tokens": 12000,

            "category": "Note Keeper",

            "description_tw": "åœ¨ä¸æ”¹è®ŠåŽŸæ„ä¸‹æ½¤ç¨¿ï¼Œæå‡æ¸…æ™°åº¦èˆ‡å°ˆæ¥­æ€§ã€‚",

        },

    )

    put(

        "critic",

        {

            "name": "Creative Critic",

            "model": "claude-3-5-sonnet-20241022",

            "system_prompt": "You give constructive, specific critique and improvement suggestions.",

            "max_tokens": 12000,

            "category": "Note Keeper",

            "description_tw": "çµ¦å‡ºå…·é«”ã€å¯åŸ·è¡Œçš„å»ºè­°èˆ‡æ‰¹åˆ¤æ€§å›žé¥‹ã€‚",

        },

    )

    put(

        "poet_laureate",

        {

            "name": "Poet Laureate",

            "model": "gemini-3-flash-preview",

            "system_prompt": "You transform content into poetic or artistic prose while preserving core ideas.",

            "max_tokens": 12000,

            "category": "Note Keeper",

            "description_tw": "æŠŠå…§å®¹è½‰ç‚ºè©©/æ•£æ–‡å¼è¡¨é”ï¼ˆä¿ç•™æ ¸å¿ƒæ„æ€ï¼‰ã€‚",

        },

    )

    put(

        "translator",

        {

            "name": "Translator",

            "model": "gemini-2.5-flash",

            "system_prompt": "You translate accurately with correct terminology.",

            "max_tokens": 12000,

            "category": "Note Keeper",

            "description_tw": "ä¾ UI èªžè¨€è‡ªå‹•ç¿»è­¯ï¼ˆä¸­â†”è‹±ï¼‰ã€‚",

        },

    )

    return cfg





if "agents_cfg" not in st.session_state:

    st.session_state["agents_cfg"] = ensure_fallback_agents(load_agents_cfg())

else:

    st.session_state["agents_cfg"] = ensure_fallback_agents(st.session_state["agents_cfg"])





# ============================================================

# 9) WOW header + sidebar

# ============================================================

def render_wow_header():

    openai_s, openai_label = api_status("openai")

    gemini_s, gemini_label = api_status("gemini")

    anth_s, anth_label = api_status("anthropic")

    grok_s, grok_label = api_status("grok")



    def dot(s: str) -> str:

        if s == "env":

            return "dot-green"

        if s == "session":

            return "dot-amber"

        return "dot-red"



    st.markdown(

        f"""

        <div class="wow-hero">

          <div style="display:flex; justify-content:space-between; align-items:flex-start; gap:14px;">

            <div>

              <div class="wow-title">{t("app_title")}</div>

              <div class="wow-subtitle">{t("top_tagline")}</div>

              <div class="wow-chips">

                <div class="wow-chip"><span class="dot {dot(openai_s)}"></span>OpenAI Â· {openai_label}</div>

                <div class="wow-chip"><span class="dot {dot(gemini_s)}"></span>Gemini Â· {gemini_label}</div>

                <div class="wow-chip"><span class="dot {dot(anth_s)}"></span>Anthropic Â· {anth_label}</div>

                <div class="wow-chip"><span class="dot {dot(grok_s)}"></span>xAI Grok Â· {grok_label}</div>

              </div>

            </div>

            <div style="text-align:right;">

              <div class="wow-badge">{st.session_state.settings["theme"]} Â· {st.session_state.settings["painter_style"]}</div><br>

              <div style="height:8px;"></div>

              <div class="wow-badge">Default: {st.session_state.settings["model"]} Â· max_tokens {st.session_state.settings["max_tokens"]}</div>

            </div>

          </div>

        </div>

        """,

        unsafe_allow_html=True,

    )





def render_sidebar():

    with st.sidebar:

        st.markdown(f"## {t('global_settings')}")



        # Theme mode

        theme_choice = st.radio(

            t("theme"),

            [t("light"), t("dark")],

            index=0 if st.session_state.settings["theme"] == "Light" else 1,

            horizontal=True,

        )

        st.session_state.settings["theme"] = "Light" if theme_choice == t("light") else "Dark"



        # Language

        lang_choice = st.radio(

            t("language"),

            [t("english"), t("zh_tw")],

            index=0 if st.session_state.settings["language"] == "en" else 1,

            horizontal=True,

        )

        st.session_state.settings["language"] = "en" if lang_choice == t("english") else "zh-tw"



        st.markdown("---")

        st.markdown(f"## {t('style_engine')}")



        c1, c2 = st.columns([4, 1])

        with c1:

            style = st.selectbox(

                t("painter_style"),

                PAINTER_STYLES_20,

                index=PAINTER_STYLES_20.index(st.session_state.settings["painter_style"])

                if st.session_state.settings["painter_style"] in PAINTER_STYLES_20

                else 0,

            )

        with c2:

            if st.button(f"ðŸŽ° {t('jackpot')}"):

                style = random.choice(PAINTER_STYLES_20)

                st.session_state.settings["painter_style"] = style

                st.rerun()



        st.session_state.settings["painter_style"] = style



        st.markdown("---")

        st.session_state.settings["model"] = st.selectbox(

            t("default_model"),

            ALL_MODELS,

            index=ALL_MODELS.index(st.session_state.settings["model"])

            if st.session_state.settings["model"] in ALL_MODELS

            else 0,

        )

        st.session_state.settings["max_tokens"] = st.number_input(

            t("default_max_tokens"),

            min_value=1000,

            max_value=120000,

            value=int(st.session_state.settings["max_tokens"]),

            step=1000,

        )

        st.session_state.settings["temperature"] = st.slider(

            t("temperature"),

            0.0,

            1.0,

            float(st.session_state.settings["temperature"]),

            0.05,

        )



        st.markdown("---")

        st.markdown(f"## {t('api_keys')}")



        # Show only inputs if env is missing; do not show env values

        keys = dict(st.session_state["api_keys"])



        # OpenAI

        if env_key_present("OPENAI_API_KEY"):

            st.caption(f"OpenAI: {t('active_env')}")

        else:

            keys["openai"] = st.text_input("OpenAI API Key", type="password", value=keys.get("openai", ""))



        # Gemini

        if env_key_present("GEMINI_API_KEY"):

            st.caption(f"Gemini: {t('active_env')}")

        else:

            keys["gemini"] = st.text_input("Gemini API Key", type="password", value=keys.get("gemini", ""))



        # Anthropic

        if env_key_present("ANTHROPIC_API_KEY"):

            st.caption(f"Anthropic: {t('active_env')}")

        else:

            keys["anthropic"] = st.text_input("Anthropic API Key", type="password", value=keys.get("anthropic", ""))



        # Grok

        if env_key_present("GROK_API_KEY"):

            st.caption(f"xAI Grok: {t('active_env')}")

        else:

            keys["grok"] = st.text_input("Grok (xAI) API Key", type="password", value=keys.get("grok", ""))



        st.session_state["api_keys"] = keys



        st.markdown("---")

        st.markdown(f"## {t('agents_catalog')}")

        uploaded_agents = st.file_uploader(t("upload_agents_yaml"), type=["yaml", "yml"])

        if uploaded_agents is not None:

            try:

                raw_content = uploaded_agents.read().decode("utf-8", errors="ignore")

                cfg = yaml.safe_load(raw_content) or {}

                

                # Check if standard

                if "agents" in cfg and isinstance(cfg["agents"], dict) and len(cfg["agents"]) > 0:

                    st.session_state["agents_cfg"] = ensure_fallback_agents(cfg)

                    st.success("Loaded valid agents.yaml.")

                    st.rerun()

                else:

                    st.info("Uploaded YAML does not match standard schema. Attempting to standardize with AI...")

                    # Call standardization

                    std_cfg = standardize_agents_yaml(raw_content)

                    if std_cfg and "agents" in std_cfg:

                        st.session_state["agents_cfg"] = ensure_fallback_agents(std_cfg)

                        st.success("Standardized and loaded agent configuration!")

                        st.rerun()

                    else:

                        st.error("Could not standardize the YAML file.")



            except Exception as e:

                st.error(f"Failed to process YAML: {e}")





def standardize_agents_yaml(raw_yaml_text: str) -> Dict[str, Any]:

    """

    Uses LLM to transform arbitrary YAML/Text into standard agents.yaml schema.

    """

    model = st.session_state.settings["model"]

    api_keys = st.session_state.get("api_keys", {})

    

    system_prompt = """

    You are a configuration Standardization Agent. 

    Convert the user's uploaded agent configuration (which might be in any format) into the STANDARD format used by this system.

    

    STANDARD FORMAT (YAML):

    agents:

      unique_agent_id_snake_case:

        name: "Human Readable Name"

        description: "Short description"

        category: "Category Name"

        model: "gpt-4o-mini" (or similar)

        temperature: 0.2

        max_tokens: 12000

        system_prompt: |

          The system prompt text...

        user_prompt_template: |

          Optional template...

          

    RULES:

    1. Extract as many agents as possible.

    2. Map fields as best as you can.

    3. Ensure valid YAML output.

    4. Output ONLY the YAML, no markdown code blocks.

    """

    

    try:

        out = call_llm(

            model=model,

            system_prompt=system_prompt,

            user_prompt=f"Raw Content:\n{raw_yaml_text}",

            max_tokens=8000,

            temperature=0.0,

            api_keys=api_keys

        )

        # Attempt to clean markdown block if present

        clean_out = out.replace("```yaml", "").replace("```", "").strip()

        data = yaml.safe_load(clean_out)

        return data

    except Exception as e:

        print(f"Standardization error: {e}")

        return {}





# ============================================================

# 10) Dashboard (WOW status indicators + interactive charts)

# ============================================================

def render_dashboard():

    # KPI row (always visible)

    hist = st.session_state["history"]

    df = pd.DataFrame(hist) if hist else pd.DataFrame(columns=["tab", "agent", "model", "tokens_est", "ts"])



    total_runs = int(len(df))

    tokens_total = int(df["tokens_est"].sum()) if total_runs else 0

    unique_models = int(df["model"].nunique()) if total_runs else 0



    token_budget = int(st.session_state.settings.get("token_budget_est", 250_000))

    token_ratio = min(1.0, (tokens_total / token_budget) if token_budget else 0.0)



    c1, c2, c3, c4 = st.columns([1.2, 1.2, 1.2, 1.4])

    with c1:

        st.markdown('<div class="wow-card">', unsafe_allow_html=True)

        st.markdown(f"**{t('agent_status')}**")

        status_row("Workspace", "idle" if total_runs == 0 else "active")

        st.markdown(f'<div class="wow-kpi">{total_runs}</div>', unsafe_allow_html=True)

        st.markdown(f'<div class="wow-muted">Total runs</div></div>', unsafe_allow_html=True)



    with c2:

        st.markdown('<div class="wow-card">', unsafe_allow_html=True)

        st.markdown(f"**{t('token_meter')}**")

        st.progress(token_ratio)

        st.markdown(

            f'<div class="wow-kpi">{tokens_total:,}</div><div class="wow-muted">Estimated tokens this session / budget {token_budget:,}</div></div>',

            unsafe_allow_html=True,

        )



    with c3:

        st.markdown('<div class="wow-card">', unsafe_allow_html=True)

        st.markdown("**Models**")

        st.markdown(f'<div class="wow-kpi">{unique_models}</div><div class="wow-muted">Unique models used</div></div>', unsafe_allow_html=True)



    with c4:

        st.markdown('<div class="wow-card">', unsafe_allow_html=True)

        st.markdown(f"**{t('api_pulse')}**")

        for p, name in [("openai", "OpenAI"), ("gemini", "Gemini"), ("anthropic", "Anthropic"), ("grok", "xAI Grok")]:

            s, label = api_status(p)

            dot_class = "dot-green" if s == "env" else ("dot-amber" if s == "session" else "dot-red")

            st.markdown(

                f'<div style="display:flex;align-items:center;gap:8px;margin:3px 0;">'

                f'<span class="dot {dot_class}"></span><b>{name}</b>'

                f'<span class="wow-badge">{label}</span></div>',

                unsafe_allow_html=True,

            )

        st.markdown("</div>", unsafe_allow_html=True)



    st.markdown("---")

    st.markdown(f"### {t('status_wall')}")



    if total_runs == 0:

        st.info("No runs yet. Start by running an agent, a workflow step, or a note magic.")

        return



    df2 = df.copy()

    df2["ts"] = pd.to_datetime(df2["ts"], errors="coerce")



    last = df2.sort_values("ts", ascending=False).iloc[0]

    severity_grad = "linear-gradient(135deg,#22c55e,#16a34a)"

    if int(last["tokens_est"]) > 40000:

        severity_grad = "linear-gradient(135deg,#f97316,#ea580c)"

    if int(last["tokens_est"]) > 80000:

        severity_grad = "linear-gradient(135deg,#ef4444,#b91c1c)"



    st.markdown(

        f"""

        <div class="wow-card" style="background:{severity_grad}; border: 1px solid rgba(255,255,255,0.22);">

          <div style="font-size:0.85rem; opacity:0.92; font-weight:900; letter-spacing:0.12em;">LATEST RUN</div>

          <div style="font-size:1.35rem; font-weight:900; margin-top:6px;">

            {last["tab"]} Â· {last["agent"]}

          </div>

          <div style="margin-top:6px; opacity:0.94;">

            Model: <b>{last["model"]}</b> Â· Tokens â‰ˆ <b>{int(last["tokens_est"]):,}</b><br>

            UTC: {str(last["ts"])}

          </div>

        </div>

        """,

        unsafe_allow_html=True,

    )



    cA, cB = st.columns(2)

    with cA:

        st.markdown("#### Runs by Tab")

        chart_tab = alt.Chart(df2).mark_bar().encode(

            x=alt.X("tab:N", sort="-y"),

            y="count():Q",

            color="tab:N",

            tooltip=["tab", "count()"],

        )

        st.altair_chart(chart_tab, use_container_width=True)



    with cB:

        st.markdown("#### Runs by Model")

        chart_model = alt.Chart(df2).mark_bar().encode(

            x=alt.X("model:N", sort="-y"),

            y="count():Q",

            color="model:N",

            tooltip=["model", "count()"],

        )

        st.altair_chart(chart_model, use_container_width=True)



    st.markdown("#### Token Usage Over Time")

    chart_time = alt.Chart(df2.dropna(subset=["ts"])).mark_line(point=True).encode(

        x="ts:T",

        y="tokens_est:Q",

        color="tab:N",

        tooltip=["ts", "tab", "agent", "model", "tokens_est"],

    )

    st.altair_chart(chart_time, use_container_width=True)



    st.markdown("#### Recent Activity")

    st.dataframe(df2.sort_values("ts", ascending=False).head(40), use_container_width=True)



    cX, cY = st.columns(2)

    with cX:

        if st.button(t("clear_history")):

            st.session_state["history"] = []

            st.rerun()

    with cY:

        csv_bytes = df2.to_csv(index=False).encode("utf-8")

        st.download_button(

            t("export_history"),

            data=csv_bytes,

            file_name="antigravity_history.csv",

            mime="text/csv",

        )





# ============================================================

# 11) Original Agent runner (single agent UI) - upgraded knobs + editable output

# ============================================================

def agent_run_ui(

    agent_id: str,

    tab_key: str,

    default_prompt: str,

    default_input_text: str = "",

    allow_model_override: bool = True,

    tab_label_for_history: Optional[str] = None,

):

    agents_cfg = st.session_state.get("agents_cfg", {})

    agents_dict = agents_cfg.get("agents", {})

    agent_cfg = agents_dict.get(agent_id, {})



    agent_name = agent_cfg.get("name", agent_id)



    # Defaults

    base_model = agent_cfg.get("model", st.session_state.settings["model"])

    base_max_tokens = int(agent_cfg.get("max_tokens", st.session_state.settings["max_tokens"]))

    system_prompt = agent_cfg.get("system_prompt", "")



    # supported_models (optional schema)

    supported = agent_cfg.get("supported_models", None)

    model_choices = ALL_MODELS

    if isinstance(supported, list) and supported:

        model_choices = [m for m in ALL_MODELS if m in supported] or ALL_MODELS



    status_key = f"{tab_key}_status"

    if status_key not in st.session_state:

        st.session_state[status_key] = "idle"



    # WOW status row

    status_row(agent_name, st.session_state[status_key])



    c1, c2, c3 = st.columns([2.2, 1.0, 1.0])

    with c1:

        user_prompt = st.text_area(

            t("prompt"),

            value=st.session_state.get(f"{tab_key}_prompt", default_prompt),

            height=170,

            key=f"{tab_key}_prompt",

        )

    with c2:

        model_index = model_choices.index(base_model) if base_model in model_choices else 0

        model = st.selectbox(

            t("model"),

            model_choices,

            index=model_index,

            disabled=not allow_model_override,

            key=f"{tab_key}_model",

        )

    with c3:

        max_tokens = st.number_input(

            "max_tokens",

            min_value=1000,

            max_value=120000,

            value=int(st.session_state.get(f"{tab_key}_max_tokens", base_max_tokens)),

            step=1000,

            key=f"{tab_key}_max_tokens",

        )



    input_text = st.text_area(

        t("input_text"),

        value=st.session_state.get(f"{tab_key}_input", default_input_text),

        height=240,

        key=f"{tab_key}_input",

    )



    run = st.button(t("run_agent"), key=f"{tab_key}_run")



    if run:

        st.session_state[status_key] = "thinking"

        status_row(agent_name, "thinking")

        api_keys = st.session_state.get("api_keys", {})

        user_full = f"{user_prompt}\n\n---\n\n{input_text}".strip()



        with st.spinner("Running..."):

            try:

                out = call_llm(

                    model=model,

                    system_prompt=system_prompt,

                    user_prompt=user_full,

                    max_tokens=int(max_tokens),

                    temperature=float(st.session_state.settings["temperature"]),

                    api_keys=api_keys,

                )

                st.session_state[f"{tab_key}_output"] = out

                st.session_state[status_key] = "done"



                token_est = est_tokens(user_full + out)

                log_event(

                    tab_label_for_history or tab_key,

                    agent_name,

                    model,

                    token_est,

                    meta={"agent_id": agent_id},

                )

            except Exception as e:

                st.session_state[status_key] = "error"

                st.error(f"Agent error: {e}")



    output = st.session_state.get(f"{tab_key}_output", "")

    view_mode = st.radio(

        t("view_mode"),

        [t("markdown"), t("plain_text")],

        horizontal=True,

        key=f"{tab_key}_viewmode",

    )

    edited = st.text_area(

        f"{t('output')} ({'Markdown' if view_mode == t('markdown') else 'Text'}, editable)",

        value=output,

        height=280,

        key=f"{tab_key}_output_edited",

    )

    st.session_state[f"{tab_key}_output_edited_value"] = edited





# ============================================================

# 12) NEW: Agent Workflow Studio (step-by-step, editable handoff)

# ============================================================

def workflow_default_steps() -> List[Dict[str, Any]]:

    """

    A recommended workflow; user can edit each step before running.

    """

    return [

        {

            "agent_id": "pdf_to_markdown_agent",

            "name": "PDF â†’ Markdown Agent",

            "model": st.session_state.settings["model"],

            "max_tokens": st.session_state.settings["max_tokens"],

            "prompt": "Convert the following content into clean structured Markdown. Preserve headings/lists/tables. Do not add facts.",

        },

        {

            "agent_id": "fda_510k_intel_agent",

            "name": "510(k) Intelligence Agent",

            "model": st.session_state.settings["model"],

            "max_tokens": st.session_state.settings["max_tokens"],

            "prompt": "Analyze the provided context and produce a reviewer-oriented report with tables and risks. Keep it grounded in input.",

        },

    ]





def render_workflow_studio():

    st.markdown(f"## {t('workflow_studio')}")

    st.caption("Run agents step-by-step. Edit prompt/model/max_tokens BEFORE each step. Edit output, then pass to next agent.")



    agents_dict = st.session_state["agents_cfg"].get("agents", {})



    # Initialize workflow steps if empty

    wf = st.session_state["workflow"]

    if not wf["steps"]:

        wf["steps"] = workflow_default_steps()

        wf["outputs"] = [""] * len(wf["steps"])

        wf["statuses"] = ["idle"] * len(wf["steps"])

        wf["cursor"] = 0



    # Controls

    c0, c1, c2, c3 = st.columns([1.2, 1.2, 1.2, 1.6])

    with c0:

        if st.button(t("load_defaults")):

            wf["steps"] = workflow_default_steps()

            wf["outputs"] = [""] * len(wf["steps"])

            wf["statuses"] = ["idle"] * len(wf["steps"])

            wf["cursor"] = 0

            wf["input"] = ""

            st.rerun()



    with c1:

        if st.button(t("add_step")):

            wf["steps"].append(

                {

                    "agent_id": "note_organizer",

                    "name": "Note Organizer",

                    "model": st.session_state.settings["model"],

                    "max_tokens": st.session_state.settings["max_tokens"],

                    "prompt": "Organize into structured Markdown. Do not add new facts.",

                }

            )

            wf["outputs"].append("")

            wf["statuses"].append("idle")

            st.rerun()



    with c2:

        if st.button(t("remove_step")):

            if len(wf["steps"]) > 1:

                wf["steps"].pop()

                wf["outputs"].pop()

                wf["statuses"].pop()

                wf["cursor"] = min(wf["cursor"], len(wf["steps"]) - 1)

                st.rerun()



    with c3:

        wf["cursor"] = st.number_input(

            "Active step index",

            min_value=0,

            max_value=max(0, len(wf["steps"]) - 1),

            value=int(wf["cursor"]),

            step=1,

        )



    st.markdown("---")



    # Workflow Input

    st.markdown(f"### {t('workflow_input')}")

    wf["input"] = st.text_area(

        t("input_text"),

        value=wf.get("input", ""),

        height=200,

        key="wf_input_text",

    )



    st.markdown("---")



    # Step list editor (simple, robust)

    st.markdown(f"### {t('step')}s")

    for idx, step in enumerate(wf["steps"]):

        agent_id = step.get("agent_id", "")

        agent_cfg = agents_dict.get(agent_id, {})

        agent_name = step.get("name") or agent_cfg.get("name") or agent_id



        with st.expander(f"{t('step')} {idx+1}: {agent_name}  Â·  ({agent_id})", expanded=(idx == wf["cursor"])):

            wf["statuses"][idx] = wf["statuses"][idx] if idx < len(wf["statuses"]) else "idle"

            status_row(f"{agent_name}", wf["statuses"][idx])



            # Resolve supported models if present

            supported = agent_cfg.get("supported_models", None)

            model_choices = ALL_MODELS

            if isinstance(supported, list) and supported:

                model_choices = [m for m in ALL_MODELS if m in supported] or ALL_MODELS



            cA, cB = st.columns([1.2, 1.2])

            with cA:

                step["agent_id"] = st.selectbox(

                    "agent_id",

                    sorted(list(agents_dict.keys())),

                    index=sorted(list(agents_dict.keys())).index(agent_id) if agent_id in agents_dict else 0,

                    key=f"wf_agent_{idx}",

                )

            with cB:

                # update agent cfg after selection

                agent_id = step["agent_id"]

                agent_cfg = agents_dict.get(agent_id, {})

                supported = agent_cfg.get("supported_models", None)

                model_choices = ALL_MODELS

                if isinstance(supported, list) and supported:

                    model_choices = [m for m in ALL_MODELS if m in supported] or ALL_MODELS



                step["model"] = st.selectbox(

                    t("model"),

                    model_choices,

                    index=model_choices.index(step.get("model")) if step.get("model") in model_choices else 0,

                    key=f"wf_model_{idx}",

                )



            cC, cD = st.columns([1.2, 1.2])

            with cC:

                step["max_tokens"] = st.number_input(

                    "max_tokens",

                    min_value=1000,

                    max_value=120000,

                    value=int(step.get("max_tokens", st.session_state.settings["max_tokens"])),

                    step=1000,

                    key=f"wf_mt_{idx}",

                )

            with cD:

                step["name"] = st.text_input(

                    "Display name",

                    value=str(step.get("name") or agent_cfg.get("name") or agent_id),

                    key=f"wf_name_{idx}",

                )



            step["prompt"] = st.text_area(

                t("prompt"),

                value=step.get("prompt", ""),

                height=150,

                key=f"wf_prompt_{idx}",

            )



            # Determine the input to this step:

            if idx == 0:

                step_input_default = wf.get("input", "")

            else:

                # previous output (editable)

                step_input_default = wf["outputs"][idx - 1] or ""



            step_input = st.text_area(

                f"{t('input_text')} (Step {idx+1})",

                value=step_input_default,

                height=180,

                key=f"wf_input_{idx}",

            )



            # Run buttons

            cR1, cR2 = st.columns([1.0, 1.0])

            run_step = cR1.button(f"â–¶ {t('run_step')} {idx+1}", key=f"wf_run_{idx}")

            run_next = cR2.button(f"â­ {t('run_next')} {idx+1}", key=f"wf_run_next_{idx}")



            if run_step or run_next:

                wf["cursor"] = idx

                wf["statuses"][idx] = "thinking"



                agent_cfg = agents_dict.get(agent_id, {})

                system_prompt = agent_cfg.get("system_prompt", "")



                user_prompt = (step.get("prompt") or "").strip()

                user_full = (user_prompt + "\n\n---\n\n" + (step_input or "")).strip()



                try:

                    with st.spinner(f"Running step {idx+1}..."):

                        out = call_llm(

                            model=step["model"],

                            system_prompt=system_prompt,

                            user_prompt=user_full,

                            max_tokens=int(step["max_tokens"]),

                            temperature=float(st.session_state.settings["temperature"]),

                            api_keys=st.session_state.get("api_keys", {}),

                        )

                    wf["outputs"][idx] = out

                    wf["statuses"][idx] = "done"



                    log_event(

                        tab="Workflow Studio",

                        agent=step.get("name", agent_id),

                        model=step["model"],

                        tokens_est=est_tokens(user_full + out),

                        meta={"agent_id": agent_id, "workflow_step": idx + 1},

                    )



                    # If "run_next", jump cursor

                    if run_next and idx < len(wf["steps"]) - 1:

                        wf["cursor"] = idx + 1

                        st.rerun()



                except Exception as e:

                    wf["statuses"][idx] = "error"

                    st.error(f"Workflow step error: {e}")



            # Output (editable, pass to next)

            st.markdown(f"**{t('workflow_output')} (editable; becomes input to next step)**")

            view = st.radio(

                t("view_mode"),

                [t("markdown"), t("plain_text")],

                horizontal=True,

                key=f"wf_view_{idx}",

            )

            wf["outputs"][idx] = st.text_area(

                f"Output (Step {idx+1})",

                value=wf["outputs"][idx] or "",

                height=240,

                key=f"wf_out_{idx}",

            )



    st.markdown("---")

    final_out = wf["outputs"][-1] if wf["outputs"] else ""

    if final_out.strip():

        st.download_button(

            t("download_md"),

            data=final_out.encode("utf-8"),

            file_name="workflow_output.md",

            mime="text/markdown",

        )





# ============================================================

# 13) Original tabs (TW Premarket / 510k / PDF->MD / Pipeline)

#     Kept largely as-is, with minor label tweaks.

# ============================================================



LABELS = {

    "Dashboard": {"en": "Dashboard", "zh-tw": "å„€è¡¨æ¿"},

    "TW Premarket": {"en": "TW Premarket Application", "zh-tw": "ç¬¬äºŒã€ä¸‰ç­‰ç´šé†«ç™‚å™¨ææŸ¥é©—ç™»è¨˜"},

    "510k_tab": {"en": "510(k) Intelligence", "zh-tw": "510(k) æ™ºèƒ½åˆ†æž"},

    "PDF â†’ Markdown": {"en": "PDF â†’ Markdown", "zh-tw": "PDF â†’ Markdown"},

    "Checklist & Report": {"en": "510(k) Review Pipeline", "zh-tw": "510(k) å¯©æŸ¥å…¨æµç¨‹"},

    "Note Keeper & Magics": {"en": "Note Keeper & Magics", "zh-tw": "ç­†è¨˜åŠ©æ‰‹èˆ‡é­”æ³•"},

    "Agents Config": {"en": "Agents Config Studio", "zh-tw": "ä»£ç†è¨­å®šå·¥ä½œå®¤"},

    "Workflow Studio": {"en": "Agent Workflow Studio", "zh-tw": "ä»£ç†å·¥ä½œæµå·¥ä½œå®¤"},

}





def tl(key: str) -> str:

    return LABELS.get(key, {}).get(lang_code(), key)





# -----------------------------

# TW schema helpers (kept from original)

# -----------------------------

TW_APP_FIELDS = [

    "doc_no", "e_no", "apply_date", "case_type", "device_category", "case_kind",

    "origin", "product_class", "similar", "replace_flag", "prior_app_no",

    "name_zh", "name_en", "indications", "spec_comp",

    "main_cat", "item_code", "item_name",

    "uniform_id", "firm_name", "firm_addr",

    "resp_name", "contact_name", "contact_tel", "contact_fax", "contact_email",

    "confirm_match", "cert_raps", "cert_ahwp", "cert_other",

    "manu_type", "manu_name", "manu_country", "manu_addr", "manu_note",

    "auth_applicable", "auth_desc",

    "cfs_applicable", "cfs_desc",

    "qms_applicable", "qms_desc",

    "similar_info", "labeling_info", "tech_file_info",

    "preclinical_info", "preclinical_replace",

    "clinical_just", "clinical_info",

]





def build_tw_app_dict_from_session() -> dict:

    s = st.session_state

    apply_date = s.get("tw_apply_date")

    apply_date_str = apply_date.strftime("%Y-%m-%d") if apply_date else ""

    return {

        "doc_no": s.get("tw_doc_no", ""),

        "e_no": s.get("tw_e_no", ""),

        "apply_date": apply_date_str,

        "case_type": s.get("tw_case_type", ""),

        "device_category": s.get("tw_device_category", ""),

        "case_kind": s.get("tw_case_kind", ""),

        "origin": s.get("tw_origin", ""),

        "product_class": s.get("tw_product_class", ""),

        "similar": s.get("tw_similar", ""),

        "replace_flag": s.get("tw_replace_flag", ""),

        "prior_app_no": s.get("tw_prior_app_no", ""),

        "name_zh": s.get("tw_dev_name_zh", ""),

        "name_en": s.get("tw_dev_name_en", ""),

        "indications": s.get("tw_indications", ""),

        "spec_comp": s.get("tw_spec_comp", ""),

        "main_cat": s.get("tw_main_cat", ""),

        "item_code": s.get("tw_item_code", ""),

        "item_name": s.get("tw_item_name", ""),

        "uniform_id": s.get("tw_uniform_id", ""),

        "firm_name": s.get("tw_firm_name", ""),

        "firm_addr": s.get("tw_firm_addr", ""),

        "resp_name": s.get("tw_resp_name", ""),

        "contact_name": s.get("tw_contact_name", ""),

        "contact_tel": s.get("tw_contact_tel", ""),

        "contact_fax": s.get("tw_contact_fax", ""),

        "contact_email": s.get("tw_contact_email", ""),

        "confirm_match": bool(s.get("tw_confirm_match", False)),

        "cert_raps": bool(s.get("tw_cert_raps", False)),

        "cert_ahwp": bool(s.get("tw_cert_ahwp", False)),

        "cert_other": s.get("tw_cert_other", ""),

        "manu_type": s.get("tw_manu_type", ""),

        "manu_name": s.get("tw_manu_name", ""),

        "manu_country": s.get("tw_manu_country", ""),

        "manu_addr": s.get("tw_manu_addr", ""),

        "manu_note": s.get("tw_manu_note", ""),

        "auth_applicable": s.get("tw_auth_app", ""),

        "auth_desc": s.get("tw_auth_desc", ""),

        "cfs_applicable": s.get("tw_cfs_app", ""),

        "cfs_desc": s.get("tw_cfs_desc", ""),

        "qms_applicable": s.get("tw_qms_app", ""),

        "qms_desc": s.get("tw_qms_desc", ""),

        "similar_info": s.get("tw_similar_info", ""),

        "labeling_info": s.get("tw_labeling_info", ""),

        "tech_file_info": s.get("tw_tech_file_info", ""),

        "preclinical_info": s.get("tw_preclinical_info", ""),

        "preclinical_replace": s.get("tw_preclinical_replace", ""),

        "clinical_just": s.get("tw_clinical_app", ""),

        "clinical_info": s.get("tw_clinical_info", ""),

    }





def apply_tw_app_dict_to_session(data: dict):

    s = st.session_state

    s["tw_doc_no"] = data.get("doc_no", "")

    s["tw_e_no"] = data.get("e_no", "")

    from datetime import date

    try:

        if data.get("apply_date"):

            y, m, d = map(int, str(data["apply_date"]).split("-"))

            s["tw_apply_date"] = date(y, m, d)

    except Exception:

        pass

    s["tw_case_type"] = data.get("case_type", "")

    s["tw_device_category"] = data.get("device_category", "")

    s["tw_case_kind"] = data.get("case_kind", "")

    s["tw_origin"] = data.get("origin", "")

    s["tw_product_class"] = data.get("product_class", "")

    s["tw_similar"] = data.get("similar", "")

    s["tw_replace_flag"] = data.get("replace_flag", "")

    s["tw_prior_app_no"] = data.get("prior_app_no", "")

    s["tw_dev_name_zh"] = data.get("name_zh", "")

    s["tw_dev_name_en"] = data.get("name_en", "")

    s["tw_indications"] = data.get("indications", "")

    s["tw_spec_comp"] = data.get("spec_comp", "")

    s["tw_main_cat"] = data.get("main_cat", "")

    s["tw_item_code"] = data.get("item_code", "")

    s["tw_item_name"] = data.get("item_name", "")

    s["tw_uniform_id"] = data.get("uniform_id", "")

    s["tw_firm_name"] = data.get("firm_name", "")

    s["tw_firm_addr"] = data.get("firm_addr", "")

    s["tw_resp_name"] = data.get("resp_name", "")

    s["tw_contact_name"] = data.get("contact_name", "")

    s["tw_contact_tel"] = data.get("contact_tel", "")

    s["tw_contact_fax"] = data.get("contact_fax", "")

    s["tw_contact_email"] = data.get("contact_email", "")

    s["tw_confirm_match"] = bool(data.get("confirm_match", False))

    s["tw_cert_raps"] = bool(data.get("cert_raps", False))

    s["tw_cert_ahwp"] = bool(data.get("cert_ahwp", False))

    s["tw_cert_other"] = data.get("cert_other", "")

    s["tw_manu_type"] = data.get("manu_type", "")

    s["tw_manu_name"] = data.get("manu_name", "")

    s["tw_manu_country"] = data.get("manu_country", "")

    s["tw_manu_addr"] = data.get("manu_addr", "")

    s["tw_manu_note"] = data.get("manu_note", "")

    s["tw_auth_app"] = data.get("auth_applicable", "")

    s["tw_auth_desc"] = data.get("auth_desc", "")

    s["tw_cfs_app"] = data.get("cfs_applicable", "")

    s["tw_cfs_desc"] = data.get("cfs_desc", "")

    s["tw_qms_app"] = data.get("qms_applicable", "")

    s["tw_qms_desc"] = data.get("qms_desc", "")

    s["tw_similar_info"] = data.get("similar_info", "")

    s["tw_labeling_info"] = data.get("labeling_info", "")

    s["tw_tech_file_info"] = data.get("tech_file_info", "")

    s["tw_preclinical_info"] = data.get("preclinical_info", "")

    s["tw_preclinical_replace"] = data.get("preclinical_replace", "")

    s["tw_clinical_app"] = data.get("clinical_just", "")

    s["tw_clinical_info"] = data.get("clinical_info", "")





def standardize_tw_app_info_with_llm(raw_obj) -> dict:

    api_keys = st.session_state.get("api_keys", {})

    model = "gemini-2.5-flash"

    if not get_api_key("gemini", api_keys):

        raise RuntimeError("No Gemini API key available for standardizing application info.")



    raw_json = json.dumps(raw_obj, ensure_ascii=False, indent=2)

    fields_str = ", ".join(TW_APP_FIELDS)



    system_prompt = f"""

You are a data normalization assistant for a Taiwanese TFDA medical device premarket application.



Map arbitrary JSON/CSV key/value data into a STANDARD JSON object with EXACT keys:

{fields_str}



Rules:

- Output MUST be a single JSON object (no markdown, no comments).

- Every key above MUST appear.

- If missing, use "" or false for boolean-like fields.

- Do NOT invent facts.

- apply_date format: YYYY-MM-DD if inferable, else "".

"""



    out = call_llm(

        model=model,

        system_prompt=system_prompt,

        user_prompt=f"Raw data:\n{raw_json}",

        max_tokens=4000,

        temperature=0.1,

        api_keys=api_keys,

    )



    try:

        data = json.loads(out)

    except json.JSONDecodeError:

        start = out.find("{")

        end = out.rfind("}")

        if start != -1 and end != -1 and end > start:

            data = json.loads(out[start : end + 1])

        else:

            raise RuntimeError("LLM did not return valid JSON.")

    if not isinstance(data, dict):

        raise RuntimeError("Standardized output is not an object.")

    for k in TW_APP_FIELDS:

        if k not in data:

            data[k] = False if k in ("confirm_match", "cert_raps", "cert_ahwp") else ""

    return data





def compute_tw_app_completeness() -> float:

    s = st.session_state

    required_keys = [

        "tw_e_no", "tw_case_type", "tw_device_category",

        "tw_origin", "tw_product_class",

        "tw_dev_name_zh", "tw_dev_name_en",

        "tw_uniform_id", "tw_firm_name", "tw_firm_addr",

        "tw_resp_name", "tw_contact_name", "tw_contact_tel",

        "tw_contact_email",

        "tw_manu_name", "tw_manu_addr",

    ]

    filled = 0

    for k in required_keys:

        v = s.get(k, "")

        if isinstance(v, str):

            filled += 1 if v.strip() else 0

        else:

            filled += 1 if v else 0

    return filled / len(required_keys) if required_keys else 0.0





def render_tw_premarket_tab():

    st.markdown(f"## {tl('TW Premarket')}")



    st.markdown(

        """

        <div class="wow-card">

          <div style="font-weight:900; font-size:1.05rem;">Quick Guide</div>

          <div class="wow-muted" style="margin-top:6px;">

            Step 1: Fill/import application fields â†’ Step 2: Provide screening guidance â†’ Step 3: Run screening agent â†’ Step 4: Improve doc with helper agent.

          </div>

        </div>

        """,

        unsafe_allow_html=True,

    )



    st.markdown("### Application Info åŒ¯å…¥ / åŒ¯å‡º (JSON / CSV)")

    col_ie1, col_ie2 = st.columns(2)

    with col_ie1:

        app_file = st.file_uploader("Upload Application Info (JSON / CSV)", type=["json", "csv"], key="tw_app_upload")

        if app_file is not None:

            try:

                if app_file.name.lower().endswith(".json"):

                    raw_data = json.load(app_file)

                else:

                    df = pd.read_csv(app_file)

                    raw_data = df.to_dict(orient="records")[0] if len(df) else None



                if raw_data is not None:

                    if isinstance(raw_data, dict) and all(k in raw_data for k in TW_APP_FIELDS):

                        standardized = raw_data

                    else:

                        with st.spinner("ä½¿ç”¨ LLM å°‡æ¬„ä½è½‰ç‚ºæ¨™æº– TFDA ç”³è«‹æ›¸æ ¼å¼..."):

                            standardized = standardize_tw_app_info_with_llm(raw_data)

                    apply_tw_app_dict_to_session(standardized)

                    st.session_state["tw_app_last_loaded"] = standardized

                    st.success("å·²å¥—ç”¨è‡³ç”³è«‹è¡¨å–®ã€‚")

                    st.rerun()

            except Exception as e:

                st.error(f"ä¸Šå‚³æˆ–æ¨™æº–åŒ–å¤±æ•—ï¼š{e}")



    with col_ie2:

        app_dict = build_tw_app_dict_from_session()

        st.download_button(

            "Download JSON",

            data=json.dumps(app_dict, ensure_ascii=False, indent=2).encode("utf-8"),

            file_name="tw_premarket_application.json",

            mime="application/json",

        )

        st.download_button(

            "Download CSV",

            data=pd.DataFrame([app_dict]).to_csv(index=False).encode("utf-8"),

            file_name="tw_premarket_application.csv",

            mime="text/csv",

        )



    if "tw_app_last_loaded" in st.session_state:

        st.markdown("**æœ€è¿‘è¼‰å…¥/æ¨™æº–åŒ–ä¹‹ Application JSON é è¦½**")

        st.json(st.session_state["tw_app_last_loaded"], expanded=False)



    st.markdown("---")



    completeness = compute_tw_app_completeness()

    pct = int(completeness * 100)

    if pct >= 80:

        card_grad = "linear-gradient(135deg,#22c55e,#16a34a)"

        txt = "ç”³è«‹åŸºæœ¬æ¬„ä½å®Œæˆåº¦é«˜ï¼Œé©åˆé€²è¡Œé å¯©ã€‚"

    elif pct >= 50:

        card_grad = "linear-gradient(135deg,#f97316,#ea580c)"

        txt = "éƒ¨åˆ†é—œéµæ¬„ä½ä»å¾…è£œé½Šï¼Œå»ºè­°è£œè¶³å¾Œå†é€é å¯©ã€‚"

    else:

        card_grad = "linear-gradient(135deg,#ef4444,#b91c1c)"

        txt = "å¤šæ•¸åŸºæœ¬æ¬„ä½å°šæœªå¡«å¯«ï¼Œè«‹å…ˆå……å¯¦ç”³è«‹è³‡è¨Šã€‚"



    st.markdown(

        f"""

        <div class="wow-card" style="background:{card_grad}; border: 1px solid rgba(255,255,255,0.22);">

          <div style="font-weight:900; letter-spacing:0.12em; opacity:0.95;">APPLICATION COMPLETENESS</div>

          <div style="font-size:1.6rem; font-weight:900; margin-top:6px;">{pct}%</div>

          <div style="margin-top:6px; opacity:0.95;">{txt}</div>

        </div>

        """,

        unsafe_allow_html=True,

    )

    st.progress(completeness)



    st.markdown("### Step 1 â€“ ç·šä¸Šå¡«å¯«ç”³è«‹æ›¸ï¼ˆè‰ç¨¿ï¼‰")

    # (Original form kept; same as provided, trimmed only minimally for length safety)



    if "tw_app_status" not in st.session_state:

        st.session_state["tw_app_status"] = "pending"

    status_row("ç”³è«‹æ›¸å¡«å¯«", st.session_state["tw_app_status"])



    # --- Basic info

    col_a1, col_a2, col_a3 = st.columns(3)

    with col_a1:

        doc_no = st.text_input("å…¬æ–‡æ–‡è™Ÿ", key="tw_doc_no")

        e_no = st.text_input("é›»å­æµæ°´è™Ÿ", value=st.session_state.get("tw_e_no", "MDE"), key="tw_e_no")

    with col_a2:

        apply_date = st.date_input("ç”³è«‹æ—¥", key="tw_apply_date")

        case_type = st.selectbox(

            "æ¡ˆä»¶é¡žåž‹*",

            ["ä¸€èˆ¬ç”³è«‹æ¡ˆ", "åŒä¸€ç”¢å“ä¸åŒå“å", "å°ˆä¾›å¤–éŠ·", "è¨±å¯è­‰æœ‰æ•ˆæœŸé™å±†è‡³å¾Œå…­å€‹æœˆå…§é‡æ–°ç”³è«‹"],

            key="tw_case_type",

        )

    with col_a3:

        device_category = st.selectbox("é†«ç™‚å™¨æé¡žåž‹*", ["ä¸€èˆ¬é†«æ", "é«”å¤–è¨ºæ–·å™¨æ(IVD)"], key="tw_device_category")

        case_kind = st.selectbox("æ¡ˆä»¶ç¨®é¡ž*", ["æ–°æ¡ˆ", "è®Šæ›´æ¡ˆ", "å±•å»¶æ¡ˆ"], index=0, key="tw_case_kind")



    col_a4, col_a5, col_a6 = st.columns(3)

    with col_a4:

        origin = st.selectbox("ç”¢åœ°*", ["åœ‹ç”¢", "è¼¸å…¥", "é™¸è¼¸"], key="tw_origin")

    with col_a5:

        product_class = st.selectbox("ç”¢å“ç­‰ç´š*", ["ç¬¬äºŒç­‰ç´š", "ç¬¬ä¸‰ç­‰ç´š"], key="tw_product_class")

    with col_a6:

        similar = st.selectbox("æœ‰ç„¡é¡žä¼¼å“*", ["æœ‰", "ç„¡", "å…¨çƒé¦–å‰µ"], key="tw_similar")



    col_a7, col_a8 = st.columns(2)

    with col_a7:

        replace_flag = st.radio(

            "æ˜¯å¦å‹¾é¸ã€Œæ›¿ä»£è‡¨åºŠå‰æ¸¬è©¦åŠåŽŸå» å“è³ªç®¡åˆ¶è³‡æ–™ã€ï¼Ÿ*",

            ["å¦", "æ˜¯"],

            index=0 if st.session_state.get("tw_replace_flag", "å¦") == "å¦" else 1,

            key="tw_replace_flag",

        )

    with col_a8:

        prior_app_no = st.text_input("ï¼ˆéžé¦–æ¬¡ç”³è«‹ï¼‰å‰æ¬¡ç”³è«‹æ¡ˆè™Ÿ", key="tw_prior_app_no")



    # --- Device info

    col_b1, col_b2 = st.columns(2)

    with col_b1:

        name_zh = st.text_input("é†«ç™‚å™¨æä¸­æ–‡åç¨±*", key="tw_dev_name_zh")

        name_en = st.text_input("é†«ç™‚å™¨æè‹±æ–‡åç¨±*", key="tw_dev_name_en")

    with col_b2:

        indications = st.text_area("æ•ˆèƒ½ã€ç”¨é€”æˆ–é©æ‡‰ç—‡èªªæ˜Ž", value=st.session_state.get("tw_indications", "è©³å¦‚æ ¸å®šä¹‹ä¸­æ–‡èªªæ˜Žæ›¸"), key="tw_indications")

        spec_comp = st.text_area("åž‹è™Ÿã€è¦æ ¼æˆ–ä¸»è¦æˆåˆ†èªªæ˜Ž", value=st.session_state.get("tw_spec_comp", "è©³å¦‚æ ¸å®šä¹‹ä¸­æ–‡èªªæ˜Žæ›¸"), key="tw_spec_comp")



    col_b3, col_b4, col_b5 = st.columns(3)

    with col_b3:

        main_cat = st.selectbox("ä¸»é¡žåˆ¥", ["", "A.è‡¨åºŠåŒ–å­¸åŠè‡¨åºŠæ¯’ç†å­¸", "B.è¡€æ¶²å­¸åŠç—…ç†å­¸", "C.å…ç–«å­¸åŠå¾®ç”Ÿç‰©å­¸",

                                      "D.éº»é†‰å­¸", "E.å¿ƒè‡Ÿè¡€ç®¡é†«å­¸", "F.ç‰™ç§‘å­¸", "G.è€³é¼»å–‰ç§‘å­¸", "H.èƒƒè…¸ç—…ç§‘å­¸åŠæ³Œå°¿ç§‘å­¸",

                                      "I.ä¸€èˆ¬åŠæ•´å½¢å¤–ç§‘æ‰‹è¡“", "J.ä¸€èˆ¬é†«é™¢åŠå€‹äººä½¿ç”¨è£ç½®", "K.ç¥žç¶“ç§‘å­¸", "L.å©¦ç”¢ç§‘å­¸", "M.çœ¼ç§‘å­¸",

                                      "N.éª¨ç§‘å­¸", "O.ç‰©ç†é†«å­¸ç§‘å­¸", "P.æ”¾å°„å­¸ç§‘å­¸"], key="tw_main_cat")

    with col_b4:

        item_code = st.text_input("åˆ†ç´šå“é …ä»£ç¢¼ï¼ˆä¾‹ï¼šA.1225ï¼‰", key="tw_item_code")

    with col_b5:

        item_name = st.text_input("åˆ†ç´šå“é …åç¨±ï¼ˆä¾‹ï¼šè‚Œæ°¨é…¸é…è©¦é©—ç³»çµ±ï¼‰", key="tw_item_name")



    # --- Firm info

    col_c1, col_c2 = st.columns(2)

    with col_c1:

        uniform_id = st.text_input("çµ±ä¸€ç·¨è™Ÿ*", key="tw_uniform_id")

        firm_name = st.text_input("é†«ç™‚å™¨æå•†åç¨±*", key="tw_firm_name")

        firm_addr = st.text_area("é†«ç™‚å™¨æå•†åœ°å€*", height=80, key="tw_firm_addr")

    with col_c2:

        resp_name = st.text_input("è² è²¬äººå§“å*", key="tw_resp_name")

        contact_name = st.text_input("è¯çµ¡äººå§“å*", key="tw_contact_name")

        contact_tel = st.text_input("é›»è©±*", key="tw_contact_tel")

        contact_fax = st.text_input("è¯çµ¡äººå‚³çœŸ", key="tw_contact_fax")

        contact_email = st.text_input("é›»å­éƒµä»¶*", key="tw_contact_email")



    confirm_match = st.checkbox(

        "æˆ‘å·²ç¢ºèªä¸Šè¿°è³‡æ–™èˆ‡æœ€æ–°ç‰ˆé†«ç™‚å™¨æå•†è­‰ç…§è³‡è¨Š(åç¨±ã€åœ°å€ã€è² è²¬äºº)ç›¸ç¬¦",

        key="tw_confirm_match",

    )



    col_c3, col_c4 = st.columns(2)

    with col_c3:

        cert_raps = st.checkbox("RAPS", key="tw_cert_raps")

        cert_ahwp = st.checkbox("AHWP", key="tw_cert_ahwp")

    with col_c4:

        cert_other = st.text_input("å…¶å®ƒï¼Œè«‹æ•˜æ˜Ž", key="tw_cert_other")



    # --- Manufacturer

    manu_type = st.radio(

        "è£½é€ æ–¹å¼",

        ["å–®ä¸€è£½é€ å» ", "å…¨éƒ¨è£½ç¨‹å§”è¨—è£½é€ ", "å§”è¨—éžå…¨éƒ¨è£½ç¨‹ä¹‹è£½é€ /åŒ…è£/è²¼æ¨™/æ»…èŒåŠæœ€çµ‚é©—æ”¾"],

        index=0,

        key="tw_manu_type",

    )

    col_d1, col_d2 = st.columns(2)

    with col_d1:

        manu_name = st.text_input("è£½é€ å» åç¨±*", key="tw_manu_name")

        manu_country = st.selectbox(

            "è£½é€ åœ‹åˆ¥*",

            ["TAIWANï¼Œ ROC", "UNITED STATES", "EU (Member State)", "JAPAN", "CHINA", "KOREAï¼Œ REPUBLIC OF", "OTHER"],

            key="tw_manu_country",

        )

    with col_d2:

        manu_addr = st.text_area("è£½é€ å» åœ°å€*", height=80, key="tw_manu_addr")

        manu_note = st.text_area("è£½é€ å» ç›¸é—œèªªæ˜Ž", height=80, key="tw_manu_note")



    with st.expander("é™„ä»¶æ‘˜è¦ï¼ˆå¯é¸å¡«ï¼‰", expanded=False):

        auth_applicable = st.selectbox("åŽŸå» æŽˆæ¬Šç™»è¨˜æ›¸", ["ä¸é©ç”¨", "é©ç”¨"], key="tw_auth_app")

        auth_desc = st.text_area("åŽŸå» æŽˆæ¬Šç™»è¨˜æ›¸è³‡æ–™èªªæ˜Ž", height=80, key="tw_auth_desc")



        cfs_applicable = st.selectbox("å‡ºç”¢åœ‹è£½å”®è­‰æ˜Ž", ["ä¸é©ç”¨", "é©ç”¨"], key="tw_cfs_app")

        cfs_desc = st.text_area("å‡ºç”¢åœ‹è£½å”®è­‰æ˜Žè³‡æ–™èªªæ˜Ž", height=80, key="tw_cfs_desc")



        qms_applicable = st.selectbox("QMS/QSD", ["ä¸é©ç”¨", "é©ç”¨"], key="tw_qms_app")

        qms_desc = st.text_area("QMS/QSD è³‡æ–™èªªæ˜Ž", height=80, key="tw_qms_desc")



        similar_info = st.text_area("é¡žä¼¼å“èˆ‡æ¯”è¼ƒè¡¨æ‘˜è¦", height=80, key="tw_similar_info")

        labeling_info = st.text_area("æ¨™ç±¤ã€èªªæ˜Žæ›¸æˆ–åŒ…è£æ“¬ç¨¿é‡é»ž", height=100, key="tw_labeling_info")

        tech_file_info = st.text_area("æŠ€è¡“æª”æ¡ˆæ‘˜è¦", height=120, key="tw_tech_file_info")

        preclinical_info = st.text_area("è‡¨åºŠå‰æ¸¬è©¦èˆ‡å“è³ªç®¡åˆ¶æ‘˜è¦", height=140, key="tw_preclinical_info")

        preclinical_replace = st.text_area("æ›¿ä»£è‡¨åºŠå‰æ¸¬è©¦è³‡æ–™ä¹‹èªªæ˜Ž", height=100, key="tw_preclinical_replace")

        clinical_just = st.selectbox("è‡¨åºŠè­‰æ“šæ˜¯å¦é©ç”¨ï¼Ÿ", ["ä¸é©ç”¨", "é©ç”¨"], key="tw_clinical_app")

        clinical_info = st.text_area("è‡¨åºŠè­‰æ“šæ‘˜è¦", height=140, key="tw_clinical_info")



    if st.button("ç”Ÿæˆç”³è«‹æ›¸ Markdown è‰ç¨¿", key="tw_generate_md_btn"):

        missing = []

        for label, val in [

            ("é›»å­æµæ°´è™Ÿ", e_no),

            ("æ¡ˆä»¶é¡žåž‹", case_type),

            ("é†«ç™‚å™¨æé¡žåž‹", device_category),

            ("ç”¢åœ°", origin),

            ("ç”¢å“ç­‰ç´š", product_class),

            ("ä¸­æ–‡åç¨±", name_zh),

            ("è‹±æ–‡åç¨±", name_en),

            ("çµ±ä¸€ç·¨è™Ÿ", uniform_id),

            ("é†«ç™‚å™¨æå•†åç¨±", firm_name),

            ("é†«ç™‚å™¨æå•†åœ°å€", firm_addr),

            ("è² è²¬äººå§“å", resp_name),

            ("è¯çµ¡äººå§“å", contact_name),

            ("é›»è©±", contact_tel),

            ("é›»å­éƒµä»¶", contact_email),

            ("è£½é€ å» åç¨±", manu_name),

            ("è£½é€ å» åœ°å€", manu_addr),

        ]:

            if isinstance(val, str) and not val.strip():

                missing.append(label)



        st.session_state["tw_app_status"] = "error" if missing else "done"

        if missing:

            st.warning("ä»¥ä¸‹åŸºæœ¬æ¬„ä½å°šæœªå®Œæ•´ï¼ˆå½¢å¼æª¢æŸ¥ï¼‰ï¼š\n- " + "\n- ".join(missing))



        apply_date_str = apply_date.strftime("%Y-%m-%d") if apply_date else ""

        app_md = f"""# ç¬¬äºŒã€ä¸‰ç­‰ç´šé†«ç™‚å™¨ææŸ¥é©—ç™»è¨˜ç”³è«‹æ›¸ï¼ˆç·šä¸Šè‰ç¨¿ï¼‰



## ä¸€ã€æ¡ˆä»¶åŸºæœ¬è³‡æ–™

- å…¬æ–‡æ–‡è™Ÿï¼š{doc_no or "ï¼ˆæœªå¡«ï¼‰"}

- é›»å­æµæ°´è™Ÿï¼š{e_no or "ï¼ˆæœªå¡«ï¼‰"}

- ç”³è«‹æ—¥ï¼š{apply_date_str or "ï¼ˆæœªå¡«ï¼‰"}

- æ¡ˆä»¶é¡žåž‹ï¼š{case_type}

- é†«ç™‚å™¨æé¡žåž‹ï¼š{device_category}

- æ¡ˆä»¶ç¨®é¡žï¼š{case_kind}

- ç”¢åœ°ï¼š{origin}

- ç”¢å“ç­‰ç´šï¼š{product_class}

- æœ‰ç„¡é¡žä¼¼å“ï¼š{similar}

- æ›¿ä»£è‡¨åºŠå‰æ¸¬è©¦åŠå“è³ªç®¡åˆ¶è³‡æ–™ï¼š{replace_flag}

- å‰æ¬¡ç”³è«‹æ¡ˆè™Ÿï¼š{prior_app_no or "ä¸é©ç”¨"}



## äºŒã€é†«ç™‚å™¨æåŸºæœ¬è³‡è¨Š

- ä¸­æ–‡åç¨±ï¼š{name_zh}

- è‹±æ–‡åç¨±ï¼š{name_en}

- æ•ˆèƒ½/ç”¨é€”/é©æ‡‰ç—‡ï¼š{indications}

- åž‹è™Ÿ/è¦æ ¼/ä¸»è¦æˆåˆ†ï¼š{spec_comp}



### åˆ†é¡žåˆ†ç´šå“é …

- ä¸»é¡žåˆ¥ï¼š{main_cat or "ï¼ˆæœªå¡«ï¼‰"}

- ä»£ç¢¼ï¼š{item_code or "ï¼ˆæœªå¡«ï¼‰"}

- åç¨±ï¼š{item_name or "ï¼ˆæœªå¡«ï¼‰"}



## ä¸‰ã€é†«ç™‚å™¨æå•†è³‡æ–™

- çµ±ä¸€ç·¨è™Ÿï¼š{uniform_id}

- åç¨±ï¼š{firm_name}

- åœ°å€ï¼š{firm_addr}

- è² è²¬äººï¼š{resp_name}

- è¯çµ¡äººï¼š{contact_name}

- é›»è©±ï¼š{contact_tel}

- å‚³çœŸï¼š{contact_fax or "ï¼ˆæœªå¡«ï¼‰"}

- é›»å­éƒµä»¶ï¼š{contact_email}

- å·²ç¢ºèªè­‰ç…§ç›¸ç¬¦ï¼š{"æ˜¯" if confirm_match else "å¦"}



## å››ã€è£½é€ å» è³‡è¨Š

- è£½é€ æ–¹å¼ï¼š{manu_type}

- è£½é€ å» åç¨±ï¼š{manu_name}

- è£½é€ åœ‹åˆ¥ï¼š{manu_country}

- è£½é€ å» åœ°å€ï¼š{manu_addr}

- è£½é€ èªªæ˜Žï¼š{manu_note or "ï¼ˆæœªå¡«ï¼‰"}



## é™„ä»¶æ‘˜è¦ï¼ˆå¦‚é©ç”¨ï¼‰

- åŽŸå» æŽˆæ¬Šï¼š{auth_applicable} / {auth_desc or "ï¼ˆæœªå¡«ï¼‰"}

- è£½å”®è­‰æ˜Žï¼š{cfs_applicable} / {cfs_desc or "ï¼ˆæœªå¡«ï¼‰"}

- QMS/QSDï¼š{qms_applicable} / {qms_desc or "ï¼ˆæœªå¡«ï¼‰"}



### é¡žä¼¼å“æ‘˜è¦

{similar_info or "ï¼ˆæœªå¡«ï¼‰"}



### æ¨™ç±¤/èªªæ˜Žæ›¸æ“¬ç¨¿é‡é»ž

{labeling_info or "ï¼ˆæœªå¡«ï¼‰"}



### æŠ€è¡“æª”æ¡ˆæ‘˜è¦

{tech_file_info or "ï¼ˆæœªå¡«ï¼‰"}



### è‡¨åºŠå‰æ¸¬è©¦èˆ‡å“è³ªç®¡åˆ¶æ‘˜è¦

{preclinical_info or "ï¼ˆæœªå¡«ï¼‰"}



### æ›¿ä»£è³‡æ–™èªªæ˜Ž

{preclinical_replace or "ï¼ˆæœªå¡«ï¼‰"}



### è‡¨åºŠè­‰æ“š

- é©ç”¨æ€§ï¼š{clinical_just}

- æ‘˜è¦ï¼š{clinical_info or "ï¼ˆæœªå¡«ï¼‰"}

"""

        st.session_state["tw_app_markdown"] = app_md



    st.markdown("##### ç”³è«‹æ›¸ Markdownï¼ˆå¯ç·¨è¼¯ï¼‰")

    app_md_current = st.session_state.get("tw_app_markdown", "")

    view = st.radio("ç”³è«‹æ›¸æª¢è¦–æ¨¡å¼", ["Markdown", "ç´”æ–‡å­—"], horizontal=True, key="tw_app_viewmode")

    app_md_edited = st.text_area("ç”³è«‹æ›¸å…§å®¹", value=app_md_current, height=280, key="tw_app_md_edited")

    st.session_state["tw_app_effective_md"] = app_md_edited



    st.markdown("---")

    st.markdown("### Step 2 â€“ è¼¸å…¥é å¯©/å½¢å¼å¯©æŸ¥æŒ‡å¼•")

    col_g1, col_g2 = st.columns(2)

    with col_g1:

        guidance_file = st.file_uploader("ä¸Šå‚³é å¯©æŒ‡å¼• (PDF / TXT / MD)", type=["pdf", "txt", "md"], key="tw_guidance_file")

        guidance_text_from_file = ""

        if guidance_file is not None:

            suffix = guidance_file.name.lower().rsplit(".", 1)[-1]

            if suffix == "pdf":

                guidance_text_from_file = extract_pdf_pages_to_text(guidance_file, 1, 9999)

            else:

                guidance_text_from_file = guidance_file.read().decode("utf-8", errors="ignore")

    with col_g2:

        guidance_text_manual = st.text_area("æˆ–ç›´æŽ¥è²¼ä¸ŠæŒ‡å¼•æ–‡å­—/Markdown", height=200, key="tw_guidance_manual")



    guidance_text = guidance_text_from_file or guidance_text_manual

    st.session_state["tw_guidance_text"] = guidance_text



    st.markdown("---")

    st.markdown("### Step 3 â€“ å½¢å¼å¯©æŸ¥ / å®Œæ•´æ€§æª¢æ ¸ï¼ˆAgentï¼‰")

    base_app_md = st.session_state.get("tw_app_effective_md", "")

    base_guidance = st.session_state.get("tw_guidance_text", "")

    combined_input = f"""=== ç”³è«‹æ›¸è‰ç¨¿ï¼ˆMarkdownï¼‰ ===

{base_app_md}



=== é å¯© / å½¢å¼å¯©æŸ¥æŒ‡å¼• ===

{base_guidance or "ï¼ˆå°šæœªæä¾›æŒ‡å¼•ï¼Œè«‹ä¾ä¸€èˆ¬æ³•è¦å¸¸è¦é€²è¡Œå½¢å¼æª¢æ ¸ï¼‰"}

"""

    default_screen_prompt = """ä½ æ˜¯ä¸€ä½ç†Ÿæ‚‰è‡ºç£ã€Œç¬¬äºŒã€ä¸‰ç­‰ç´šé†«ç™‚å™¨ææŸ¥é©—ç™»è¨˜ã€çš„å½¢å¼å¯©æŸ¥(é å¯©)å¯©æŸ¥å“¡ã€‚



è«‹æ ¹æ“šï¼š

1) ç”³è«‹æ›¸è‰ç¨¿ï¼ˆMarkdownï¼‰

2) é å¯©/å½¢å¼å¯©æŸ¥æŒ‡å¼•ï¼ˆå¦‚æœ‰ï¼‰



ä»¥ç¹é«”ä¸­æ–‡ Markdown è¼¸å‡ºï¼š

- å½¢å¼å®Œæ•´æ€§æª¢æ ¸è¡¨ï¼ˆå«ï¼šé æœŸæ‡‰é™„ã€æ˜¯å¦æåŠã€åˆ¤å®šã€å‚™è¨»ï¼‰

- é‡è¦æ¬„ä½æª¢æ ¸ï¼ˆå•é¡Œé …ç›®/ç–‘æ…®/å»ºè­°è£œå……ï¼‰

- é å¯©è©•èªžæ‘˜è¦ï¼ˆ300â€“600å­—ï¼‰

- ç„¡å¾žåˆ¤æ–·è«‹æ˜Žç¢ºè¨»è¨˜

"""

    agent_run_ui(

        agent_id="tw_screen_review_agent",

        tab_key="tw_screen",

        default_prompt=default_screen_prompt,

        default_input_text=combined_input,

        allow_model_override=True,

        tab_label_for_history="TW Premarket Screen Review",

    )



    st.markdown("---")

    st.markdown("### Step 4 â€“ AI å”åŠ©ç·¨ä¿®ç”³è«‹æ›¸å…§å®¹")

    helper_default_prompt = """ä½ æ˜¯ä¸€ä½å”åŠ©è‡ºç£é†«ç™‚å™¨ææŸ¥é©—ç™»è¨˜ç”³è«‹äººçš„æ–‡ä»¶æ’°å¯«åŠ©æ‰‹ã€‚



è«‹åœ¨ä¸æ”¹è®Šå¯¦éš›æŠ€è¡“/æ³•è¦å…§å®¹çš„å‰æä¸‹ï¼š

- å„ªåŒ–æ®µè½çµæ§‹èˆ‡æ¨™é¡Œå±¤ç´š

- ä¿®æ­£æ–‡å¥ã€æå‡å¯è®€æ€§

- è³‡è¨Šä¸è¶³è™•ä»¥ã€Œâ€»å¾…è£œï¼š...ã€æ¨™è¨»

- è¼¸å‡º Markdown

"""

    agent_run_ui(

        agent_id="tw_app_doc_helper",

        tab_key="tw_app_helper",

        default_prompt=helper_default_prompt,

        default_input_text=base_app_md,

        allow_model_override=True,

        tab_label_for_history="TW Application Doc Helper",

    )





def render_510k_tab():

    st.markdown(f"## {tl('510k_tab')}")

    col1, col2 = st.columns(2)

    with col1:

        device_name = st.text_input("Device Name")

        k_number = st.text_input("510(k) Number (e.g., K123456)")

    with col2:

        sponsor = st.text_input("Sponsor / Manufacturer (optional)")

        product_code = st.text_input("Product Code (optional)")

    extra_info = st.text_area("Additional context (indications, technology, etc.)")



    default_prompt = f"""

You are assisting an FDA 510(k) reviewer.



Task:

1) Summarize information for:

   - Device: {device_name}

   - 510(k) number: {k_number}

   - Sponsor: {sponsor}

   - Product code: {product_code}

2) Produce a detailed review-oriented summary (2000â€“3000 words).

3) Provide markdown tables (overview, indications, testing, risks).



Language: {lang_code()}.

"""

    combined_input = f"""

Device name: {device_name}

510(k) number: {k_number}

Sponsor: {sponsor}

Product code: {product_code}



Additional context:

{extra_info}

"""

    agent_run_ui(

        agent_id="fda_510k_intel_agent",

        tab_key="510k",

        default_prompt=default_prompt,

        default_input_text=combined_input,

        tab_label_for_history="510(k) Intelligence",

    )





def render_pdf_to_md_tab():

    st.markdown(f"## {tl('PDF â†’ Markdown')}")

    uploaded = st.file_uploader("Upload PDF to convert selected pages to Markdown", type=["pdf"], key="pdf_to_md_uploader")

    if uploaded:

        c1, c2 = st.columns(2)

        with c1:

            num_start = st.number_input("From page", min_value=1, value=1, key="pdf_to_md_from")

        with c2:

            num_end = st.number_input("To page", min_value=1, value=5, key="pdf_to_md_to")



            text = extract_pdf_pages_to_text(uploaded, int(num_start), int(num_end), use_ocr=False)

            st.session_state["pdf_raw_text"] = text

            st.success("Text extracted (Raw). Run agent below to clean up.")



        with c2:

             if st.button("Extract with OCR (Slower)", key="pdf_ocr_btn"):

                 with st.spinner("Running OCR..."):

                     text = extract_pdf_pages_to_text(uploaded, int(num_start), int(num_end), use_ocr=True)

                     st.session_state["pdf_raw_text"] = text

                     st.success("OCR Complete. Run agent below to clean up.")



    raw_text = st.session_state.get("pdf_raw_text", "")

    if raw_text:

        st.markdown("---")

        # Allow selecting any agent, default to pdf_to_markdown_agent

        all_agents = list(st.session_state["agents_cfg"]["agents"].keys())

        default_idx = all_agents.index("pdf_to_markdown_agent") if "pdf_to_markdown_agent" in all_agents else 0

        

        selected_agent = st.selectbox("Select Agent for Processing", all_agents, index=default_idx, key="pdf_agent_select")

        

        # Get default prompt from selected agent

        sel_cfg = st.session_state["agents_cfg"]["agents"][selected_agent]

        base_def_prompt = sel_cfg.get("user_prompt_template", "") or sel_cfg.get("system_prompt", "")

        

        if selected_agent == "pdf_to_markdown_agent":

             # Keep the specialized default for this specific agent

             base_def_prompt = f"""

You are converting part of a regulatory PDF into markdown.



- Produce clean, structured markdown preserving headings, lists, tables (as markdown tables if possible).

- Do not hallucinate content.



Language: {lang_code()}.

"""



        agent_run_ui(

            agent_id=selected_agent,

            tab_key="pdf_to_md",

            default_prompt=base_def_prompt,

            default_input_text=raw_text,

            tab_label_for_history="PDF Processing",

        )

    else:

        st.info("Upload a PDF and click 'Extract Text' to begin.")





def render_510k_review_pipeline_tab():

    st.markdown(f"## {tl('Checklist & Report')}")

    st.markdown("### Step 1 â€“ æäº¤è³‡æ–™ â†’ çµæ§‹åŒ– Markdown")



    raw_subm = st.text_area("Paste 510(k) submission material (text/markdown)", height=200, key="subm_paste")

    default_subm_prompt = """You are a 510(k) submission organizer.



Restructure the following content into organized markdown with sections such as:

- Device & submitter information

- Device description and technology

- Indications for use

- Predicate/comparator information

- Performance testing

- Risks and risk controls



Do not invent facts; reorganize and clarify only.

"""

    if st.button("Structure Submission", key="subm_run_btn"):

        if not raw_subm.strip():

            st.warning("Please paste submission material first.")

        else:

            api_keys = st.session_state.get("api_keys", {})

            try:

                out = call_llm(

                    model=st.session_state.settings["model"],

                    system_prompt="You structure a 510(k) submission.",

                    user_prompt=default_subm_prompt + "\n\n=== SUBMISSION ===\n" + raw_subm,

                    max_tokens=st.session_state.settings["max_tokens"],

                    temperature=0.15,

                    api_keys=api_keys,

                )

                st.session_state["subm_struct_md"] = out

                log_event("510(k) Review Pipeline", "Submission Structurer", st.session_state.settings["model"], est_tokens(raw_subm + out))

            except Exception as e:

                st.error(f"Error: {e}")



    subm_md = st.session_state.get("subm_struct_md", "")

    if subm_md:

        st.text_area("Structured Submission (Markdown, editable)", value=subm_md, height=220, key="subm_struct_md_edited")

    else:

        st.info("Structured submission will appear here.")



    st.markdown("---")

    st.markdown("### Step 2 â€“ Checklist & Step 3 â€“ Review Report")



    chk_md = st.text_area("Paste checklist (markdown or text)", height=200, key="chk_md")

    if st.button("Build Review Report", key="rep_run_btn"):

        subm_md_eff = st.session_state.get("subm_struct_md_edited", subm_md)

        if not subm_md_eff.strip() or not chk_md.strip():

            st.warning("Need both structured submission and checklist.")

        else:

            api_keys = st.session_state.get("api_keys", {})

            rep_prompt = """You are drafting an internal FDA 510(k) review memo.



Using the checklist and structured submission, write a concise review report with:

- Introduction & scope

- Device and submission overview

- Key differences vs predicate(s)

- Checklist-based assessment (headings/tables)

- Conclusion and recommendations

"""

            user_prompt = rep_prompt + "\n\n=== CHECKLIST ===\n" + chk_md + "\n\n=== STRUCTURED SUBMISSION ===\n" + subm_md_eff

            try:

                out = call_llm(

                    model=st.session_state.settings["model"],

                    system_prompt="You are an FDA 510(k) reviewer.",

                    user_prompt=user_prompt,

                    max_tokens=st.session_state.settings["max_tokens"],

                    temperature=0.18,

                    api_keys=api_keys,

                )

                st.session_state["rep_md"] = out

                log_event("510(k) Review Pipeline", "Review Memo Builder", st.session_state.settings["model"], est_tokens(user_prompt + out))

            except Exception as e:

                st.error(f"Error: {e}")



    rep_md = st.session_state.get("rep_md", "")

    if rep_md:

        st.text_area("Review Report (Markdown, editable)", value=rep_md, height=260, key="rep_md_edited")





# ============================================================

# 14) Note Keeper (paste + upload + organize + coral keywords + 6 magics)

# ============================================================

def normalize_whitespace(s: str) -> str:

    return re.sub(r"\n{3,}", "\n\n", (s or "").strip())





def read_uploaded_note_file() -> str:

    file = st.session_state.get("note_file")

    if not file:

        return ""

    name = file.name.lower()

    if name.endswith(".pdf"):

        # simple extraction; OCR not included

        return extract_pdf_pages_to_text(file, 1, 9999)

    return file.read().decode("utf-8", errors="ignore")





def highlight_keywords_html(text: str, keywords: List[str], color: str = "#FF7F50") -> str:

    """

    Safer-ish highlighter: word-boundary when possible; preserves markdown-ish text by using HTML spans.

    """

    if not text.strip() or not keywords:

        return text



    # Avoid overlapping replacements by sorting longest first

    kws = sorted({k.strip() for k in keywords if k and k.strip()}, key=len, reverse=True)

    out = text



    for kw in kws:

        # simple heuristic: if keyword has letters/numbers, use boundary; else direct

        if re.search(r"[A-Za-z0-9]", kw):

            pattern = re.compile(rf"(?<![\w-]){re.escape(kw)}(?![\w-])")

            out = pattern.sub(rf'<span style="color:{color};font-weight:800;">{kw}</span>', out)

        else:

            out = out.replace(kw, f'<span style="color:{color};font-weight:800;">{kw}</span>')

    return out





def magic_ai_keywords(base_md: str, color: str, model: str) -> Tuple[List[str], str]:

    """

    Returns (keywords, highlighted_html_markdown)

    """

    api_keys = st.session_state.get("api_keys", {})

    system_prompt = st.session_state["agents_cfg"]["agents"]["keyword_extractor"].get("system_prompt", "")

    user_prompt = f"""

Extract the TOP 10-15 high-signal keywords/entities from the note below.



Rules:

- Prefer: proper nouns, standards (ISO/IEC), guidance names, device names, test names, endpoints, regulatory terms, dates, key metrics.

- Output MUST be JSON only: {{"keywords":["..."]}}



NOTE:

{base_md}

"""

    raw = call_llm(

        model=model,

        system_prompt=system_prompt,

        user_prompt=user_prompt,

        max_tokens=1500,

        temperature=0.1,

        api_keys=api_keys,

    )



    # Parse JSON

    try:

        obj = json.loads(raw)

    except Exception:

        s = raw[raw.find("{") : raw.rfind("}") + 1]

        obj = json.loads(s)



    keywords = obj.get("keywords", [])

    if not isinstance(keywords, list):

        keywords = []



    highlighted = highlight_keywords_html(base_md, keywords, color=color)

    return keywords, highlighted





def render_note_keeper_tab():

    st.markdown(f"## {tl('Note Keeper & Magics')}")

    st.caption("Paste or upload notes. Convert into organized Markdown with coral-highlighted keywords, then apply 6 AI Magics.")



    c0, c1 = st.columns([1.2, 1.8])

    with c0:

        st.file_uploader(t("note_upload"), type=["pdf", "txt", "md"], key="note_file")

        if st.button("Load uploaded note into editor"):

            file_text = read_uploaded_note_file()

            st.session_state["notes_raw"] = normalize_whitespace(file_text)

            st.rerun()

    with c1:

        st.text_area(t("note_paste"), height=220, key="notes_raw")



    base_raw = normalize_whitespace(st.session_state.get("notes_raw", ""))



    st.markdown("---")

    st.markdown(f"### {t('note_transform')}")



    cA, cB, cC = st.columns([1.2, 1.2, 1.2])

    with cA:

        note_model = st.selectbox("Model", ALL_MODELS, index=ALL_MODELS.index(st.session_state.settings["model"]), key="note_model")

    with cB:

        note_max_tokens = st.number_input("max_tokens", 2000, 120000, 12000, 1000, key="note_max_tokens")

    with cC:

        kw_color = st.color_picker(t("note_color"), "#FF7F50", key="note_kw_color")



    organizer_prompt = st.text_area(

        t("prompt"),

        value="""You are an expert note organizer.



Transform the RAW NOTE into clean, organized Markdown with:

- Clear headings and subheadings

- Bullet points where appropriate

- A short "Key Takeaways" section at the top

- A "Questions / Follow-ups" section at the bottom



Hard rules:

- Do not add facts that are not present in the note.

- Keep technical and regulatory terminology accurate.

""",

        height=160,

        key="note_organizer_prompt",

    )



    if st.button(t("run"), key="note_transform_btn"):

        if not base_raw.strip():

            st.warning("No note content.")

        else:

            api_keys = st.session_state.get("api_keys", {})

            agent_cfg = st.session_state["agents_cfg"]["agents"]["note_organizer"]

            system_prompt = agent_cfg.get("system_prompt", "")

            user_prompt = organizer_prompt + "\n\n=== RAW NOTE ===\n" + base_raw



            try:

                with st.spinner("Organizing note..."):

                    out = call_llm(

                        model=note_model,

                        system_prompt=system_prompt,

                        user_prompt=user_prompt,

                        max_tokens=int(note_max_tokens),

                        temperature=0.15,

                        api_keys=api_keys,

                    )

                st.session_state["note_md"] = out

                log_event("Note Keeper", "Note Organizer", note_model, est_tokens(user_prompt + out))

            except Exception as e:

                st.error(f"Error: {e}")



    base_md = normalize_whitespace(st.session_state.get("note_md", base_raw))



    st.markdown("#### Base Note (editable)")

    view = st.radio(t("view_mode"), [t("markdown"), t("plain_text")], horizontal=True, key="note_view_mode")

    base_md = st.text_area("Note", value=base_md, height=260, key="note_md_edited")

    st.session_state["note_effective"] = base_md



    st.markdown("---")

    st.markdown(f"### {t('ai_magics')} (6)")



    base_note = st.session_state.get("note_effective", "")



    # Magic 1: AI Keywords (auto extract) + user editable keyword list + color

    st.markdown(f"#### 1) {t('magic_keywords')}")

    cK1, cK2, cK3 = st.columns([1.1, 1.1, 1.2])

    with cK1:

        kw_model = st.selectbox("Model", ALL_MODELS, index=ALL_MODELS.index("gemini-2.5-flash") if "gemini-2.5-flash" in ALL_MODELS else 0, key="kw_model")

    with cK2:

        kw_color2 = st.color_picker(t("note_color"), kw_color, key="kw_color2")

    with cK3:

        manual_kw = st.text_input("Manual keywords (comma-separated; optional)", key="manual_kw", value="")



    cK4, cK5 = st.columns([1.0, 1.0])

    with cK4:

        if st.button("Run AI Keywords + Highlight", key="kw_ai_btn"):

            if not base_note.strip():

                st.warning("No base note.")

            else:

                try:

                    kws, highlighted = magic_ai_keywords(base_note, kw_color2, kw_model)

                    st.session_state["kw_ai_list"] = kws

                    st.session_state["kw_highlighted"] = highlighted

                    log_event("Note Keeper", "AI Keywords", kw_model, est_tokens(base_note))

                except Exception as e:

                    st.error(f"AI Keywords failed: {e}")



    with cK5:

        if st.button("Apply Manual Highlight", key="kw_manual_btn"):

            kws = [k.strip() for k in manual_kw.split(",") if k.strip()]

            st.session_state["kw_ai_list"] = kws

            st.session_state["kw_highlighted"] = highlight_keywords_html(base_note, kws, color=kw_color2)



    highlighted = st.session_state.get("kw_highlighted", "")

    if highlighted.strip():

        st.markdown("**Rendered (HTML-capable Markdown):**")

        st.markdown(highlighted, unsafe_allow_html=True)

        st.text_area("Highlighted (editable source)", value=highlighted, height=200, key="kw_highlighted_edit")



    # Magic 2: Summarize

    st.markdown(f"#### 2) {t('magic_summarize')}")

    sum_model = st.selectbox("Model", ALL_MODELS, index=ALL_MODELS.index("gpt-4o-mini") if "gpt-4o-mini" in ALL_MODELS else 0, key="sum_model")

    sum_prompt = st.text_area(

        t("prompt"),

        value="Summarize into 8â€“12 bullets + a 5-sentence executive summary. Keep terminology accurate. Output Markdown.",

        height=120,

        key="sum_prompt",

    )

    if st.button(t("run"), key="sum_btn"):

        try:

            out = call_llm(

                model=sum_model,

                system_prompt="You write executive summaries for technical/regulatory notes.",

                user_prompt=sum_prompt + "\n\n=== NOTE ===\n" + base_note,

                max_tokens=12000,

                temperature=0.2,

                api_keys=st.session_state.get("api_keys", {}),

            )

            st.session_state["sum_out"] = out

            log_event("Note Keeper", "Summarize", sum_model, est_tokens(base_note + out))

        except Exception as e:

            st.error(f"Summarize failed: {e}")

    if st.session_state.get("sum_out"):

        st.text_area("Summary (editable)", value=st.session_state["sum_out"], height=220, key="sum_out_edit")



    # Magic 3: Polisher

    st.markdown(f"#### 3) {t('magic_polish')}")

    pol_model = st.selectbox("Model", ALL_MODELS, index=ALL_MODELS.index("gpt-4.1-mini") if "gpt-4.1-mini" in ALL_MODELS else 0, key="pol_model")

    pol_prompt = st.text_area(

        t("prompt"),

        value="Polish for clarity, grammar, and professional tone. Do not add facts. Keep Markdown structure.",

        height=120,

        key="pol_prompt",

    )

    if st.button(t("run"), key="pol_btn"):

        try:

            out = call_llm(

                model=pol_model,

                system_prompt=st.session_state["agents_cfg"]["agents"]["polisher"].get("system_prompt", ""),

                user_prompt=pol_prompt + "\n\n=== NOTE ===\n" + base_note,

                max_tokens=12000,

                temperature=0.15,

                api_keys=st.session_state.get("api_keys", {}),

            )

            st.session_state["pol_out"] = out

            log_event("Note Keeper", "Polisher", pol_model, est_tokens(base_note + out))

        except Exception as e:

            st.error(f"Polisher failed: {e}")

    if st.session_state.get("pol_out"):

        st.text_area("Polished (editable)", value=st.session_state["pol_out"], height=220, key="pol_out_edit")



    # Magic 4: Critique

    st.markdown(f"#### 4) {t('magic_critique')}")

    cri_model = st.selectbox("Model", ALL_MODELS, index=ALL_MODELS.index("claude-3-5-sonnet-20241022") if "claude-3-5-sonnet-20241022" in ALL_MODELS else 0, key="cri_model")

    cri_prompt = st.text_area(

        t("prompt"),

        value="Provide constructive critique: unclear areas, missing evidence, risks, contradictions, and specific improvement suggestions. Output Markdown with sections.",

        height=120,

        key="cri_prompt",

    )

    if st.button(t("run"), key="cri_btn"):

        try:

            out = call_llm(

                model=cri_model,

                system_prompt=st.session_state["agents_cfg"]["agents"]["critic"].get("system_prompt", ""),

                user_prompt=cri_prompt + "\n\n=== NOTE ===\n" + base_note,

                max_tokens=12000,

                temperature=0.35,

                api_keys=st.session_state.get("api_keys", {}),

            )

            st.session_state["cri_out"] = out

            log_event("Note Keeper", "Critique", cri_model, est_tokens(base_note + out))

        except Exception as e:

            st.error(f"Critique failed: {e}")

    if st.session_state.get("cri_out"):

        st.text_area("Critique (editable)", value=st.session_state["cri_out"], height=220, key="cri_out_edit")



    # Magic 5: Poet Mode

    st.markdown(f"#### 5) {t('magic_poet')}")

    poe_model = st.selectbox("Model", ALL_MODELS, index=ALL_MODELS.index("gemini-3-flash-preview") if "gemini-3-flash-preview" in ALL_MODELS else 0, key="poe_model")

    poe_prompt = st.text_area(

        t("prompt"),

        value=f"Transform the note into poetic or artistic prose inspired by the current UI style: {st.session_state.settings['painter_style']}. Preserve core meaning; do not add facts.",

        height=120,

        key="poe_prompt",

    )

    if st.button(t("run"), key="poe_btn"):

        try:

            out = call_llm(

                model=poe_model,

                system_prompt=st.session_state["agents_cfg"]["agents"]["poet_laureate"].get("system_prompt", ""),

                user_prompt=poe_prompt + "\n\n=== NOTE ===\n" + base_note,

                max_tokens=12000,

                temperature=0.75,

                api_keys=st.session_state.get("api_keys", {}),

            )

            st.session_state["poe_out"] = out

            log_event("Note Keeper", "Poet Mode", poe_model, est_tokens(base_note + out))

        except Exception as e:

            st.error(f"Poet failed: {e}")

    if st.session_state.get("poe_out"):

        st.text_area("Poet output (editable)", value=st.session_state["poe_out"], height=220, key="poe_out_edit")



    # Magic 6: Translate to UI language

    st.markdown(f"#### 6) {t('magic_translate')}")

    tr_model = st.selectbox("Model", ALL_MODELS, index=ALL_MODELS.index("gemini-2.5-flash") if "gemini-2.5-flash" in ALL_MODELS else 0, key="tr_model")

    target = "Traditional Chinese (zh-TW)" if lang_code() == "zh-tw" else "English"

    tr_prompt = st.text_area(

        t("prompt"),

        value=f"Detect the language and translate the note into {target}. Preserve markdown structure and technical terms.",

        height=120,

        key="tr_prompt",

    )

    if st.button(t("run"), key="tr_btn"):

        try:

            out = call_llm(

                model=tr_model,

                system_prompt=st.session_state["agents_cfg"]["agents"]["translator"].get("system_prompt", ""),

                user_prompt=tr_prompt + "\n\n=== NOTE ===\n" + base_note,

                max_tokens=12000,

                temperature=0.2,

                api_keys=st.session_state.get("api_keys", {}),

            )

            st.session_state["tr_out"] = out

            log_event("Note Keeper", "Translate", tr_model, est_tokens(base_note + out))

        except Exception as e:

            st.error(f"Translate failed: {e}")

    if st.session_state.get("tr_out"):

        st.text_area("Translated (editable)", value=st.session_state["tr_out"], height=220, key="tr_out_edit")



    st.markdown("---")

    st.markdown("### 7) Run Any Agent")

    st.caption("Select any agent from your catalog to run on this note.")

    

    agent_options = list(st.session_state["agents_cfg"]["agents"].keys())

    if agent_options:

        selected_agent = st.selectbox("Select Agent", agent_options, key="note_generic_agent_select")

        

        # Determine default prompt from agent config

        sel_cfg = st.session_state["agents_cfg"]["agents"][selected_agent]

        def_prompt = sel_cfg.get("user_prompt_template", "") or "Analyze the input note."

        

        # Use our generic UI

        # We pass the note as the default input text

        agent_run_ui(

            agent_id=selected_agent,

            tab_key="note_generic",

            default_prompt=def_prompt,

            default_input_text=base_note,

            allow_model_override=True,

            tab_label_for_history="Note Keeper Generic"

        )

    else:

        st.info("No agents found in catalog.")



    # download base note

    if base_note.strip():

        st.download_button(

            t("download_md"),

            data=base_note.encode("utf-8"),

            file_name="note.md",

            mime="text/markdown",

        )





# ============================================================

# 15) Agents Config tab (kept; improved resilience)

# ============================================================

def render_agents_config_tab():

    st.markdown(f"## {tl('Agents Config')}")

    agents_cfg = st.session_state["agents_cfg"]

    agents_dict = agents_cfg.get("agents", {})



    st.subheader("1) Agents Overview")

    if not agents_dict:

        st.warning("No agents found in current agents.yaml.")

    else:

        df = pd.DataFrame(

            [

                {

                    "agent_id": aid,

                    "name": acfg.get("name", ""),

                    "model": acfg.get("model", ""),

                    "max_tokens": acfg.get("max_tokens", ""),

                    "category": acfg.get("category", ""),

                    "supported_models": ", ".join(acfg.get("supported_models", [])) if isinstance(acfg.get("supported_models"), list) else "",

                    "description_tw": acfg.get("description_tw", ""),

                }

                for aid, acfg in agents_dict.items()

            ]

        )

        st.dataframe(df, use_container_width=True, height=320)



    st.markdown("---")

    st.subheader("2) Edit Full agents.yaml (raw text)")

    yaml_str_current = yaml.dump(st.session_state["agents_cfg"], allow_unicode=True, sort_keys=False)



    edited_yaml_text = st.text_area("agents.yaml (editable)", value=yaml_str_current, height=360, key="agents_yaml_text_editor")



    c1, c2, c3 = st.columns(3)

    with c1:

        if st.button("Apply edited YAML to session", key="apply_edited_yaml"):

            try:

                cfg = yaml.safe_load(edited_yaml_text) or {}

                if not isinstance(cfg, dict) or "agents" not in cfg:

                    st.error("Parsed YAML missing top-level key 'agents'. No changes applied.")

                else:

                    st.session_state["agents_cfg"] = ensure_fallback_agents(cfg)

                    st.success("Updated agents.yaml in current session.")

                    st.rerun()

            except Exception as e:

                st.error(f"Failed to parse edited YAML: {e}")



    with c2:

        uploaded_agents_tab = st.file_uploader("Upload agents.yaml file", type=["yaml", "yml"], key="agents_yaml_tab_uploader")

        if uploaded_agents_tab is not None:

            try:

                cfg = yaml.safe_load(uploaded_agents_tab.read()) or {}

                if "agents" in cfg:

                    st.session_state["agents_cfg"] = ensure_fallback_agents(cfg)

                    st.success("Uploaded agents.yaml applied to this session.")

                    st.rerun()

                else:

                    st.warning("Uploaded file has no top-level 'agents' key. Ignoring.")

            except Exception as e:

                st.error(f"Failed to parse uploaded YAML: {e}")



    with c3:

        st.download_button(

            "Download current agents.yaml",

            data=yaml_str_current.encode("utf-8"),

            file_name="agents.yaml",

            mime="text/yaml",

            key="download_agents_yaml_current",

        )





# ============================================================

# 16) Main render

# ============================================================

render_sidebar()

apply_style_engine(st.session_state.settings["theme"], st.session_state.settings["painter_style"])

render_wow_header()



tab_labels = [

    tl("Dashboard"),

    tl("Workflow Studio"),

    tl("TW Premarket"),

    tl("510k_tab"),

    tl("PDF â†’ Markdown"),

    tl("Checklist & Report"),

    tl("Note Keeper & Magics"),

    tl("Agents Config"),

]

tabs = st.tabs(tab_labels)



with tabs[0]:

    render_dashboard()

with tabs[1]:

    render_workflow_studio()

with tabs[2]:

    render_tw_premarket_tab()

with tabs[3]:

    render_510k_tab()

with tabs[4]:

    render_pdf_to_md_tab()

with tabs[5]:

    render_510k_review_pipeline_tab()

with tabs[6]:

    render_note_keeper_tab()

with tabs[7]:

    render_agents_config_tab()

Default case: {

  "doc_no": "è¡›æŽˆé†«å™¨å­—ç¬¬1130001234è™Ÿ",

  "e_no": "MDE-2026-000198",

  "apply_date": "2026-01-15",

  "case_type": "ä¸€èˆ¬ç”³è«‹æ¡ˆ",

  "device_category": "ä¸€èˆ¬é†«æ",

  "case_kind": "æ–°æ¡ˆ",

  "origin": "è¼¸å…¥",

  "product_class": "ç¬¬äºŒç­‰ç´š",

  "similar": "æœ‰",

  "replace_flag": "å¦",

  "prior_app_no": "",

  "name_zh": "ä¸€æ¬¡æ€§ä½¿ç”¨ç„¡èŒæ³¨å°„å™¨ï¼ˆå«é‡ï¼‰",

  "name_en": "Single-use Sterile Syringe with Needle",

  "indications": "ä¾›é†«ç™‚å°ˆæ¥­äººå“¡æ–¼è‡¨åºŠæ³¨å°„èˆ‡æŠ½å–æ¶²é«”ä½¿ç”¨ã€‚è©³å¦‚æ ¸å®šä¹‹ä¸­æ–‡èªªæ˜Žæ›¸ã€‚",

  "spec_comp": "å®¹é‡ 1 mL / 3 mL / 5 mLï¼›é‡è¦ 23G / 25Gï¼›ä¸»è¦æè³ªï¼šPPï¼ˆç­’èº«ï¼‰ã€ä¸é½é‹¼ï¼ˆé‡ç®¡ï¼‰ã€‚",

  "main_cat": "J.ä¸€èˆ¬é†«é™¢åŠå€‹äººä½¿ç”¨è£ç½®",

  "item_code": "J.4830",

  "item_name": "æ³¨å°„å™¨åŠå…¶é™„ä»¶",

  "uniform_id": "24567890",

  "firm_name": "å®‰æ¾¤é†«æè‚¡ä»½æœ‰é™å…¬å¸",

  "firm_addr": "è‡ºåŒ—å¸‚å…§æ¹–å€ç‘žå…‰è·¯321è™Ÿ8æ¨“",

  "resp_name": "é™³å¿—è±ª",

  "contact_name": "æž—æ€¡å›",

  "contact_tel": "02-2799-1234",

  "contact_fax": "02-2799-5678",

  "contact_email": "regulatory@anzenmed.com.tw",

  "confirm_match": true,

  "cert_raps": false,

  "cert_ahwp": true,

  "cert_other": "ISO 13485 å…§éƒ¨ç¨½æ ¸å“¡è¨“ç·´è­‰æ˜Žï¼ˆ2025ï¼‰",

  "manu_type": "å–®ä¸€è£½é€ å» ",

  "manu_name": "GLOBAL MEDICAL DEVICES CO., LTD.",

  "manu_country": "UNITED STATES",

  "manu_addr": "1200 Innovation Drive, Irvine, CA 92618, USA",

  "manu_note": "åŽŸå» è² è²¬è£½é€ ã€åŒ…è£èˆ‡æœ€çµ‚æ”¾è¡Œï¼›å°ç£é†«ç™‚å™¨æå•†è² è²¬é€²å£èˆ‡ä¸Šå¸‚å¾Œç›£ç£ã€‚",

  "auth_applicable": "é©ç”¨",

  "auth_desc": "é™„åŽŸå» æŽˆæ¬Šç™»è¨˜æ›¸æ­£æœ¬èˆ‡ä¸­è­¯æœ¬ï¼›æŽˆæ¬Šç¯„åœåŒ…å«æœ¬ç”¢å“å…¨è¦æ ¼èˆ‡åž‹è™Ÿã€‚",

  "cfs_applicable": "é©ç”¨",

  "cfs_desc": "æä¾›ç¾Žåœ‹å‡ºç”¢åœ‹è£½å”®è­‰æ˜Žï¼åŒç­‰æ•ˆåŠ›æ–‡ä»¶å½±æœ¬ï¼Œä¸¦é™„ä¸­è­¯æœ¬ã€‚",

  "qms_applicable": "é©ç”¨",

  "qms_desc": "åŽŸå»  ISO 13485:2016 è­‰æ›¸æœ‰æ•ˆæœŸè‡³ 2027-06ï¼›é©—è­‰ç¯„åœæ¶µè“‹æœ¬ç”¢å“ã€‚",

  "similar_info": "åŒé¡žç”¢å“å·²æ–¼å¤šåœ‹ä¸Šå¸‚ï¼›æä¾›èˆ‡æ—¢æœ‰åŒé¡žå“æ¯”è¼ƒï¼šæè³ªã€æ»…èŒæ–¹å¼ã€å®¹é‡èˆ‡é‡è¦å·®ç•°ã€‚é¡žä¼¼å“è¨±å¯è­‰è³‡è¨Šå¦é™„è¡¨ã€‚",

  "labeling_info": "ä¸­æ–‡æ¨™ç±¤èˆ‡èªªæ˜Žæ›¸æ“¬ç¨¿å«ï¼šç”¢å“åç¨±ã€è¦æ ¼ã€æ»…èŒæ–¹å¼ï¼ˆEOï¼‰ã€æœ‰æ•ˆæœŸé™ã€æ³¨æ„äº‹é …ã€å–®æ¬¡ä½¿ç”¨è­¦èªžã€‚",

  "tech_file_info": "æä¾›ç”¢å“çµæ§‹åœ–ã€ææ–™æ¸…å–®ã€å°ºå¯¸è¦æ ¼ã€è£½ç¨‹æ¦‚è¦ã€æ»…èŒç¢ºæ•ˆæ‘˜è¦ã€åŒ…è£å®Œæ•´æ€§æ¸¬è©¦æ‘˜è¦ã€‚",

  "preclinical_info": "è‡¨åºŠå‰æ¸¬è©¦æ‘˜è¦ï¼šç”Ÿç‰©ç›¸å®¹æ€§ï¼ˆä¾ ISO 10993 ç³»åˆ—ï¼‰ã€æ»…èŒç¢ºæ•ˆï¼ˆISO 11135ï¼‰ã€åŒ…è£å®Œæ•´æ€§èˆ‡é‹è¼¸æ¨¡æ“¬ã€é‡å°–ç©¿åˆºåŠ›èˆ‡æ»‘å‹•æ€§æ¸¬è©¦ã€‚",

  "preclinical_replace": "",

  "clinical_just": "ä¸é©ç”¨",

  "clinical_info": "ä¾ç¾è¡Œè¦ç¯„èˆ‡ç”¢å“é¢¨éšªè©•ä¼°ï¼Œæœ¬å“å±¬æˆç†ŸæŠ€è¡“èˆ‡åŒé¡žç”¢å“ï¼Œæä¾›è‡¨åºŠå‰æ¸¬è©¦èˆ‡ä¸Šå¸‚å¾Œç›£æ¸¬è¨ˆç•«ï¼Œç„¡è‡¨åºŠè©¦é©—éœ€æ±‚ã€‚"

}

Default guidance:Dataset #1 é å¯©æŒ‡å¼•ï¼ˆä¸€æ¬¡æ€§ä½¿ç”¨ç„¡èŒæ³¨å°„å™¨å«é‡ï¼Œç¬¬äºŒç­‰ç´š/è¼¸å…¥ï¼‰

# é å¯©/å½¢å¼å¯©æŸ¥æŒ‡å¼•ï¼ˆMockï¼‰â€”ç¬¬äºŒç­‰ç´šè¼¸å…¥ä¸€èˆ¬é†«æï¼šä¸€æ¬¡æ€§ä½¿ç”¨ç„¡èŒæ³¨å°„å™¨ï¼ˆå«é‡ï¼‰



## 0. å¯©æŸ¥ç›®çš„

æœ¬æŒ‡å¼•ç”¨æ–¼å½¢å¼å¯©æŸ¥ï¼ˆé å¯©ï¼‰éšŽæ®µï¼Œç¢ºèªç”³è«‹æ›¸èˆ‡ä¸»è¦é™„ä»¶æ˜¯å¦é½Šå‚™ã€è³‡è¨Šæ˜¯å¦ä¸€è‡´ã€æ–‡ä»¶å¯è¿½æº¯æ€§æ˜¯å¦è¶³ä»¥é€²å…¥æŠ€è¡“å¯©æŸ¥ã€‚



---



## 1. å¿…è¦æ–‡ä»¶æ¸…å–®ï¼ˆé æœŸæ‡‰é™„ï¼‰

> å¯©æŸ¥æ™‚è«‹é€ä¸€ç¢ºèªã€Œæ˜¯å¦æåŠã€ã€Œæ˜¯å¦æª¢é™„ã€ã€Œæ˜¯å¦æœ‰æ•ˆ/åœ¨æ•ˆæœŸå…§ã€ã€‚



1. ç”³è«‹æ›¸ï¼ˆç¬¬äºŒã€ä¸‰ç­‰ç´šé†«ç™‚å™¨ææŸ¥é©—ç™»è¨˜ç”³è«‹æ›¸ï¼‰

2. é†«ç™‚å™¨æå•†è¨±å¯åŸ·ç…§ï¼ˆåç¨±/åœ°å€/è² è²¬äººé ˆèˆ‡ç”³è«‹æ›¸ä¸€è‡´ï¼‰

3. åŽŸå» æŽˆæ¬Šç™»è¨˜æ›¸ï¼ˆè¼¸å…¥æ¡ˆé€šå¸¸å¿…é™„ï¼‰

4. å‡ºç”¢åœ‹è£½å”®è­‰æ˜Žï¼ˆCFS æˆ–åŒç­‰æ•ˆåŠ›æ–‡ä»¶ï¼Œå«æ•ˆæœŸ/ç°½ç™¼æ©Ÿé—œï¼‰

5. QMS/QSD æˆ– ISO 13485 è­‰æ˜Žï¼ˆæ¶µè“‹ç”¢å“ç¯„åœã€æœ‰æ•ˆæœŸï¼‰

6. ç”¢å“ä¸­æ–‡æ¨™ç±¤/èªªæ˜Žæ›¸/å¤–ç›’æ¨™ç¤ºæ“¬ç¨¿

7. ç”¢å“æŠ€è¡“æª”æ¡ˆæ‘˜è¦ï¼ˆçµæ§‹ã€ææ–™ã€è¦æ ¼ã€è£½ç¨‹ç°¡è¿°ã€åœ–æ¨£ï¼‰

8. æ»…èŒç¢ºæ•ˆæ‘˜è¦ï¼ˆå¦‚ EOï¼šISO 11135ï¼›éœ€èªªæ˜Ž SALã€å¾ªç’°ã€æ”¾è¡Œæ–¹å¼ï¼‰

9. åŒ…è£å®Œæ•´æ€§/é‹è¼¸æ¨¡æ“¬æ‘˜è¦ï¼ˆå¦‚é©ç”¨ï¼‰

10. ç”Ÿç‰©ç›¸å®¹æ€§æ‘˜è¦ï¼ˆæŽ¥è§¸æ€§è³ª/æ™‚é–“èˆ‡ ISO 10993 å°æ‡‰ï¼‰

11. æ€§èƒ½/åŠŸèƒ½æ¸¬è©¦æ‘˜è¦ï¼ˆä¾‹å¦‚é‡å°–ç©¿åˆºåŠ›ã€æ»‘å‹•æ€§ã€æ¼æ¶²ã€å°ºå¯¸ï¼‰

12. é¢¨éšªç®¡ç†æ‘˜è¦ï¼ˆISO 14971ï¼Œè‡³å°‘åŒ…å«ä¸»è¦å±å®³èˆ‡æŽ§åˆ¶ï¼‰

13. ä¸Šå¸‚å¾Œç›£ç£/æŠ±æ€¨è™•ç†æ©Ÿåˆ¶ç°¡è¿°ï¼ˆå¯ç”¨æ‘˜è¦ï¼‰



---



## 2. ç”³è«‹æ›¸é—œéµæ¬„ä½æª¢æ ¸

- æ¡ˆä»¶åŸºæœ¬è³‡æ–™ï¼šæ¡ˆä»¶é¡žåž‹ã€æ¡ˆä»¶ç¨®é¡žã€ç”¢åœ°ã€ç”¢å“ç­‰ç´šã€æœ‰ç„¡é¡žä¼¼å“ã€æ˜¯å¦å‹¾é¸æ›¿ä»£æ¢æ¬¾

- åç¨±ä¸€è‡´æ€§ï¼šä¸­æ–‡å“å/è‹±æ–‡å“åèˆ‡æ¨™ç±¤ã€æŽˆæ¬Šæ›¸ã€CFS æ˜¯å¦ä¸€è‡´

- åˆ†é¡žåˆ†ç´šï¼šä¸»é¡žåˆ¥/å“é …ä»£ç¢¼/å“é …åç¨±æ˜¯å¦å¡«å¯«ä¸”åˆç†

- é†«ç™‚å™¨æå•†è³‡æ–™ï¼šçµ±ç·¨ã€åœ°å€ã€è² è²¬äººã€è¯çµ¡è³‡è¨Šæ˜¯å¦å®Œæ•´

- è£½é€ å» è³‡è¨Šï¼šè£½é€ å» åç¨±/åœ°å€/åœ‹åˆ¥æ˜¯å¦å®Œæ•´ï¼Œèˆ‡ QMS/CFS æ˜¯å¦ä¸€è‡´



---



## 3. æ–‡ä»¶ä¸€è‡´æ€§èˆ‡æ•ˆæœŸæª¢æ ¸

- åŽŸå» æŽˆæ¬Šç¯„åœï¼šæ˜¯å¦æ¶µè“‹æ‰€æœ‰è¦æ ¼ï¼ˆå®¹é‡ã€é‡è¦ï¼‰

- CFS æ–‡ä»¶ï¼šæ˜¯å¦æ˜Žç¢ºæ¶µè“‹ç”¢å“ã€æ˜¯å¦ä»åœ¨æ•ˆæœŸ

- QMS/ISO 13485ï¼šç¯„åœæ˜¯å¦åŒ…å«ã€Œè¨­è¨ˆ/è£½é€ ã€åŠæœ¬ç”¢å“é¡žåˆ¥ï¼›æ˜¯å¦æœ‰æ•ˆ

- æ¨™ç¤ºæ“¬ç¨¿ï¼šæ˜¯å¦åŒ…å«ã€Œç„¡èŒã€å–®æ¬¡ä½¿ç”¨ã€æ»…èŒæ–¹å¼ã€æ•ˆæœŸã€æ‰¹è™Ÿã€è­¦èªžã€



---



## 4. å¸¸è¦‹ç¼ºå¤±ï¼ˆè«‹åœ¨å ±å‘Šä¸­æ˜Žç¢ºåˆ—ç‚ºç¼ºæ¼/è£œä»¶ï¼‰

- ç¼ºåŽŸå» æŽˆæ¬Šæˆ–æŽˆæ¬Šæœªæ¶µè“‹å…¨éƒ¨è¦æ ¼

- ç¼º CFS æˆ–æ–‡ä»¶éŽæœŸ/ç„¡ç°½ç™¼æ©Ÿé—œè³‡è¨Š

- ç¼ºæ»…èŒç¢ºæ•ˆæ‘˜è¦æˆ–æœªèªªæ˜Ž EO åƒæ•¸/æ”¾è¡Œæ¢ä»¶

- ç¼ºç”Ÿç‰©ç›¸å®¹æ€§å°æ‡‰ï¼ˆISO 10993 æ¸¬é …èˆ‡æŽ¥è§¸åˆ†é¡žä¸åŒ¹é…ï¼‰

- ä¸­æ–‡æ¨™ç¤ºæœªå«æ‰¹è™Ÿ/æ•ˆæœŸ/ä¿å­˜æ¢ä»¶/ä¸€æ¬¡æ€§ä½¿ç”¨è­¦èªž



---



## 5. å»ºè­°è¼¸å‡ºæ ¼å¼ï¼ˆæä¾›çµ¦å¯©æŸ¥ä»£ç†ï¼‰

- è¡¨æ ¼ï¼šæ–‡ä»¶é …ç›®ï½œé æœŸæ‡‰é™„ï¼Ÿï½œç”³è«‹æ›¸æ˜¯å¦æåŠï¼Ÿï½œæ˜¯å¦æª¢é™„ï¼Ÿï½œåˆ¤å®šï½œå‚™è¨»/è£œä»¶

- æ¢åˆ—ï¼šé—œéµæ¬„ä½ç¼ºå¤±ã€æ–‡ä»¶ä¸€è‡´æ€§ç–‘æ…®ã€ä¸‹ä¸€æ­¥å»ºè­°ï¼ˆå¿…è£œ/å»ºè­°è£œå……ï¼‰

Dataset #2 é å¯©æŒ‡å¼•ï¼ˆHBV RT-qPCR å®šé‡è©¦åŠ‘ï¼Œç¬¬ä¸‰ç­‰ç´š/åœ‹ç”¢/IVD/è®Šæ›´æ¡ˆï¼‰

# é å¯©/å½¢å¼å¯©æŸ¥æŒ‡å¼•ï¼ˆMockï¼‰â€”ç¬¬ä¸‰ç­‰ç´šåœ‹ç”¢ IVDï¼šHBV æ ¸é…¸å®šé‡ï¼ˆRT-qPCRï¼‰è®Šæ›´æ¡ˆ

# Antigravity AI Workspace â€” Comprehensive Technical Specification (Improved Design, Original Features Preserved)

## 1. Overview

Antigravity AI Workspace is a multi-tool Streamlit application that combines: (1) multi-provider LLM access (OpenAI, Gemini, Anthropic, Grok), (2) agent execution from an `agents.yaml` catalog, (3) a step-based Workflow Studio, (4) a TW TFDA premarket application drafting + screening experience, (5) an FDA 510(k) intelligence and review pipeline, (6) PDF-to-Markdown conversion with optional OCR, (7) a Note Keeper with keyword highlighting and â€œmagicsâ€, and (8) a WOW UI â€œStyle Engineâ€ featuring 20 painter styles and a â€œJackpotâ€ randomizer.

This specification describes the **existing system design** and an **improved design** that **keeps all original features** while adding the requested enhancements:

1. **Default case + default review guidance persistence and selection**: users can choose to load built-in default datasets/documents or upload new ones. Users can edit cases and guidance in Markdown (where appropriate) and download modified content in multiple formats.
2. **Non-standard case dataset standardization**: if uploaded case dataset is not standardized, the system transforms it into the standardized schema before the user edits and exports it.
3. **A new â€œRefresh Application Completenessâ€ button** plus a clear listing of which items are incomplete.

This is a *technical specification* (not code). It assumes the current codebase remains unchanged until implementation work begins, and defines how the improvements should be implemented and validated.

---

## 2. Goals and Non-Goals

### 2.1 Goals
- Preserve all current functionality and UI tabs:
  - Dashboard (history, token meter, charts)
  - Workflow Studio (multi-step agents)
  - TW Premarket (application form + guidance + screening + doc helper)
  - 510(k) Intelligence
  - PDF â†’ Markdown (with OCR option)
  - 510(k) Review Pipeline
  - Note Keeper & Magics
  - Agents Config Studio
- Add robust dataset/document lifecycle controls for **TW Premarket cases** and **screening guidance**:
  - Load default data
  - Upload new data (JSON/CSV for cases; PDF/TXT/MD for guidance)
  - Standardize uploaded cases if needed
  - Edit cases and guidance
  - Download edited cases (JSON/CSV) and guidance (TXT/MD)
- Add a completeness refresh mechanism that:
  - Recalculates completeness deterministically
  - Lists missing/unfinished items in a human-readable checklist

### 2.2 Non-Goals
- No backend database requirement (the app currently operates primarily in-memory via Streamlit `session_state`).
- No changes to model provider integrations beyond what exists.
- No requirement to support multi-user concurrency persistence across sessions (unless later requested).

---

## 3. System Context and Architecture

### 3.1 High-level architecture
- **Frontend/UI layer**: Streamlit components + custom CSS (Style Engine).
- **State layer**: `st.session_state` stores settings, API keys, workflow steps/outputs/status, TW form fields, extracted PDF text, agent outputs, history logs, etc.
- **Agent configuration layer**: loads `agents.yaml`, applies fallback agents, supports upload and LLM-based standardization of non-standard YAML.
- **LLM router**: `call_llm()` dispatches to provider-specific SDKs (OpenAI/Gemini/Anthropic/httpx for Grok).
- **Utilities**: PDF text extraction (pypdf + optional OCR), PDF export (reportlab), keyword highlighting, token estimation.

### 3.2 Proposed modular additions (design-level)
Add a **Data & Guidance Manager** subsystem specifically for the TW Premarket experience:
- Default case store (built-in JSON object already provided in prompt)
- Default guidance store (built-in guidance documents; at least Dataset #1 and Dataset #2)
- User upload ingestion + standardization pipeline for cases
- Editors + download/export tools for cases and guidance
- Completeness refresh + missing items view

---

## 4. Data Models and Schemas

### 4.1 Standardized â€œCaseâ€ schema (TW TFDA application)
The application already defines a canonical schema via `TW_APP_FIELDS` and `build_tw_app_dict_from_session()`. The standardized case object is a single JSON object with these keys:

- Core identifiers and classification:
  - `doc_no`, `e_no`, `apply_date`, `case_type`, `device_category`, `case_kind`,
  - `origin`, `product_class`, `similar`, `replace_flag`, `prior_app_no`
- Device naming and classification:
  - `name_zh`, `name_en`, `indications`, `spec_comp`,
  - `main_cat`, `item_code`, `item_name`
- Applicant (local firm) info:
  - `uniform_id`, `firm_name`, `firm_addr`,
  - `resp_name`, `contact_name`, `contact_tel`, `contact_fax`, `contact_email`
- Certifications:
  - `confirm_match`, `cert_raps`, `cert_ahwp`, `cert_other`
- Manufacturer info:
  - `manu_type`, `manu_name`, `manu_country`, `manu_addr`, `manu_note`
- Attachments summaries:
  - `auth_applicable`, `auth_desc`,
  - `cfs_applicable`, `cfs_desc`,
  - `qms_applicable`, `qms_desc`,
  - `similar_info`, `labeling_info`, `tech_file_info`,
  - `preclinical_info`, `preclinical_replace`,
  - `clinical_just`, `clinical_info`

**Date normalization**: `apply_date` must be `YYYY-MM-DD` or empty string.

### 4.2 â€œCases datasetâ€ formats
To support user datasets, define a â€œcases datasetâ€ as either:
- **Single-case file**:
  - JSON object (one case)
  - CSV with one row
- **Multi-case dataset**:
  - JSON list of objects, each representing a standardized case
  - CSV with multiple rows, each row a case

The system must detect whether input represents single or multiple cases and normalize internally to:
- `cases: List[CaseObject]` (list of standardized case dicts)

### 4.3 Guidance document formats
Guidance is treated as a â€œdocumentâ€ with:
- `guidance_id` (string; e.g., `dataset_1_syringe_mock`)
- `title` (string)
- `content` (string; Markdown preferred)
- `source_type` (enum: `default`, `uploaded`)
- `format` (enum: `markdown`, `text`, `pdf_extracted_text`)
- `last_modified` timestamp (optional)

Internally, guidance should be stored as Markdown text whenever possible. For PDF uploads, the extracted text can be converted to Markdown via the existing PDF â†’ Markdown agent, but that conversion remains optional.

---

## 5. Feature Specifications (Existing + Improved)

## 5.1 Existing features (must remain unchanged)
- Multi-provider model selection and per-run overrides (agent runner, workflow studio, note magics).
- Agents YAML load/upload + LLM-based YAML standardization.
- WOW UI Style Engine with painter themes, dark/light mode, and â€œJackpotâ€.
- Dashboard logging with run history, token estimates, charts, and export to CSV.
- PDF extraction + optional OCR.
- TW Premarket:
  - form-based application drafting,
  - guidance upload/paste,
  - screening agent run,
  - document helper agent run,
  - application import/export JSON+CSV,
  - completeness indicator (currently computed)
- 510(k) intelligence and review pipeline.
- Note Keeper with keyword highlighting and 6 magics + run any agent.

## 5.2 New Feature 1 â€” Default dataset/document library + load/edit/download

### 5.2.1 Default content to ship with the app
- **Default Case**: the provided JSON object (â€œä¸€æ¬¡æ€§ä½¿ç”¨ç„¡èŒæ³¨å°„å™¨ï¼ˆå«é‡ï¼‰â€¦â€) is stored as the built-in default case.
- **Default Guidance**:
  - Dataset #1: the â€œä¸€æ¬¡æ€§ä½¿ç”¨ç„¡èŒæ³¨å°„å™¨ï¼ˆå«é‡ï¼‰â€ mock pre-review guidance (Markdown).
  - Dataset #2: â€œHBV RT-qPCR å®šé‡è©¦åŠ‘â€¦â€ mock guidance (Markdown; currently partial in prompt but should still be stored).

### 5.2.2 User selection UX (TW Premarket tab)
Add a â€œData Sourceâ€ section at the top of TW Premarket:
- **Cases Source** (radio/select):
  - â€œLoad default caseâ€
  - â€œUpload case dataset (JSON/CSV)â€
- **Guidance Source** (radio/select):
  - â€œLoad default guidanceâ€
  - â€œUpload guidance (PDF/TXT/MD)â€
  - (Optional) â€œChoose from default guidance libraryâ€ (Dataset #1 vs #2)

When â€œLoad default â€¦â€ is selected, the system populates session state:
- Apply case â†’ fills the form fields (via existing `apply_tw_app_dict_to_session`)
- Load guidance â†’ sets `tw_guidance_text`

### 5.2.3 Editing cases and guidance
**Cases editing requirements**:
- Provide two editing modes:
  1. **Form mode** (existing): users edit through the TW form.
  2. **Dataset mode** (new): users can view/edit one or many cases as:
     - A table editor (pandas dataframe editing pattern)
     - A raw JSON editor (textarea)
- Users can choose which case is â€œactiveâ€ for the TW form and screening. For multi-case datasets:
  - Add a â€œSelect active caseâ€ dropdown (by `e_no` or index + `name_zh`)

**Guidance editing requirements**:
- Provide a Markdown editor textarea for guidance content (existing paste area can serve as base, but the design requires a clearer â€œGuidance Editorâ€ with preview).
- Provide an optional â€œNormalize to Markdownâ€ utility:
  - If guidance comes from PDF extraction, allow running â€œPDF â†’ Markdown Agentâ€ to clean it.

### 5.2.4 Download/export of modified content
**Cases**:
- Download standardized and user-modified cases in:
  - `cases.json`
    - If single case: object or list (implementation choice; recommend list for consistency)
  - `cases.csv`
    - Flattened columns exactly matching standardized schema

**Guidance**:
- Download guidance in:
  - `.md` (preferred)
  - `.txt`

Export should reflect the **edited** version in session state.

---

## 5.3 New Feature 2 â€” Automatic standardization of non-standard uploaded case datasets

### 5.3.1 Ingestion detection
When a user uploads a case dataset:
- If JSON:
  - Detect if itâ€™s a dict (single) or list (multi)
- If CSV:
  - Read into DataFrame; treat each row as a case candidate

### 5.3.2 Standardization logic
A robust standardization pipeline should be applied when the uploaded cases are not already standardized.

**Standardization stages**:
1. **Structural normalization**
   - Convert input into a list of records (`records: List[dict]`)
2. **Schema compliance check**
   - A record is â€œstandardizedâ€ if all keys in `TW_APP_FIELDS` exist (extra keys allowed but should be ignored or preserved separately).
3. **Deterministic mapping (first pass)**
   - Attempt to map common synonyms to standardized keys (non-LLM):
     - Examples:
       - `é›»å­æµæ°´è™Ÿ`, `eNo`, `e_no` â†’ `e_no`
       - `ç”³è«‹æ—¥`, `applyDate` â†’ `apply_date`
       - `å…¬å¸çµ±ç·¨` â†’ `uniform_id`
       - `è£½é€ å» åœ°å€` â†’ `manu_addr`
   - Normalize booleans (`yes/no`, `true/false`, `æ˜¯/å¦`) for:
     - `confirm_match`, `cert_raps`, `cert_ahwp`
4. **LLM-assisted mapping (fallback)**
   - For records still missing required keys or with ambiguous mappings, call the existing LLM normalization approach (similar to `standardize_tw_app_info_with_llm`).
   - Enforce strict JSON output rules and ensure all standardized keys exist with default values (`""` or `false`).

### 5.3.3 Post-standardization validation
After standardization, run validation checks:
- Ensure all `TW_APP_FIELDS` are present in each case
- Enforce `apply_date` format or blank
- Ensure boolean fields are boolean
- Report warnings for:
  - Empty critical fields (e.g., `e_no`, `name_zh`, `firm_name`)
  - Unexpected value domains (e.g., `product_class` not in {ç¬¬äºŒç­‰ç´š, ç¬¬ä¸‰ç­‰ç´š})

### 5.3.4 Editing and exporting standardized dataset
The user must be able to:
- Edit standardized cases (table + JSON)
- Select active case for form/screening
- Export modified dataset in CSV or JSON

---

## 5.4 New Feature 3 â€” Refresh completeness + missing items list

### 5.4.1 Completeness definition
The app already computes a TW application completeness ratio using required keys in session state. The improved design adds:
- A user-triggered **â€œRefresh Application Completenessâ€** button that:
  - Recomputes completeness
  - Produces a detailed missing-items report
  - Updates the UI card and progress bar deterministically

### 5.4.2 Missing items report
Provide an explicit checklist grouped by category:

**A. Required form fields missing**
- Derived from the same list used in completeness:
  - e.g., `tw_e_no`, `tw_case_type`, `tw_device_category`, `tw_origin`, `tw_product_class`,
  - `tw_dev_name_zh`, `tw_dev_name_en`,
  - `tw_uniform_id`, `tw_firm_name`, `tw_firm_addr`,
  - `tw_resp_name`, `tw_contact_name`, `tw_contact_tel`, `tw_contact_email`,
  - `tw_manu_name`, `tw_manu_addr`

**B. Guidance readiness**
- If guidance is empty, mark:
  - â€œScreening guidance not provided (optional but recommended)â€
- If guidance is PDF-extracted raw text, mark:
  - â€œGuidance not normalized to Markdown (optional)â€

**C. Attachment summaries completeness (optional tier)**
Even if not required for the basic completeness ratio, highlight missing summaries if relevant:
- `auth_desc` when `auth_applicable` == â€œé©ç”¨â€
- `cfs_desc` when `cfs_applicable` == â€œé©ç”¨â€
- `qms_desc` when `qms_applicable` == â€œé©ç”¨â€
- `labeling_info`, `tech_file_info`, `preclinical_info`, `clinical_info` (depending on case)

**D. Consistency checks (informational warnings)**
- Name consistency: `name_zh`, `name_en` appear consistent with guidance context (non-blocking unless rules are added)
- Manufacturer fields consistent with QMS/CFS (informational unless parsed)

### 5.4.3 UI placement
- Place the refresh button in the TW Premarket tab near the completeness card.
- After refresh, show:
  - Updated completeness percentage
  - A collapsible â€œWhatâ€™s not finishedâ€ section with bullet lists per category

### 5.4.4 Behavior
- Clicking refresh should not erase user edits.
- The report should be reproducible and based purely on current session state values.

---

## 6. User Experience and Interaction Flows

## 6.1 TW Premarket end-to-end flow (improved)
1. **Choose case source**
   - Load default case OR upload dataset
2. **If upload dataset**
   - System standardizes if needed
   - User edits standardized dataset
   - User selects active case
3. **Case applied to form**
   - Form reflects active case fields; user can edit in form
4. **Choose guidance source**
   - Load default guidance dataset OR upload guidance document
5. **Edit guidance**
   - User refines in Markdown editor; optional normalization to Markdown
6. **Refresh completeness**
   - See missing items and what remains
7. **Run screening agent**
   - Combined input: application markdown + guidance markdown/text
8. **Run doc helper agent**
   - Improves the application markdown
9. **Export**
   - Download modified case (JSON/CSV)
   - Download modified guidance (MD/TXT)
   - Download application markdown and screening outputs (existing behavior can be extended)

---

## 7. State Management

### 7.1 Session state keys (design additions)
Introduce new session keys conceptually (names may vary at implementation):
- `tw_cases_source`: `default|upload`
- `tw_guidance_source`: `default|upload`
- `tw_cases_dataset`: list of standardized case dicts
- `tw_active_case_index`: int
- `tw_guidance_library_selected`: e.g., `dataset_1|dataset_2`
- `tw_guidance_effective_md`: the edited guidance content
- `tw_completeness_last_refresh`: timestamp
- `tw_missing_items_report`: structured dict for UI rendering
- `tw_cases_last_uploaded_raw`: raw uploaded content for traceability (optional)

### 7.2 No persistence guarantees
Because Streamlit session state resets on restart, the design relies on:
- Download/export to preserve user changes
- Optional future enhancement: local file save or remote storage (not required here)

---

## 8. Security, Privacy, and Compliance Considerations

- API keys:
  - Must remain hidden; environment variables preferred; session input allowed.
- Uploaded documents:
  - Processed in-memory; do not log sensitive contents.
- LLM usage:
  - Standardization uses LLM; users should be warned that uploaded data may be transmitted to the selected provider.
- Export:
  - Provide a clear path to download modified content; avoid auto-saving to server filesystem by default.

---

## 9. Error Handling and Resilience

### 9.1 Standardization failures
- If deterministic mapping fails and LLM is unavailable (missing key), provide:
  - Clear error message and instructions
  - A fallback: allow user to edit raw dataset manually in JSON/CSV editor

### 9.2 Validation warnings
- Non-blocking warnings for:
  - Missing recommended fields
  - Guidance missing
  - Unusual value domains

### 9.3 Safe parsing
- Always sanitize/guard JSON parsing (strip markdown fences).
- CSV parsing should handle encoding issues and empty rows.

---

## 10. Testing and Acceptance Criteria

### 10.1 Acceptance criteria (key)
1. User can load default case and have TW form populated.
2. User can load default guidance (Dataset #1 or #2) and see it in guidance editor.
3. User can upload a non-standard CSV/JSON, and the system produces a standardized dataset matching `TW_APP_FIELDS`.
4. User can edit standardized dataset and download it as JSON and CSV.
5. User can edit guidance in Markdown and download as `.md` and `.txt`.
6. Refresh completeness button updates completeness percent and shows a list of missing items.
7. All existing tabs and features operate as before, without regressions.

### 10.2 Suggested test cases
- Upload JSON object with Chinese field names â†’ standardized keys populated.
- Upload CSV with partial columns â†’ missing columns filled with defaults.
- Upload multi-row CSV â†’ dataset editor supports selecting active case and applying to form.
- Guidance PDF upload â†’ extraction works; optional conversion to Markdown works (agent-run).
- Completeness refresh with partially filled form â†’ missing list correct.

---

## 11. Extensibility Notes

- The same dataset/document manager pattern can be reused for:
  - 510(k) checklists (default + upload + normalize)
  - Note Keeper templates
  - Workflow templates
- Completeness logic can be expanded into a â€œrule engineâ€:
  - Conditional requirements (e.g., if `origin == è¼¸å…¥`, then `auth_applicable` expected)
  - Scoring by weights per field category

---

## 12. Defined Default Assets (as shipped)

### 12.1 Default Case
- The provided â€œä¸€æ¬¡æ€§ä½¿ç”¨ç„¡èŒæ³¨å°„å™¨ï¼ˆå«é‡ï¼‰â€ JSON object is treated as `default_case_1`.

### 12.2 Default Guidance Library
- Dataset #1: â€œç¬¬äºŒç­‰ç´šè¼¸å…¥ä¸€èˆ¬é†«æï¼šä¸€æ¬¡æ€§ä½¿ç”¨ç„¡èŒæ³¨å°„å™¨ï¼ˆå«é‡ï¼‰â€ (Markdown)
- Dataset #2: â€œç¬¬ä¸‰ç­‰ç´šåœ‹ç”¢ IVDï¼šHBV RT-qPCR è®Šæ›´æ¡ˆâ€ (Markdown; partial content acceptable initially but should be editable and exportable)

---

# Follow-up Questions (20)

1. Should the exported `cases.json` always be a JSON array (even for a single case) to simplify downstream ingestion, or should it preserve object-vs-array based on the upload shape?
2. For multi-case datasets, what is the preferred â€œprimary keyâ€ to identify and select the active case (`e_no`, `doc_no`, combination, or auto-generated UUID)?
3. Should the system preserve *extra, non-standard fields* from uploaded datasets (round-trip), or should it strictly discard them after standardization?
4. What deterministic synonym mapping table (Chinese/English key aliases) do you want supported for non-LLM standardization before falling back to LLM?
5. For CSV exports, should boolean fields be exported as `true/false`, `1/0`, or `æ˜¯/å¦` to match common regulatory spreadsheet practices?
6. Do you want `apply_date` validation to be strict (reject invalid dates) or permissive (keep raw string and warn)?
7. Should guidance â€œdefault libraryâ€ be limited to the two datasets, or should it support a scalable catalog (e.g., YAML/JSON manifest of many guidances)?
8. When a user uploads guidance as PDF, should the system automatically run PDFâ†’Markdown conversion, or keep it manual to control token usage and latency?
9. Should the guidance editor support versioning (restore previous edits, compare diffs), or is single in-session editing sufficient?
10. For the â€œRefresh Application Completenessâ€ feature, do you want completeness to be based only on the current required field list, or expanded to include conditional and attachment-related requirements?
11. What level of â€œconsistency checksâ€ is desired (e.g., cross-check `manu_name` vs guidance text, check `origin` vs `auth_applicable`), and should any be blocking?
12. Should the missing-items report be exportable (e.g., download as Markdown/JSON) for audit trails?
13. Should the TW Premarket tab support saving/loading multiple named â€œprojectsâ€ in a session (case + guidance + outputs bundled), even without server persistence?
14. Do you want the dataset editor to allow batch operations (fill-down, replace, bulk normalize values like â€œç¬¬äºŒç­‰ç´š/äºŒç­‰ç´šâ€)?
15. Should the system include a â€œschema displayâ€ panel that documents each TW field with description and example values for end users?
16. For LLM-based standardization, should the model be fixed (e.g., Gemini only as today) or user-selectable with a recommended default?
17. What is the desired behavior when standardizing multi-case datasets and the LLM fails on one recordâ€”skip that record, stop all, or keep partial with flagged errors?
18. Should the application completeness refresh also consider whether the user has generated the application Markdown draft and/or run the screening agent as part of â€œfinishedâ€ status?
19. Are there any regulatory or organizational requirements for local/offline processing (e.g., forbidding sending applicant data to external LLMs), requiring a â€œno-LLM standardization onlyâ€ mode?
20. Do you want the â€œrefresh completenessâ€ button to exist only in TW Premarket, or also generalized to other workflows (510(k) pipeline completeness, note completeness, workflow completeness)?
ãƒ•ã‚¡ã‚¤ãƒ«ãŒé¸æŠžã•ã‚Œã¦ã„ã¾ã›ã‚“ãƒ•ã‚¡ã‚¤ãƒ«ãŒé¸æŠžã•ã‚Œã¦ã„ã¾ã›ã‚“
Super, please create 3 mock case datasets in JSON and 3 respective review guidance in markdown. Ending with 20 comprehensive foollow up questions

Mock Case Dataset #1 (JSON) â€” ç¬¬äºŒç­‰ç´š / è¼¸å…¥ / ä¸€èˆ¬é†«æï¼ˆå¤–ç§‘ç¸«åˆé‡ç·šçµ„ï¼‰
[
  {
    "doc_no": "è¡›æŽˆé†«å™¨å­—ç¬¬1150000456è™Ÿ",
    "e_no": "MDE-2026-001102",
    "apply_date": "2026-03-12",
    "case_type": "ä¸€èˆ¬ç”³è«‹æ¡ˆ",
    "device_category": "ä¸€èˆ¬é†«æ",
    "case_kind": "æ–°æ¡ˆ",
    "origin": "è¼¸å…¥",
    "product_class": "ç¬¬äºŒç­‰ç´š",
    "similar": "æœ‰",
    "replace_flag": "å¦",
    "prior_app_no": "",
    "name_zh": "ä¸€æ¬¡æ€§ä½¿ç”¨ç„¡èŒå¤–ç§‘ç¸«åˆé‡ç·šçµ„",
    "name_en": "Single-use Sterile Surgical Suture with Needle",
    "indications": "ä¾›é†«ç™‚å°ˆæ¥­äººå“¡æ–¼å¤–ç§‘æ‰‹è¡“ä¸­é€²è¡Œè»Ÿçµ„ç¹”ç¸«åˆä½¿ç”¨ã€‚è©³å¦‚æ ¸å®šä¹‹ä¸­æ–‡èªªæ˜Žæ›¸ã€‚",
    "spec_comp": "ç¸«ç·šæè³ªï¼šPGA/PPï¼ˆä¾åž‹è™Ÿï¼‰ï¼›ç¸«ç·šè¦æ ¼ï¼šUSP 2-0/3-0/4-0ï¼›é‡åž‹ï¼šåœ“é‡/ä¸‰è§’é‡ï¼›ç·šé•·ï¼š45/75 cmã€‚",
    "main_cat": "I.ä¸€èˆ¬åŠæ•´å½¢å¤–ç§‘æ‰‹è¡“",
    "item_code": "I.3670",
    "item_name": "å¤–ç§‘ç¸«åˆææ–™",
    "uniform_id": "24813579",
    "firm_name": "æ›œæ¾„é†«ç™‚å™¨æè‚¡ä»½æœ‰é™å…¬å¸",
    "firm_addr": "æ–°åŒ—å¸‚æ¿æ©‹å€æ–‡åŒ–è·¯äºŒæ®µ88è™Ÿ12æ¨“",
    "resp_name": "å³å† å»·",
    "contact_name": "é»ƒç­±é›¯",
    "contact_tel": "02-2258-6600",
    "contact_fax": "02-2258-6611",
    "contact_email": "ra@yaochengmed.com.tw",
    "confirm_match": true,
    "cert_raps": true,
    "cert_ahwp": false,
    "cert_other": "UDI/Labeling training certificate (2025)",
    "manu_type": "å–®ä¸€è£½é€ å» ",
    "manu_name": "SURGITECH MEDICAL INC.",
    "manu_country": "UNITED STATES",
    "manu_addr": "5000 Medical Parkway, San Diego, CA 92121, USA",
    "manu_note": "åŽŸå» è² è²¬è£½é€ ã€æ»…èŒï¼ˆEOï¼‰èˆ‡æœ€çµ‚æ”¾è¡Œï¼›è‡ºç£é†«ç™‚å™¨æå•†è² è²¬é€²å£ã€åˆ†éŠ·èˆ‡ä¸Šå¸‚å¾Œç›£ç£ã€‚",
    "auth_applicable": "é©ç”¨",
    "auth_desc": "é™„åŽŸå» æŽˆæ¬Šç™»è¨˜æ›¸æ­£æœ¬èˆ‡ä¸­è­¯æœ¬ï¼›æŽˆæ¬Šç¯„åœæ¶µè“‹æ‰€æœ‰ç¸«ç·šè¦æ ¼èˆ‡é‡åž‹ã€‚",
    "cfs_applicable": "é©ç”¨",
    "cfs_desc": "æä¾›ç¾Žåœ‹å‡ºç”¢åœ‹è£½å”®è­‰æ˜Žå½±æœ¬ï¼Œå«ç°½ç™¼æ©Ÿé—œè³‡è¨Šèˆ‡æœ‰æ•ˆæ—¥æœŸã€‚",
    "qms_applicable": "é©ç”¨",
    "qms_desc": "åŽŸå»  ISO 13485:2016 è­‰æ›¸æœ‰æ•ˆæœŸè‡³ 2028-01ï¼›é©—è­‰ç¯„åœæ¶µè“‹è¨­è¨ˆèˆ‡è£½é€ åŠæœ¬ç”¢å“é¡žåˆ¥ã€‚",
    "similar_info": "æä¾›èˆ‡å·²ä¸Šå¸‚åŒé¡žç¸«åˆç·šä¹‹æ¯”è¼ƒè¡¨ï¼šæè³ªã€å¸æ”¶æ€§ã€æ‹‰ä¼¸å¼·åº¦ã€é‡åž‹ã€æ»…èŒæ–¹å¼ç­‰å·®ç•°ï¼›å¦é™„åŒé¡žå“è¨±å¯è­‰è³‡è¨Šã€‚",
    "labeling_info": "ä¸­æ–‡æ¨™ç±¤/èªªæ˜Žæ›¸æ“¬ç¨¿å«ï¼šç”¢å“è¦æ ¼ã€é‡åž‹ã€æè³ªã€ç„¡èŒã€å–®æ¬¡ä½¿ç”¨ã€æ»…èŒæ–¹å¼ï¼ˆEOï¼‰ã€æ•ˆæœŸã€æ‰¹è™Ÿã€ç¦å¿Œèˆ‡æ³¨æ„äº‹é …ã€‚",
    "tech_file_info": "æä¾›ç”¢å“çµæ§‹èˆ‡è¦æ ¼è¡¨ã€ææ–™æ¸…å–®ã€è£½ç¨‹æ¦‚è¿°ã€æ»…èŒç¢ºæ•ˆæ‘˜è¦ã€åŒ…è£å®Œæ•´æ€§æ¸¬è©¦æ‘˜è¦èˆ‡æ€§èƒ½æ¸¬è©¦æ‘˜è¦ã€‚",
    "preclinical_info": "è‡¨åºŠå‰æ¸¬è©¦æ‘˜è¦ï¼šç”Ÿç‰©ç›¸å®¹æ€§ï¼ˆISO 10993 ç³»åˆ—ï¼‰ã€æ»…èŒç¢ºæ•ˆï¼ˆISO 11135ï¼‰ã€åŒ…è£å®Œæ•´æ€§èˆ‡é‹è¼¸æ¨¡æ“¬ã€æ‹‰ä¼¸å¼·åº¦ã€é‡-ç·šé€£æŽ¥å¼·åº¦ç­‰æ€§èƒ½æ¸¬è©¦ã€‚",
    "preclinical_replace": "",
    "clinical_just": "ä¸é©ç”¨",
    "clinical_info": "æœ¬å“å±¬æˆç†ŸæŠ€è¡“ä¹‹ç¸«åˆææ–™ï¼Œé¢¨éšªè©•ä¼°èˆ‡æ³•è¦è¦æ±‚ä»¥è‡¨åºŠå‰æ€§èƒ½/ç”Ÿç‰©ç›¸å®¹æ€§åŠæ»…èŒç¢ºæ•ˆç‚ºä¸»ï¼Œç„¡è‡¨åºŠè©¦é©—éœ€æ±‚ã€‚"
  },
  {
    "doc_no": "è¡›æŽˆé†«å™¨å­—ç¬¬1150000457è™Ÿ",
    "e_no": "MDE-2026-001103",
    "apply_date": "2026-03-12",
    "case_type": "ä¸€èˆ¬ç”³è«‹æ¡ˆ",
    "device_category": "ä¸€èˆ¬é†«æ",
    "case_kind": "æ–°æ¡ˆ",
    "origin": "è¼¸å…¥",
    "product_class": "ç¬¬äºŒç­‰ç´š",
    "similar": "æœ‰",
    "replace_flag": "å¦",
    "prior_app_no": "",
    "name_zh": "ä¸€æ¬¡æ€§ä½¿ç”¨ç„¡èŒå¤–ç§‘ç¸«åˆç·šï¼ˆç„¡é‡ï¼‰",
    "name_en": "Single-use Sterile Surgical Suture (Needleless)",
    "indications": "ä¾›é†«ç™‚å°ˆæ¥­äººå“¡æ–¼å¤–ç§‘æ‰‹è¡“æˆ–å‚·å£è™•ç½®ä¸­é€²è¡Œè»Ÿçµ„ç¹”ç¸«åˆä½¿ç”¨ã€‚è©³å¦‚æ ¸å®šä¹‹ä¸­æ–‡èªªæ˜Žæ›¸ã€‚",
    "spec_comp": "ç¸«ç·šæè³ªï¼šNylon/PPï¼ˆä¾åž‹è™Ÿï¼‰ï¼›ç¸«ç·šè¦æ ¼ï¼šUSP 2-0/3-0/4-0ï¼›ç·šé•·ï¼š45/90 cmï¼›ç„¡é‡ç‰ˆæœ¬ã€‚",
    "main_cat": "I.ä¸€èˆ¬åŠæ•´å½¢å¤–ç§‘æ‰‹è¡“",
    "item_code": "I.3670",
    "item_name": "å¤–ç§‘ç¸«åˆææ–™",
    "uniform_id": "24813579",
    "firm_name": "æ›œæ¾„é†«ç™‚å™¨æè‚¡ä»½æœ‰é™å…¬å¸",
    "firm_addr": "æ–°åŒ—å¸‚æ¿æ©‹å€æ–‡åŒ–è·¯äºŒæ®µ88è™Ÿ12æ¨“",
    "resp_name": "å³å† å»·",
    "contact_name": "é»ƒç­±é›¯",
    "contact_tel": "02-2258-6600",
    "contact_fax": "02-2258-6611",
    "contact_email": "ra@yaochengmed.com.tw",
    "confirm_match": true,
    "cert_raps": true,
    "cert_ahwp": false,
    "cert_other": "UDI/Labeling training certificate (2025)",
    "manu_type": "å–®ä¸€è£½é€ å» ",
    "manu_name": "SURGITECH MEDICAL INC.",
    "manu_country": "UNITED STATES",
    "manu_addr": "5000 Medical Parkway, San Diego, CA 92121, USA",
    "manu_note": "èˆ‡åŒç³»åˆ—å«é‡ç”¢å“åŒå» è£½é€ èˆ‡æ»…èŒï¼ˆEOï¼‰ï¼›è‡ºç£å•†è² è²¬ä¸Šå¸‚å¾Œç›£ç£ã€‚",
    "auth_applicable": "é©ç”¨",
    "auth_desc": "æŽˆæ¬Šæ›¸ç¯„åœåŒ…å«æœ¬ç„¡é‡ç‰ˆæœ¬åž‹è™Ÿèˆ‡è¦æ ¼ï¼›é™„ä¸­è­¯æœ¬ã€‚",
    "cfs_applicable": "é©ç”¨",
    "cfs_desc": "åŒç³»åˆ—ç”¢å“å‡ºç”¢åœ‹è£½å”®è­‰æ˜Žæ–‡ä»¶ï¼›é™„ç°½ç™¼æ©Ÿé—œè³‡è¨Šã€‚",
    "qms_applicable": "é©ç”¨",
    "qms_desc": "ISO 13485:2016 è­‰æ›¸æœ‰æ•ˆæœŸè‡³ 2028-01ã€‚",
    "similar_info": "æä¾›ç„¡é‡ç¸«åˆç·šèˆ‡å¸‚å”®åŒé¡žå“æ¯”è¼ƒï¼šæè³ªã€ç·šå¾‘ã€çµç¯€å¼·åº¦ç­‰ã€‚",
    "labeling_info": "ä¸­æ–‡æ¨™ç¤ºå«ï¼šç„¡èŒã€å–®æ¬¡ä½¿ç”¨ã€æ»…èŒæ–¹å¼ï¼ˆEOï¼‰ã€æ•ˆæœŸã€æ‰¹è™ŸåŠç¦å¿Œæ³¨æ„äº‹é …ã€‚",
    "tech_file_info": "æä¾›è¦æ ¼è¡¨ã€ææ–™æ¸…å–®ã€è£½ç¨‹ç°¡è¿°ã€æ»…èŒç¢ºæ•ˆæ‘˜è¦ã€åŒ…è£å®Œæ•´æ€§æ‘˜è¦åŠæ€§èƒ½æ¸¬è©¦æ‘˜è¦ã€‚",
    "preclinical_info": "ç”Ÿç‰©ç›¸å®¹æ€§ã€æ»…èŒç¢ºæ•ˆã€åŒ…è£å®Œæ•´æ€§èˆ‡æ€§èƒ½ï¼ˆæ‹‰ä¼¸/çµç¯€å¼·åº¦ï¼‰æ¸¬è©¦æ‘˜è¦ã€‚",
    "preclinical_replace": "",
    "clinical_just": "ä¸é©ç”¨",
    "clinical_info": "æˆç†ŸæŠ€è¡“ç”¢å“ï¼Œä»¥è‡¨åºŠå‰è³‡æ–™æ”¯æŒå®‰å…¨æœ‰æ•ˆã€‚"
  }
]
Review Guidance #1 (Markdown) â€” Dataset #1 é å¯©/å½¢å¼å¯©æŸ¥æŒ‡å¼•ï¼ˆå¤–ç§‘ç¸«åˆé‡ç·šçµ„ï¼Œç¬¬äºŒç­‰ç´š/è¼¸å…¥ï¼‰
# é å¯©/å½¢å¼å¯©æŸ¥æŒ‡å¼•ï¼ˆMockï¼‰â€”ç¬¬äºŒç­‰ç´šè¼¸å…¥ä¸€èˆ¬é†«æï¼šå¤–ç§‘ç¸«åˆé‡ç·šçµ„

## 0. å¯©æŸ¥ç›®çš„
æœ¬æŒ‡å¼•ç”¨æ–¼å½¢å¼å¯©æŸ¥ï¼ˆé å¯©ï¼‰éšŽæ®µï¼Œç¢ºèªç”³è«‹æ›¸é—œéµæ¬„ä½ã€å¿…å‚™é™„ä»¶ã€æ–‡ä»¶ä¸€è‡´æ€§èˆ‡è¿½æº¯æ€§æ˜¯å¦è¶³ä»¥é€²å…¥æŠ€è¡“å¯©æŸ¥ã€‚

---

## 1. å¿…è¦æ–‡ä»¶æ¸…å–®ï¼ˆé æœŸæ‡‰é™„ï¼‰
> å¯©æŸ¥æ™‚è«‹é€é …ç¢ºèªï¼š**æ˜¯å¦æåŠ** / **æ˜¯å¦æª¢é™„** / **æ˜¯å¦æœ‰æ•ˆï¼ˆåœ¨æ•ˆæœŸå…§ï¼‰**ã€‚

1. ç¬¬äºŒã€ä¸‰ç­‰ç´šé†«ç™‚å™¨ææŸ¥é©—ç™»è¨˜ç”³è«‹æ›¸ï¼ˆå«æ¡ˆä»¶åŸºæœ¬è³‡æ–™ã€åˆ†é¡žåˆ†ç´šã€è£½é€ å» è³‡è¨Šï¼‰
2. é†«ç™‚å™¨æå•†è¨±å¯åŸ·ç…§ï¼ˆåç¨±/åœ°å€/è² è²¬äººéœ€èˆ‡ç”³è«‹æ›¸ä¸€è‡´ï¼‰
3. åŽŸå» æŽˆæ¬Šç™»è¨˜æ›¸ï¼ˆè¼¸å…¥æ¡ˆé€šå¸¸å¿…é™„ï¼›éœ€æ¶µè“‹æ‰€æœ‰è¦æ ¼èˆ‡åž‹è™Ÿï¼‰
4. å‡ºç”¢åœ‹è£½å”®è­‰æ˜Žï¼ˆCFS æˆ–åŒç­‰æ•ˆåŠ›æ–‡ä»¶ï¼›éœ€å¯è¾¨è­˜ç”¢å“ä¸¦åœ¨æ•ˆæœŸå…§ï¼‰
5. QMS/QSD æˆ– ISO 13485 è­‰æ˜Žï¼ˆæ¶µè“‹è¨­è¨ˆ/è£½é€ èˆ‡ç”¢å“ç¯„åœï¼›åœ¨æ•ˆæœŸå…§ï¼‰
6. ä¸­æ–‡æ¨™ç±¤/ä¸­æ–‡èªªæ˜Žæ›¸/å¤–ç›’æ¨™ç¤ºæ“¬ç¨¿ï¼ˆéœ€å«ï¼šç„¡èŒã€å–®æ¬¡ä½¿ç”¨ã€æ»…èŒæ–¹å¼ã€æ•ˆæœŸã€æ‰¹è™Ÿï¼‰
7. æŠ€è¡“æª”æ¡ˆæ‘˜è¦ï¼ˆç”¢å“è¦æ ¼ã€ææ–™ã€çµæ§‹ã€è£½ç¨‹ç°¡è¿°ã€é—œéµåœ–æ¨£ï¼‰
8. æ»…èŒç¢ºæ•ˆæ‘˜è¦ï¼ˆEOï¼šISO 11135ï¼›éœ€èªªæ˜Ž SALã€å¾ªç’°ã€æ”¾è¡Œæ–¹å¼ï¼‰
9. åŒ…è£å®Œæ•´æ€§/é‹è¼¸æ¨¡æ“¬æ‘˜è¦ï¼ˆå¦‚é©ç”¨ï¼‰
10. ç”Ÿç‰©ç›¸å®¹æ€§æ‘˜è¦ï¼ˆISO 10993ï¼›éœ€ç¬¦åˆæŽ¥è§¸æ€§è³ª/æŽ¥è§¸æ™‚é–“åˆ†é¡žï¼‰
11. æ€§èƒ½æ¸¬è©¦æ‘˜è¦ï¼ˆä¾‹å¦‚ï¼šæ‹‰ä¼¸å¼·åº¦ã€çµç¯€å¼·åº¦ã€é‡-ç·šé€£æŽ¥å¼·åº¦ï¼›å¦‚å«é‡éœ€è£œå……é‡å°–ç›¸é—œæ€§èƒ½ï¼‰
12. é¢¨éšªç®¡ç†æ‘˜è¦ï¼ˆISO 14971ï¼›è‡³å°‘åˆ—ä¸»è¦å±å®³ã€æŽ§åˆ¶æŽªæ–½èˆ‡æ®˜é¤˜é¢¨éšªï¼‰
13. ä¸Šå¸‚å¾Œç›£ç£/æŠ±æ€¨è™•ç†æ©Ÿåˆ¶ç°¡è¿°ï¼ˆå¯æ‘˜è¦ï¼‰

---

## 2. ç”³è«‹æ›¸é—œéµæ¬„ä½æª¢æ ¸ï¼ˆå¿…æŸ¥ï¼‰
- æ¡ˆä»¶åŸºæœ¬è³‡æ–™ï¼šæ¡ˆä»¶é¡žåž‹/æ¡ˆä»¶ç¨®é¡ž/ç”¢åœ°/ç”¢å“ç­‰ç´š/æœ‰ç„¡é¡žä¼¼å“/æ›¿ä»£æ¢æ¬¾å‹¾é¸ç‹€æ…‹
- åç¨±ä¸€è‡´æ€§ï¼šä¸­æ–‡å“å/è‹±æ–‡å“åéœ€èˆ‡æŽˆæ¬Šæ›¸ã€CFSã€æ¨™ç¤ºæ“¬ç¨¿ä¸€è‡´
- è¦æ ¼å®Œæ•´æ€§ï¼šUSP ç·šå¾‘ã€æè³ªã€é‡åž‹ã€ç·šé•·ç­‰è¦æ ¼éœ€åœ¨ç”³è«‹æ›¸æˆ–æŠ€è¡“æ‘˜è¦å¯è¿½æº¯
- åˆ†é¡žåˆ†ç´šï¼šä¸»é¡žåˆ¥/å“é …ä»£ç¢¼/å“é …åç¨±éœ€å¡«å¯«ä¸”åˆç†
- é†«ç™‚å™¨æå•†èˆ‡è£½é€ å» ï¼šåç¨±/åœ°å€/åœ‹åˆ¥éœ€èˆ‡ QMS/CFS å…§å®¹ä¸€è‡´

---

## 3. æ–‡ä»¶ä¸€è‡´æ€§èˆ‡æ•ˆæœŸæª¢æ ¸ï¼ˆå¸¸è¦‹ç–‘é»žï¼‰
- æŽˆæ¬Šç¯„åœï¼šæ˜¯å¦æ¶µè“‹ã€Œå«é‡ã€èˆ‡ã€Œç„¡é‡ã€ç‰ˆæœ¬ã€æ‰€æœ‰ USP ç·šå¾‘èˆ‡é‡åž‹
- CFSï¼šæ˜¯å¦å¯è¾¨è­˜ç”¢å“ç³»åˆ—/åž‹è™Ÿï¼›æ˜¯å¦éŽæœŸæˆ–ç¼ºç°½ç™¼æ©Ÿé—œè³‡è¨Š
- ISO 13485ï¼šç¯„åœæ˜¯å¦åŒ…å«è¨­è¨ˆèˆ‡è£½é€ ï¼›ç”¢å“ç¯„åœæ˜¯å¦åŒ¹é…ç¸«åˆææ–™
- æ¨™ç¤ºæ“¬ç¨¿ï¼šæ˜¯å¦ç¼ºã€Œç„¡èŒ/å–®æ¬¡ä½¿ç”¨/EO/æ•ˆæœŸ/æ‰¹è™Ÿã€ä»»ä½•ä¸€é …
- ç”Ÿç‰©ç›¸å®¹æ€§ï¼šæ˜¯å¦èƒ½å°æ‡‰æŽ¥è§¸åˆ†é¡žï¼ˆé€šå¸¸ç‚ºçŸ­æœŸ/é•·æœŸæŽ¥è§¸ï¼Œä¾å¯¦éš›ç”¨é€”ï¼‰

---

## 4. å¸¸è¦‹ç¼ºå¤±ï¼ˆå ±å‘Šä¸­è«‹æ˜Žç¢ºåˆ—ç‚ºç¼ºæ¼/è£œä»¶ï¼‰
- æŽˆæ¬Šæ›¸æœªæ¶µè“‹å…¨éƒ¨è¦æ ¼/é‡åž‹
- CFS éŽæœŸæˆ–ç„¡æ³•è¾¨è­˜ç”¢å“
- æ»…èŒç¢ºæ•ˆæ‘˜è¦æœªèªªæ˜Ž SAL æˆ–æ”¾è¡Œæ–¹å¼
- ç”Ÿç‰©ç›¸å®¹æ€§æ¸¬é …èˆ‡æŽ¥è§¸åˆ†é¡žä¸åŒ¹é…æˆ–æ‘˜è¦ä¸å®Œæ•´
- æ€§èƒ½æ¸¬è©¦ç¼ºå°‘çµç¯€å¼·åº¦/æ‹‰ä¼¸å¼·åº¦æˆ–é‡-ç·šé€£æŽ¥å¼·åº¦
- ä¸­æ–‡æ¨™ç¤ºç¼ºæ‰¹è™Ÿ/æ•ˆæœŸ/ä¸€æ¬¡æ€§ä½¿ç”¨è­¦èªž

---

## 5. å»ºè­°è¼¸å‡ºæ ¼å¼ï¼ˆæä¾›çµ¦å¯©æŸ¥ä»£ç†ï¼‰
- è¡¨æ ¼ï¼šæ–‡ä»¶é …ç›®ï½œé æœŸæ‡‰é™„ï¼Ÿï½œç”³è«‹æ›¸æ˜¯å¦æåŠï¼Ÿï½œæ˜¯å¦æª¢é™„ï¼Ÿï½œåˆ¤å®šï½œå‚™è¨»/è£œä»¶
- æ¢åˆ—ï¼šé—œéµæ¬„ä½ç¼ºå¤±ã€æ–‡ä»¶ä¸€è‡´æ€§ç–‘æ…®ã€ä¸‹ä¸€æ­¥å»ºè­°ï¼ˆå¿…è£œ/å»ºè­°è£œå……ï¼‰
Mock Case Dataset #2 (JSON) â€” ç¬¬ä¸‰ç­‰ç´š / åœ‹ç”¢ / IVD / è®Šæ›´æ¡ˆï¼ˆHbA1c æª¢æ¸¬è©¦åŠ‘ï¼‰
[
  {
    "doc_no": "è¡›æŽˆé†«å™¨å­—ç¬¬1150001122è™Ÿ",
    "e_no": "IVD-2026-000221",
    "apply_date": "2026-04-08",
    "case_type": "ä¸€èˆ¬ç”³è«‹æ¡ˆ",
    "device_category": "é«”å¤–è¨ºæ–·å™¨æ(IVD)",
    "case_kind": "è®Šæ›´æ¡ˆ",
    "origin": "åœ‹ç”¢",
    "product_class": "ç¬¬ä¸‰ç­‰ç´š",
    "similar": "æœ‰",
    "replace_flag": "å¦",
    "prior_app_no": "è¡›éƒ¨é†«å™¨è£½å­—ç¬¬009999è™Ÿ",
    "name_zh": "ç³–åŒ–è¡€è‰²ç´ ï¼ˆHbA1cï¼‰å®šé‡æª¢æ¸¬è©¦åŠ‘ï¼ˆHPLC æ³•ï¼‰",
    "name_en": "HbA1c Quantitative Reagent (HPLC Method)",
    "indications": "ç”¨æ–¼é«”å¤–å®šé‡æ¸¬å®šäººé¡žå…¨è¡€ä¸­ HbA1c æ¿ƒåº¦ï¼Œä½œç‚ºç³–å°¿ç—…è¡€ç³–æŽ§åˆ¶è©•ä¼°ä¹‹è¼”åŠ©ã€‚è©³å¦‚æ ¸å®šä¹‹ä¸­æ–‡èªªæ˜Žæ›¸ã€‚",
    "spec_comp": "åŒ…å«æ´—è„«æ¶²ã€æ ¡æ­£å“èˆ‡å“ç®¡å“ï¼›é©ç”¨æŒ‡å®š HPLC åˆ†æžå„€åž‹è™Ÿï¼ˆè©³è¦‹æŠ€è¡“æª”æ¡ˆï¼‰ã€‚",
    "main_cat": "A.è‡¨åºŠåŒ–å­¸åŠè‡¨åºŠæ¯’ç†å­¸",
    "item_code": "A.1234",
    "item_name": "ç³–åŒ–è¡€è‰²ç´ æª¢é©—ç³»çµ±",
    "uniform_id": "53531234",
    "firm_name": "åº·å‘ˆç”ŸæŠ€è‚¡ä»½æœ‰é™å…¬å¸",
    "firm_addr": "æ–°ç«¹ç¸£ç«¹åŒ—å¸‚ç”Ÿé†«ä¸€è·¯99è™Ÿ5æ¨“",
    "resp_name": "å‘¨é›…å©·",
    "contact_name": "è¨±å“²ç¶­",
    "contact_tel": "03-550-7788",
    "contact_fax": "03-550-7799",
    "contact_email": "ivd-ra@kchbio.com.tw",
    "confirm_match": true,
    "cert_raps": false,
    "cert_ahwp": false,
    "cert_other": "GMP/ISO 13485 internal training record (2025)",
    "manu_type": "å–®ä¸€è£½é€ å» ",
    "manu_name": "åº·å‘ˆç”ŸæŠ€è‚¡ä»½æœ‰é™å…¬å¸ï¼ˆç«¹åŒ—å» ï¼‰",
    "manu_country": "TAIWANï¼Œ ROC",
    "manu_addr": "æ–°ç«¹ç¸£ç«¹åŒ—å¸‚ç”Ÿé†«ä¸€è·¯99è™Ÿ3æ¨“",
    "manu_note": "æœ¬æ¬¡è®Šæ›´æ¶‰åŠé…æ–¹ä¾›æ‡‰å•†è®Šæ›´èˆ‡æ¨™ç¤ºä¿®è¨‚ï¼›è£½ç¨‹èˆ‡æ”¾è¡Œè¦æ ¼ç¶­æŒä¸€è‡´ï¼ˆè©³è®Šæ›´è©•ä¼°å ±å‘Šï¼‰ã€‚",
    "auth_applicable": "ä¸é©ç”¨",
    "auth_desc": "",
    "cfs_applicable": "ä¸é©ç”¨",
    "cfs_desc": "",
    "qms_applicable": "é©ç”¨",
    "qms_desc": "ISO 13485:2016 è­‰æ›¸æœ‰æ•ˆæœŸè‡³ 2027-10ï¼›æ¶µè“‹ IVD è©¦åŠ‘ä¹‹è¨­è¨ˆèˆ‡è£½é€ ã€‚",
    "similar_info": "æä¾›èˆ‡æ—¢æœ‰æ ¸å‡†å“é …ä¹‹å·®ç•°æ¯”è¼ƒï¼šä¾›æ‡‰å•†ã€æ¨™ç¤ºèˆ‡åŒ…è£è®Šæ›´ï¼›æ€§èƒ½è¦æ ¼èˆ‡æ–¹æ³•å­¸ç¶­æŒã€‚",
    "labeling_info": "ä¸­æ–‡æ¨™ç±¤/IFU æ“¬ç¨¿ï¼šæ›´æ–°å„²å­˜æ¢ä»¶æè¿°èˆ‡è­¦èªžå­—å¥ï¼›ç¶­æŒé©æ‡‰ç—‡èˆ‡ä½¿ç”¨æ–¹æ³•ä¸è®Šã€‚",
    "tech_file_info": "æä¾›è®Šæ›´è©•ä¼°å ±å‘Šã€é¢¨éšªè©•ä¼°æ›´æ–°ã€é…æ–¹ç­‰åŒæ€§/å¯æ¯”æ€§è³‡æ–™æ‘˜è¦ã€æ¨™ç¤ºå·®ç•°å°ç…§è¡¨ã€‚",
    "preclinical_info": "æ€§èƒ½é©—è­‰æ‘˜è¦ï¼šç²¾å¯†åº¦ã€æ­£ç¢ºåº¦ã€ç·šæ€§ã€æ”œå¸¶æ±¡æŸ“ã€æ–¹æ³•æ¯”å°ï¼ˆèˆ‡æ—¢æœ‰ç‰ˆæœ¬/åƒè€ƒæ–¹æ³•æ¯”å°ï¼‰ï¼›ä¾è®Šæ›´å½±éŸ¿ç¯„åœè£œå……å¿…è¦æ¸¬è©¦ã€‚",
    "preclinical_replace": "",
    "clinical_just": "ä¸é©ç”¨",
    "clinical_info": "æœ¬è®Šæ›´å±¬è£½é€ /æ¨™ç¤ºå±¤ç´šè®Šæ›´ï¼Œæ€§èƒ½é©—è­‰èˆ‡é¢¨éšªè©•ä¼°æ”¯æŒå¯æ¯”æ€§ï¼Œç„¡éœ€æ–°å¢žè‡¨åºŠè©¦é©—ã€‚"
  },
  {
    "doc_no": "è¡›æŽˆé†«å™¨å­—ç¬¬1150001123è™Ÿ",
    "e_no": "IVD-2026-000222",
    "apply_date": "2026-04-08",
    "case_type": "ä¸€èˆ¬ç”³è«‹æ¡ˆ",
    "device_category": "é«”å¤–è¨ºæ–·å™¨æ(IVD)",
    "case_kind": "è®Šæ›´æ¡ˆ",
    "origin": "åœ‹ç”¢",
    "product_class": "ç¬¬ä¸‰ç­‰ç´š",
    "similar": "æœ‰",
    "replace_flag": "å¦",
    "prior_app_no": "è¡›éƒ¨é†«å™¨è£½å­—ç¬¬009999è™Ÿ",
    "name_zh": "ç³–åŒ–è¡€è‰²ç´ ï¼ˆHbA1cï¼‰å®šé‡æ ¡æ­£å“",
    "name_en": "HbA1c Calibrator Set",
    "indications": "ç”¨æ–¼ HbA1c å®šé‡æª¢æ¸¬ç³»çµ±ä¹‹æ ¡æ­£ç”¨é€”ã€‚è©³å¦‚æ ¸å®šä¹‹ä¸­æ–‡èªªæ˜Žæ›¸ã€‚",
    "spec_comp": "å¤šæ¿ƒåº¦æ ¡æ­£å“çµ„ï¼›æº¯æºæ€§èˆ‡ç›®æ¨™å€¼è¨­å®šæ–¹å¼è©³è¦‹æŠ€è¡“æª”æ¡ˆã€‚",
    "main_cat": "A.è‡¨åºŠåŒ–å­¸åŠè‡¨åºŠæ¯’ç†å­¸",
    "item_code": "A.1234",
    "item_name": "ç³–åŒ–è¡€è‰²ç´ æª¢é©—ç³»çµ±",
    "uniform_id": "53531234",
    "firm_name": "åº·å‘ˆç”ŸæŠ€è‚¡ä»½æœ‰é™å…¬å¸",
    "firm_addr": "æ–°ç«¹ç¸£ç«¹åŒ—å¸‚ç”Ÿé†«ä¸€è·¯99è™Ÿ5æ¨“",
    "resp_name": "å‘¨é›…å©·",
    "contact_name": "è¨±å“²ç¶­",
    "contact_tel": "03-550-7788",
    "contact_fax": "03-550-7799",
    "contact_email": "ivd-ra@kchbio.com.tw",
    "confirm_match": true,
    "cert_raps": false,
    "cert_ahwp": false,
    "cert_other": "GMP/ISO 13485 internal training record (2025)",
    "manu_type": "å–®ä¸€è£½é€ å» ",
    "manu_name": "åº·å‘ˆç”ŸæŠ€è‚¡ä»½æœ‰é™å…¬å¸ï¼ˆç«¹åŒ—å» ï¼‰",
    "manu_country": "TAIWANï¼Œ ROC",
    "manu_addr": "æ–°ç«¹ç¸£ç«¹åŒ—å¸‚ç”Ÿé†«ä¸€è·¯99è™Ÿ3æ¨“",
    "manu_note": "æ ¡æ­£å“æ¨™ç¤ºèˆ‡åŒ…è£è¦æ ¼èª¿æ•´ï¼›é…æ–¹èˆ‡ç›®æ¨™å€¼æº¯æºæ–‡ä»¶æ›´æ–°ï¼ˆè©³è®Šæ›´å ±å‘Šï¼‰ã€‚",
    "auth_applicable": "ä¸é©ç”¨",
    "auth_desc": "",
    "cfs_applicable": "ä¸é©ç”¨",
    "cfs_desc": "",
    "qms_applicable": "é©ç”¨",
    "qms_desc": "ISO 13485:2016 è­‰æ›¸æœ‰æ•ˆæœŸè‡³ 2027-10ã€‚",
    "similar_info": "æä¾›è®Šæ›´å‰å¾Œå·®ç•°å°ç…§ï¼šæ¨™ç¤ºã€å¤–ç›’ã€èªªæ˜Žæ›¸ç‰ˆæœ¬æŽ§ç®¡èˆ‡åŒ…è£æè³ªæ›´å‹•ã€‚",
    "labeling_info": "IFU æ›´æ–°ï¼šæ¨™ç¤ºç‰ˆæœ¬è™Ÿã€æœ‰æ•ˆæœŸé™è¡¨ç¤ºæ–¹å¼ä¸€è‡´åŒ–ï¼›æ–°å¢žè²¯å­˜æ¢ä»¶æç¤ºã€‚",
    "tech_file_info": "æä¾›æ–‡ä»¶ç‰ˆæœ¬ç®¡åˆ¶æ¸…å–®ã€åŒ…è£æè³ªè¦æ ¼ã€æ¨™ç¤ºå·®ç•°å°ç…§èˆ‡é¢¨éšªè©•ä¼°æ›´æ–°æ‘˜è¦ã€‚",
    "preclinical_info": "å¯æ¯”æ€§æ‘˜è¦ï¼šæ ¡æ­£æ›²ç·šèˆ‡ç›®æ¨™å€¼ä¸€è‡´æ€§ã€ç©©å®šæ€§ï¼ˆåŠ é€Ÿ/å¯¦æ™‚ï¼‰èˆ‡æ‰¹é–“å·®æ¸¬è©¦æ‘˜è¦ã€‚",
    "preclinical_replace": "",
    "clinical_just": "ä¸é©ç”¨",
    "clinical_info": "è®Šæ›´å½±éŸ¿è©•ä¼°é¡¯ç¤ºå°è‡¨åºŠæ€§èƒ½ç„¡é¡¯è‘—å½±éŸ¿ï¼Œç„¡éœ€æ–°å¢žè‡¨åºŠè©¦é©—ã€‚"
  }
]
Review Guidance #2 (Markdown) â€” Dataset #2 é å¯©/å½¢å¼å¯©æŸ¥æŒ‡å¼•ï¼ˆHbA1c IVD è®Šæ›´æ¡ˆï¼Œç¬¬ä¸‰ç­‰ç´š/åœ‹ç”¢ï¼‰
# é å¯©/å½¢å¼å¯©æŸ¥æŒ‡å¼•ï¼ˆMockï¼‰â€”ç¬¬ä¸‰ç­‰ç´šåœ‹ç”¢ IVDï¼šHbA1c å®šé‡æª¢æ¸¬ï¼ˆHPLC æ³•ï¼‰è®Šæ›´æ¡ˆ

## 0. å¯©æŸ¥ç›®çš„
ç¢ºèªè®Šæ›´æ¡ˆç”³è«‹ä¹‹**è®Šæ›´ç¯„åœæè¿°**ã€**å—å½±éŸ¿æ–‡ä»¶æ¸…å–®**ã€**æ€§èƒ½å¯æ¯”æ€§è­‰æ“š**èˆ‡**æ–‡ä»¶ç‰ˆæœ¬æŽ§ç®¡**æ˜¯å¦é½Šå‚™ï¼Œè¶³ä»¥é€²å…¥æŠ€è¡“å¯©æŸ¥ã€‚

---

## 1. å¿…è¦æ–‡ä»¶æ¸…å–®ï¼ˆé æœŸæ‡‰é™„ï¼‰
1. è®Šæ›´æ¡ˆç”³è«‹æ›¸ï¼ˆæ¡ˆä»¶åŸºæœ¬è³‡æ–™ã€åŽŸè¨±å¯è­‰å­—è™Ÿ/æ¡ˆè™Ÿã€è®Šæ›´å…§å®¹æ‘˜è¦ï¼‰
2. é†«ç™‚å™¨æå•†/è£½é€ å» ç™»è¨˜èˆ‡åœ°å€ä¸€è‡´æ€§æ–‡ä»¶ï¼ˆåœ‹ç”¢ï¼šè£½é€ å» è³‡è¨Šéœ€å¯è¿½æº¯ï¼‰
3. QMS/QSD æˆ– ISO 13485 è­‰æ˜Žï¼ˆåœ¨æ•ˆæœŸå…§ï¼›ç¯„åœæ¶µè“‹ IVD è©¦åŠ‘è¨­è¨ˆ/è£½é€ ï¼‰
4. è®Šæ›´è©•ä¼°å ±å‘Šï¼ˆChange Assessmentï¼‰
   - è®Šæ›´åŽŸå› ã€è®Šæ›´å…§å®¹ã€å½±éŸ¿åˆ†æžã€é¢¨éšªè©•ä¼°æ›´æ–°çµè«–
5. å—å½±éŸ¿æ–‡ä»¶ç‰ˆæœ¬æ¸…å–®ï¼ˆDocument Impact Listï¼‰
   - IFUã€æ¨™ç±¤ã€å¤–ç›’ã€æŠ€è¡“æª”æ¡ˆç« ç¯€ã€è£½ç¨‹æ–‡ä»¶ç­‰
6. æ¨™ç¤º/IFU å·®ç•°å°ç…§è¡¨ï¼ˆæ–°èˆŠç‰ˆæœ¬é€æ¢æ¯”å°ï¼‰
7. æ€§èƒ½å¯æ¯”æ€§èˆ‡é©—è­‰æ‘˜è¦ï¼ˆä¾è®Šæ›´æ€§è³ªæ±ºå®šæ¸¬è©¦é …ç›®ï¼‰
   - ç²¾å¯†åº¦ã€æ­£ç¢ºåº¦ã€ç·šæ€§ã€æ–¹æ³•æ¯”å°ã€æ”œå¸¶æ±¡æŸ“ç­‰ï¼ˆé©ç”¨æ™‚ï¼‰
8. ç©©å®šæ€§è³‡æ–™æ‘˜è¦ï¼ˆå¦‚é…æ–¹ã€åŒ…è£æˆ–å„²å­˜æ¢ä»¶å½±éŸ¿ï¼‰
9. é¢¨éšªç®¡ç†æ–‡ä»¶æ‘˜è¦ï¼ˆISO 14971ï¼›è®Šæ›´å¾Œé¢¨éšªè©•ä¼°æ›´æ–°ï¼‰
10. ä¸Šå¸‚å¾Œç›£ç£èˆ‡æŠ±æ€¨è™•ç†è³‡æ–™æ‘˜è¦ï¼ˆå¦‚è®Šæ›´èˆ‡æŠ±æ€¨/ä¸è‰¯äº‹ä»¶ç›¸é—œï¼‰

---

## 2. ç”³è«‹æ›¸é—œéµæ¬„ä½æª¢æ ¸ï¼ˆå¿…æŸ¥ï¼‰
- åŽŸè¨±å¯è­‰å­—è™Ÿ/å‰æ¡ˆè™Ÿï¼šæ˜¯å¦å¡«å¯«ä¸”å¯è¿½æº¯
- è®Šæ›´é¡žåž‹èˆ‡ç¯„åœï¼šé…æ–¹ã€ä¾›æ‡‰å•†ã€åŒ…è£ã€æ¨™ç¤ºã€æ”¾è¡Œè¦æ ¼ã€æ–¹æ³•å­¸ã€è»Ÿé«”ï¼ˆå¦‚æœ‰ï¼‰ç­‰æ˜¯å¦æ˜Žç¢º
- è®Šæ›´å½±éŸ¿åˆ¤å®šï¼šæ˜¯å¦èªªæ˜Žå°å®‰å…¨æ€§/æ•ˆèƒ½/è‡¨åºŠç”¨é€”ä¹‹å½±éŸ¿
- åç¨±ä¸€è‡´æ€§ï¼šä¸­æ–‡/è‹±æ–‡å“åèˆ‡æ¨™ç¤ºã€æŠ€è¡“æª”æ¡ˆã€æ–‡ä»¶ç‰ˆæœ¬ä¸€è‡´

---

## 3. æ–‡ä»¶ä¸€è‡´æ€§èˆ‡ç‰ˆæœ¬æŽ§ç®¡ï¼ˆå¸¸è¦‹ç–‘é»žï¼‰
- IFU/Label ç‰ˆæœ¬è™Ÿã€ä¿®è¨‚æ—¥æœŸã€ä¿®è¨‚æ‘˜è¦æ˜¯å¦å®Œæ•´
- å—å½±éŸ¿æ–‡ä»¶æ¸…å–®æ˜¯å¦æ¼åˆ—ï¼ˆä¾‹å¦‚ï¼šæ ¡æ­£å“/å“ç®¡å“ä¹Ÿå¯èƒ½å—å½±éŸ¿ï¼‰
- æ€§èƒ½é©—è­‰æ‘˜è¦æ˜¯å¦èˆ‡è®Šæ›´å½±éŸ¿ä¸€è‡´ï¼ˆé¿å…â€œè®Šæ›´å¾ˆå¤§ä½†æ¸¬è©¦å¾ˆå°‘â€æˆ–åä¹‹ï¼‰
- QMS è­‰æ›¸ç¯„åœæ˜¯å¦æ¶µè“‹ IVD è©¦åŠ‘è¨­è¨ˆèˆ‡è£½é€ 

---

## 4. å¸¸è¦‹ç¼ºå¤±ï¼ˆè«‹åœ¨å ±å‘Šä¸­åˆ—ç‚ºç¼ºæ¼/è£œä»¶ï¼‰
- ç¼ºè®Šæ›´è©•ä¼°å ±å‘Šæˆ–ç¼ºé¢¨éšªè©•ä¼°æ›´æ–°çµè«–
- ç¼ºæ–°èˆŠæ¨™ç¤ºå·®ç•°å°ç…§è¡¨æˆ–å°ç…§è¡¨ä¸å®Œæ•´
- æ€§èƒ½å¯æ¯”æ€§è­‰æ“šä¸è¶³ï¼ˆæœªå°æ‡‰è®Šæ›´å½±éŸ¿ï¼‰
- ç©©å®šæ€§è³‡æ–™æœªèªªæ˜Žï¼ˆå°¤å…¶é…æ–¹/åŒ…è£/å„²å­˜æ¢ä»¶è®Šæ›´ï¼‰
- æ–‡ä»¶ç‰ˆæœ¬æŽ§ç®¡ä¸æ¸…ï¼ˆç¼ºç‰ˆæœ¬è™Ÿã€ä¿®è¨‚æ—¥æœŸã€å—å½±éŸ¿æ–‡ä»¶æ¸…å–®ï¼‰

---

## 5. å»ºè­°è¼¸å‡ºæ ¼å¼ï¼ˆæä¾›çµ¦å¯©æŸ¥ä»£ç†ï¼‰
- è¡¨æ ¼ï¼šæ–‡ä»¶é …ç›®ï½œé æœŸæ‡‰é™„ï¼Ÿï½œæ˜¯å¦æåŠï¼Ÿï½œæ˜¯å¦æª¢é™„ï¼Ÿï½œæ˜¯å¦æœ‰æ•ˆï¼Ÿï½œåˆ¤å®šï½œè£œä»¶/å‚™è¨»
- æ¢åˆ—ï¼šè®Šæ›´ç¯„åœç–‘é»žã€æ–‡ä»¶ä¸€è‡´æ€§ç–‘æ…®ã€ä¸‹ä¸€æ­¥å»ºè­°ï¼ˆå¿…è£œ/å»ºè­°è£œå……ï¼‰
Mock Case Dataset #3 (JSON) â€” ç¬¬äºŒç­‰ç´š / åœ‹ç”¢ / ä¸€èˆ¬é†«æ / æ–°æ¡ˆï¼ˆå¯é‡è¤‡ä½¿ç”¨é›»å­è¡€å£“è¨ˆï¼‰
[
  {
    "doc_no": "è¡›æŽˆé†«å™¨å­—ç¬¬1150002098è™Ÿ",
    "e_no": "MDE-2026-001880",
    "apply_date": "2026-06-20",
    "case_type": "ä¸€èˆ¬ç”³è«‹æ¡ˆ",
    "device_category": "ä¸€èˆ¬é†«æ",
    "case_kind": "æ–°æ¡ˆ",
    "origin": "åœ‹ç”¢",
    "product_class": "ç¬¬äºŒç­‰ç´š",
    "similar": "æœ‰",
    "replace_flag": "å¦",
    "prior_app_no": "",
    "name_zh": "ä¸Šè‡‚å¼é›»å­è¡€å£“è¨ˆï¼ˆå¯é‡è¤‡ä½¿ç”¨ï¼‰",
    "name_en": "Upper Arm Digital Blood Pressure Monitor (Reusable)",
    "indications": "ä¾›é†«ç™‚æ©Ÿæ§‹æˆ–ä¸€èˆ¬ä½¿ç”¨è€…æ–¼éžä¾µå…¥æ–¹å¼æ¸¬é‡æ”¶ç¸®å£“ã€èˆ’å¼µå£“åŠè„ˆæã€‚è©³å¦‚æ ¸å®šä¹‹ä¸­æ–‡èªªæ˜Žæ›¸ã€‚",
    "spec_comp": "ä¸»æ©Ÿå«å£“åŠ›æ„Ÿæ¸¬æ¨¡çµ„èˆ‡é¡¯ç¤ºå™¨ï¼›å£“è„ˆå¸¶å°ºå¯¸ S/M/Lï¼›é›»æºï¼šAA é›»æ± æˆ– USB ä¾›é›»ï¼›å…·æ¸¬é‡è¨˜æ†¶èˆ‡å¹³å‡å€¼é¡¯ç¤ºåŠŸèƒ½ï¼ˆä¾åž‹è™Ÿï¼‰ã€‚",
    "main_cat": "J.ä¸€èˆ¬é†«é™¢åŠå€‹äººä½¿ç”¨è£ç½®",
    "item_code": "J.1200",
    "item_name": "è¡€å£“è¨ˆ",
    "uniform_id": "29104567",
    "firm_name": "è¡¡å¿ƒé†«é›»ç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸",
    "firm_addr": "è‡ºä¸­å¸‚è¥¿å±¯å€å·¥æ¥­å€ä¸€è·¯10è™Ÿ2æ¨“",
    "resp_name": "å¼µæ¯“çŠ",
    "contact_name": "é„­å‡±æ–‡",
    "contact_tel": "04-2359-8800",
    "contact_fax": "04-2359-8811",
    "contact_email": "reg@hxmedtech.com.tw",
    "confirm_match": true,
    "cert_raps": false,
    "cert_ahwp": false,
    "cert_other": "IEC 62366-1 usability training record (2025)",
    "manu_type": "å–®ä¸€è£½é€ å» ",
    "manu_name": "è¡¡å¿ƒé†«é›»ç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸ï¼ˆå°ä¸­å» ï¼‰",
    "manu_country": "TAIWANï¼Œ ROC",
    "manu_addr": "è‡ºä¸­å¸‚è¥¿å±¯å€å·¥æ¥­å€ä¸€è·¯10è™Ÿ1æ¨“",
    "manu_note": "è£½é€ åŒ…å«çµ„è£ã€æ ¡æ­£èˆ‡æœ€çµ‚æ”¾è¡Œï¼›å£“è„ˆå¸¶ç”±åˆæ ¼ä¾›æ‡‰å•†ä¾›æ‡‰ä¸¦ä¾é€²æ–™è¦æ ¼æª¢é©—ã€‚",
    "auth_applicable": "ä¸é©ç”¨",
    "auth_desc": "",
    "cfs_applicable": "ä¸é©ç”¨",
    "cfs_desc": "",
    "qms_applicable": "é©ç”¨",
    "qms_desc": "ISO 13485:2016 è­‰æ›¸æœ‰æ•ˆæœŸè‡³ 2027-12ï¼›ç¯„åœæ¶µè“‹éžä¾µå…¥å¼ç”Ÿç†é‡æ¸¬è¨­å‚™ä¹‹è¨­è¨ˆèˆ‡è£½é€ ã€‚",
    "similar_info": "æä¾›èˆ‡å¸‚å”®åŒé¡žä¸Šè‡‚å¼è¡€å£“è¨ˆæ¯”è¼ƒï¼šæ¸¬é‡ç¯„åœã€ç²¾åº¦è¦æ ¼ã€å£“è„ˆå¸¶å°ºå¯¸ã€ä¾›é›»æ–¹å¼èˆ‡è¨˜æ†¶åŠŸèƒ½ã€‚",
    "labeling_info": "ä¸­æ–‡æ¨™ç±¤/èªªæ˜Žæ›¸æ“¬ç¨¿å«ï¼šåž‹è™Ÿã€åºè™Ÿ/æ‰¹è™Ÿè¡¨ç¤ºã€é©ç”¨å°è±¡ã€ä½¿ç”¨æ­¥é©Ÿã€æ³¨æ„äº‹é …ã€æ¸…æ½”ä¿é¤Šã€æ ¡æ­£å»ºè­°èˆ‡è­¦èªžã€‚",
    "tech_file_info": "æä¾›ç”¢å“è¦æ ¼æ›¸ã€é›»æ°£æ–¹å¡Šåœ–ã€è»Ÿé«”ç‰ˆæœ¬è³‡è¨Šï¼ˆå¦‚é©ç”¨ï¼‰ã€è£½ç¨‹æ¦‚è¿°ã€æ ¡æ­£æµç¨‹æ‘˜è¦ã€EMC/å®‰å…¨æ¸¬è©¦æ‘˜è¦èˆ‡æ€§èƒ½é©—è­‰æ‘˜è¦ã€‚",
    "preclinical_info": "è‡¨åºŠå‰æ¸¬è©¦æ‘˜è¦ï¼šè¡€å£“é‡æ¸¬ç²¾åº¦/é‡è¤‡æ€§è©•ä¼°ã€å£“åŠ›æ„Ÿæ¸¬æ ¡æ­£èˆ‡æ¼‚ç§»æ¸¬è©¦ã€é›»æ°£å®‰å…¨èˆ‡ EMCï¼ˆä¾é©ç”¨æ¨™æº–ï¼‰ã€ç’°å¢ƒè©¦é©—ï¼ˆæº«æ¿•åº¦/è·Œè½ç­‰ï¼Œä¾é¢¨éšªè©•ä¼°ï¼‰ã€‚",
    "preclinical_replace": "",
    "clinical_just": "ä¸é©ç”¨",
    "clinical_info": "æœ¬å“å±¬æˆç†ŸæŠ€è¡“ä¹‹éžä¾µå…¥å¼è¡€å£“é‡æ¸¬è£ç½®ï¼›ä»¥æ€§èƒ½é©—è­‰ã€é›»æ°£å®‰å…¨/EMC èˆ‡é¢¨éšªç®¡ç†æ”¯æŒå®‰å…¨æœ‰æ•ˆï¼Œç„¡è‡¨åºŠè©¦é©—éœ€æ±‚ã€‚"
  },
  {
    "doc_no": "è¡›æŽˆé†«å™¨å­—ç¬¬1150002099è™Ÿ",
    "e_no": "MDE-2026-001881",
    "apply_date": "2026-06-20",
    "case_type": "ä¸€èˆ¬ç”³è«‹æ¡ˆ",
    "device_category": "ä¸€èˆ¬é†«æ",
    "case_kind": "æ–°æ¡ˆ",
    "origin": "åœ‹ç”¢",
    "product_class": "ç¬¬äºŒç­‰ç´š",
    "similar": "æœ‰",
    "replace_flag": "å¦",
    "prior_app_no": "",
    "name_zh": "ä¸Šè‡‚å¼é›»å­è¡€å£“è¨ˆï¼ˆè—ç‰™å‚³è¼¸åž‹ï¼‰",
    "name_en": "Upper Arm Digital Blood Pressure Monitor (Bluetooth Model)",
    "indications": "ä¾›ä¸€èˆ¬ä½¿ç”¨è€…æ–¼å±…å®¶ç’°å¢ƒæ¸¬é‡è¡€å£“èˆ‡è„ˆæï¼Œä¸¦å¯é€éŽè—ç‰™å‚³è¼¸è‡³è¡Œå‹•è£ç½®é€²è¡Œç´€éŒ„ã€‚è©³å¦‚æ ¸å®šä¹‹ä¸­æ–‡èªªæ˜Žæ›¸ã€‚",
    "spec_comp": "å«è—ç‰™æ¨¡çµ„ï¼›æ”¯æ´ App è³‡æ–™åŒæ­¥ï¼ˆApp ç‚ºé¸é…ï¼‰ï¼›å£“è„ˆå¸¶å°ºå¯¸ M/Lï¼›é›»æºï¼šAA é›»æ± æˆ– USBï¼›è³‡æ–™åŠ å¯†èˆ‡é…å°æ–¹å¼è©³è¦‹æŠ€è¡“æª”æ¡ˆã€‚",
    "main_cat": "J.ä¸€èˆ¬é†«é™¢åŠå€‹äººä½¿ç”¨è£ç½®",
    "item_code": "J.1200",
    "item_name": "è¡€å£“è¨ˆ",
    "uniform_id": "29104567",
    "firm_name": "è¡¡å¿ƒé†«é›»ç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸",
    "firm_addr": "è‡ºä¸­å¸‚è¥¿å±¯å€å·¥æ¥­å€ä¸€è·¯10è™Ÿ2æ¨“",
    "resp_name": "å¼µæ¯“çŠ",
    "contact_name": "é„­å‡±æ–‡",
    "contact_tel": "04-2359-8800",
    "contact_fax": "04-2359-8811",
    "contact_email": "reg@hxmedtech.com.tw",
    "confirm_match": true,
    "cert_raps": false,
    "cert_ahwp": false,
    "cert_other": "Cybersecurity awareness training (2025)",
    "manu_type": "å–®ä¸€è£½é€ å» ",
    "manu_name": "è¡¡å¿ƒé†«é›»ç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸ï¼ˆå°ä¸­å» ï¼‰",
    "manu_country": "TAIWANï¼Œ ROC",
    "manu_addr": "è‡ºä¸­å¸‚è¥¿å±¯å€å·¥æ¥­å€ä¸€è·¯10è™Ÿ1æ¨“",
    "manu_note": "æœ¬åž‹è™Ÿå¢žåŠ ç„¡ç·šé€šè¨ŠåŠŸèƒ½ï¼›è»Ÿé«”/éŸŒé«”ç‰ˆæœ¬æŽ§ç®¡èˆ‡è³‡å®‰é¢¨éšªè©•ä¼°å¦é™„æ‘˜è¦ã€‚",
    "auth_applicable": "ä¸é©ç”¨",
    "auth_desc": "",
    "cfs_applicable": "ä¸é©ç”¨",
    "cfs_desc": "",
    "qms_applicable": "é©ç”¨",
    "qms_desc": "ISO 13485:2016 è­‰æ›¸æœ‰æ•ˆæœŸè‡³ 2027-12ï¼›æ¶µè“‹è¨­è¨ˆèˆ‡è£½é€ ã€‚",
    "similar_info": "èˆ‡åŒé¡žè—ç‰™è¡€å£“è¨ˆæ¯”è¼ƒï¼šé€šè¨Šå”å®šã€é…å°æµç¨‹ã€è³‡æ–™å„²å­˜ã€ä½¿ç”¨è€…ä»‹é¢èˆ‡å®‰å…¨æ€§æŽªæ–½ã€‚",
    "labeling_info": "æ¨™ç¤ºæ“¬ç¨¿å«ï¼šç„¡ç·šåŠŸèƒ½èªªæ˜Žã€App ç›¸å®¹æ€§ã€é…å°æ³¨æ„äº‹é …ã€è³‡æ–™éš±ç§æç¤ºèˆ‡æ•…éšœæŽ’é™¤ã€‚",
    "tech_file_info": "æä¾›ç„¡ç·šé€šè¨Šè¦æ ¼ã€è»Ÿé«”/éŸŒé«”ç‰ˆæœ¬è³‡è¨Šã€è³‡å®‰é¢¨éšªç®¡ç†æ‘˜è¦ã€é›»æ°£å®‰å…¨/EMC æ¸¬è©¦æ‘˜è¦ã€æ€§èƒ½é©—è­‰æ‘˜è¦ã€‚",
    "preclinical_info": "æ€§èƒ½èˆ‡å®‰å…¨æ¸¬è©¦æ‘˜è¦ï¼šè¡€å£“ç²¾åº¦/é‡è¤‡æ€§ã€é€šè¨Šç©©å®šæ€§ã€è³‡æ–™å‚³è¼¸å¯é æ€§ã€EMC/ç„¡ç·šå…±å­˜è©•ä¼°ï¼ˆå¦‚é©ç”¨ï¼‰ã€è³‡å®‰åŸºæœ¬æ¸¬è©¦èˆ‡é¢¨éšªæŽ§åˆ¶ã€‚",
    "preclinical_replace": "",
    "clinical_just": "ä¸é©ç”¨",
    "clinical_info": "å±¬æˆç†Ÿè¡€å£“é‡æ¸¬æŠ€è¡“ï¼›æ–°å¢žç„¡ç·šåŠŸèƒ½ä»¥è³‡å®‰èˆ‡é€šè¨Šé©—è­‰æ”¯æŒï¼Œä¸éœ€è‡¨åºŠè©¦é©—ã€‚"
  }
]
Review Guidance #3 (Markdown) â€” Dataset #3 é å¯©/å½¢å¼å¯©æŸ¥æŒ‡å¼•ï¼ˆé›»å­è¡€å£“è¨ˆï¼Œç¬¬äºŒç­‰ç´š/åœ‹ç”¢ï¼‰
# é å¯©/å½¢å¼å¯©æŸ¥æŒ‡å¼•ï¼ˆMockï¼‰â€”ç¬¬äºŒç­‰ç´šåœ‹ç”¢ä¸€èˆ¬é†«æï¼šä¸Šè‡‚å¼é›»å­è¡€å£“è¨ˆï¼ˆå«è—ç‰™åž‹ï¼‰

## 0. å¯©æŸ¥ç›®çš„
ç¢ºèªç”³è«‹æ›¸åŸºæœ¬æ¬„ä½ã€ç”¢å“è¦æ ¼èˆ‡åž‹è™Ÿç¯„åœã€å¿…å‚™é™„ä»¶ã€æ¨™ç¤ºèˆ‡æŠ€è¡“æ‘˜è¦ä¸€è‡´æ€§ï¼Œä»¥åŠï¼ˆè‹¥å«ç„¡ç·š/è»Ÿé«”ï¼‰ç›¸é—œæ–‡ä»¶æ˜¯å¦é½Šå‚™ï¼Œè¶³ä»¥é€²å…¥æŠ€è¡“å¯©æŸ¥ã€‚

---

## 1. å¿…è¦æ–‡ä»¶æ¸…å–®ï¼ˆé æœŸæ‡‰é™„ï¼‰
1. ç¬¬äºŒç­‰ç´šé†«ç™‚å™¨ææŸ¥é©—ç™»è¨˜ç”³è«‹æ›¸ï¼ˆå«åˆ†é¡žåˆ†ç´šã€è£½é€ å» è³‡è¨Šï¼‰
2. é†«ç™‚å™¨æå•†è¨±å¯/ç™»è¨˜è³‡è¨Šï¼ˆåç¨±/åœ°å€/è² è²¬äººä¸€è‡´æ€§ï¼‰
3. QMS/QSD æˆ– ISO 13485 è­‰æ˜Žï¼ˆåœ‹ç”¢é€šå¸¸å¿…å‚™ï¼›åœ¨æ•ˆæœŸå…§ï¼›ç¯„åœæ¶µè“‹è¨­è¨ˆ/è£½é€ ï¼‰
4. ä¸­æ–‡æ¨™ç±¤/ä¸­æ–‡èªªæ˜Žæ›¸/å¤–ç›’æ¨™ç¤ºæ“¬ç¨¿
   - éœ€å«ï¼šåž‹è™Ÿã€è£½é€ è³‡è¨Šã€æ³¨æ„äº‹é …ã€æ¸…æ½”ä¿é¤Šã€æ ¡æ­£å»ºè­°ã€è­¦èªž
5. æŠ€è¡“æª”æ¡ˆæ‘˜è¦
   - ç”¢å“è¦æ ¼ã€é‡æ¸¬åŽŸç†ã€é‡æ¸¬ç¯„åœ/ç²¾åº¦ã€å£“è„ˆå¸¶å°ºå¯¸ã€ä½¿ç”¨ç’°å¢ƒæ¢ä»¶
6. æ€§èƒ½é©—è­‰æ‘˜è¦
   - é‡æ¸¬ç²¾åº¦ã€é‡è¤‡æ€§ã€ç©©å¥æ€§/æ¼‚ç§»èˆ‡æ ¡æ­£ç­–ç•¥ï¼ˆæ‘˜è¦å³å¯ï¼‰
7. é›»æ°£å®‰å…¨èˆ‡ EMC æ¸¬è©¦æ‘˜è¦ï¼ˆä¾é©ç”¨æ¨™æº–ï¼‰
8.ï¼ˆè‹¥å…·è—ç‰™/ç„¡ç·šï¼‰ç„¡ç·šé€šè¨Šèˆ‡å…±å­˜è©•ä¼°æ‘˜è¦ï¼ˆå¦‚é©ç”¨ï¼‰
9.ï¼ˆè‹¥å…· App/è»Ÿé«”ï¼‰è»Ÿé«”ç‰ˆæœ¬è³‡è¨Šèˆ‡æ–‡ä»¶ç‰ˆæœ¬æŽ§ç®¡æ‘˜è¦
10.ï¼ˆè‹¥å…·é€£ç·šåŠŸèƒ½ï¼‰è³‡å®‰/éš±ç§é¢¨éšªç®¡ç†æ‘˜è¦ï¼ˆè‡³å°‘ï¼šä¸»è¦å¨è„…ã€æŽ§åˆ¶æŽªæ–½ã€æ›´æ–°/ç¶­è­·ç­–ç•¥ï¼‰
11. é¢¨éšªç®¡ç†æ‘˜è¦ï¼ˆISO 14971ï¼›ä¸»è¦å±å®³èˆ‡æŽ§åˆ¶ï¼‰

---

## 2. ç”³è«‹æ›¸é—œéµæ¬„ä½æª¢æ ¸ï¼ˆå¿…æŸ¥ï¼‰
- æ¡ˆä»¶åŸºæœ¬è³‡æ–™ï¼šæ¡ˆä»¶é¡žåž‹/æ¡ˆä»¶ç¨®é¡ž/ç”¢åœ°/ç”¢å“ç­‰ç´š/æœ‰ç„¡é¡žä¼¼å“
- åç¨±ä¸€è‡´æ€§ï¼šä¸­æ–‡/è‹±æ–‡å“åéœ€èˆ‡æ¨™ç¤ºæ“¬ç¨¿ã€æŠ€è¡“æ‘˜è¦ä¸€è‡´
- åž‹è™Ÿèˆ‡è¦æ ¼ç¯„åœï¼šå£“è„ˆå¸¶å°ºå¯¸ã€ä¾›é›»æ–¹å¼ã€è¨˜æ†¶åŠŸèƒ½ã€é€šè¨ŠåŠŸèƒ½ï¼ˆè‹¥æœ‰ï¼‰éœ€å¯è¿½æº¯
- è£½é€ å» è³‡è¨Šï¼šåç¨±/åœ°å€éœ€å®Œæ•´ä¸”èˆ‡ QMS è­‰æ›¸ä¸€è‡´
- è¯çµ¡è³‡è¨Šï¼šé›»è©±èˆ‡ email éœ€å¯ç”¨æ–¼è£œä»¶è¯ç¹«

---

## 3. æ–‡ä»¶ä¸€è‡´æ€§èˆ‡å¸¸è¦‹ç–‘é»ž
- æ¨™ç¤ºæ“¬ç¨¿æ˜¯å¦ç¼ºå°‘ï¼šåž‹è™Ÿã€åºè™Ÿ/æ‰¹è™Ÿè¡¨ç¤ºæ–¹å¼ã€æ ¡æ­£/ä¿é¤Šå»ºè­°ã€æ³¨æ„äº‹é …
- æŠ€è¡“æ‘˜è¦ä¸­çš„ç²¾åº¦è¦æ ¼æ˜¯å¦èˆ‡æ€§èƒ½é©—è­‰æ‘˜è¦ä¸€è‡´
- è‹¥å«è—ç‰™/è»Ÿé«”ï¼š
  - æ˜¯å¦æä¾›è»Ÿé«”/éŸŒé«”ç‰ˆæœ¬ã€æ›´æ–°ç­–ç•¥æ‘˜è¦
  - æ˜¯å¦æä¾›æœ€åŸºæœ¬çš„è³‡å®‰é¢¨éšªè©•ä¼°èˆ‡è³‡æ–™è™•ç†èªªæ˜Žï¼ˆéš±ç§æç¤ºï¼‰

---

## 4. å¸¸è¦‹ç¼ºå¤±ï¼ˆè«‹åœ¨å ±å‘Šä¸­åˆ—ç‚ºç¼ºæ¼/è£œä»¶ï¼‰
- ç¼º ISO 13485 æˆ–è­‰æ›¸ç¯„åœä¸æ¶µè“‹è¨­è¨ˆ/è£½é€ 
- ç¼ºé›»æ°£å®‰å…¨/EMC æ¸¬è©¦æ‘˜è¦
- åž‹è™Ÿ/è¦æ ¼ç¯„åœæè¿°ä¸æ¸…ï¼ˆå£“è„ˆå¸¶å°ºå¯¸ã€ä¾›é›»æ–¹å¼ã€ç„¡ç·šåŠŸèƒ½å·®ç•°ï¼‰
- è—ç‰™åž‹æœªæä¾›è³‡å®‰/éš±ç§é¢¨éšªç®¡ç†æ‘˜è¦æˆ–æœªèªªæ˜Žè³‡æ–™å‚³è¼¸ç‰¹æ€§
- ä¸­æ–‡èªªæ˜Žæ›¸ç¼ºæ ¡æ­£/ä¿é¤Šã€è­¦èªžæˆ–æ•…éšœæŽ’é™¤è³‡è¨Š

---

## 5. å»ºè­°è¼¸å‡ºæ ¼å¼ï¼ˆæä¾›çµ¦å¯©æŸ¥ä»£ç†ï¼‰
- è¡¨æ ¼ï¼šæ–‡ä»¶é …ç›®ï½œé æœŸæ‡‰é™„ï¼Ÿï½œç”³è«‹æ›¸æ˜¯å¦æåŠï¼Ÿï½œæ˜¯å¦æª¢é™„ï¼Ÿï½œåˆ¤å®šï½œå‚™è¨»/è£œä»¶
- æ¢åˆ—ï¼šé—œéµæ¬„ä½ç¼ºå¤±ã€æ–‡ä»¶ä¸€è‡´æ€§ç–‘æ…®ã€ä¸‹ä¸€æ­¥å»ºè­°ï¼ˆå¿…è£œ/å»ºè­°è£œå……ï¼‰
Follow-up Questions (20)
é€™ä¸‰çµ„ mock dataset ä½ å¸Œæœ›æ¯çµ„ä»£è¡¨ã€Œä¸€å€‹å¤šæ¡ˆä¾‹è³‡æ–™é›†ã€ï¼ˆå¦‚æˆ‘ç¾åœ¨æä¾›çš„ arrayï¼‰ï¼Œé‚„æ˜¯æ¯çµ„åªè¦ã€Œå–®ä¸€æ¡ˆä¾‹ã€æ›´ç¬¦åˆä½ å¾ŒçºŒæµç¨‹ï¼Ÿ
ä½ å¸Œæœ› dataset çš„æª”å/è­˜åˆ¥è¦å‰‡æ˜¯ä»€éº¼ï¼ˆä¾‹å¦‚ cases_dataset_1.json, tw_cases_suture_imported.jsonï¼‰ï¼Œä»¥ä¾¿åœ¨ç¨‹å¼ä¸­åšé è¨­è¼‰å…¥èˆ‡é¸å–®å‘ˆç¾ï¼Ÿ
å°æ–¼å¤šæ¡ˆä¾‹ datasetï¼Œä½ å¸Œæœ›ã€ŒActive caseã€é¸æ“‡ä¾æ“šæ˜¯ e_noã€name_zhã€æˆ–è‡ªå‹•ç”Ÿæˆçš„ case_idï¼ˆæ–°å¢žæ¬„ä½ï¼‰ï¼Ÿ
æ˜¯å¦éœ€è¦åœ¨æ¯å€‹ case ç‰©ä»¶ä¸­æ–°å¢ž dataset_idã€tagsã€notes ç­‰ä¸­ç¹¼è³‡æ–™æ¬„ä½ï¼Œä»¥åˆ©ç®¡ç†èˆ‡æœå°‹ï¼Ÿè‹¥è¦æ–°å¢žï¼Œæ˜¯å¦ä»è¦ç¶­æŒè¼¸å‡ºå¯å›žåˆ°ç´” TW_APP_FIELDSï¼Ÿ
cert_raps / cert_ahwp / confirm_match åœ¨ CSV åŒ¯å‡ºæ™‚ï¼Œä½ åå¥½ true/falseã€1/0ã€é‚„æ˜¯ æ˜¯/å¦ï¼Ÿ
ä½ å¸Œæœ› apply_date è‹¥è¼¸å…¥éžæ—¥æœŸæ ¼å¼æ™‚ï¼šç›´æŽ¥æ¸…ç©ºã€ä¿ç•™åŽŸå­—ä¸²ã€æˆ–è½‰ç‚ºæœ€è¿‘å¯è§£æžæ—¥æœŸä¸¦æç¤ºè­¦å‘Šï¼Ÿ
å°è¼¸å…¥æ¡ˆï¼ˆorigin=è¼¸å…¥ï¼‰ï¼Œä½ å¸Œæœ› completeness æˆ–ç¼ºæ¼æ¸…å–®ä¸­ã€Œå¼·åˆ¶ã€è¦æ±‚ auth_applicableã€cfs_applicableã€qms_applicable å¿…é ˆç‚ºã€Œé©ç”¨ã€å—Žï¼Ÿé‚„æ˜¯åªæç¤ºä½†ä¸é˜»æ“‹ï¼Ÿ
é‡å° IVD è®Šæ›´æ¡ˆï¼Œä½ å¸Œæœ› guidance ä¸­æ˜¯å¦è¦åŒ…å«æ›´ç´°çš„è®Šæ›´é¡žåž‹åˆ†é¡žï¼ˆä¾‹å¦‚ï¼šé…æ–¹/ä¾›æ‡‰å•†/è»Ÿé«”/æ¨™ç¤º/åŒ…è£/æ”¾è¡Œè¦æ ¼ï¼‰ï¼Œä¸¦åœ¨å ±å‘Šä¸­è¦æ±‚é€é¡žå°æ‡‰è­‰æ“šï¼Ÿ
å°å«ç„¡ç·šåŠŸèƒ½çš„è¡€å£“è¨ˆï¼Œä½ å¸Œæœ› guidance å°‡ã€Œè³‡å®‰ã€åˆ—ç‚ºå½¢å¼å¯©æŸ¥çš„å¿…å‚™é …ï¼Œé‚„æ˜¯æŠ€è¡“å¯©æŸ¥é …ï¼ˆé å¯©åªæç¤ºï¼‰ï¼Ÿ
ä½ å¸Œæœ›ä¸‰ä»½ guidance çš„è¼¸å‡ºèªžæ°£æ˜¯ã€Œçµ¦å¯©æŸ¥ä»£ç†ï¼ˆagentï¼‰ã€é‚„æ˜¯ã€Œçµ¦ç”³è«‹è€…ã€ï¼Ÿæ˜¯å¦è¦åŒæ™‚æä¾›å…©ç¨®ç‰ˆæœ¬ï¼ˆå¯©æŸ¥ç‰ˆ/ç”³è«‹è€…ç‰ˆï¼‰ï¼Ÿ